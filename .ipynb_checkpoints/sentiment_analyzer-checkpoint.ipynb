{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import metrics\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import wordpunct_tokenize\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from collections import Counter\n",
    "from nltk.probability import FreqDist\n",
    "\n",
    "from sklearn.linear_model import LogisticRegressionCV,LogisticRegression\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_json('reviews_Office_Products_5.json',lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asin</th>\n",
       "      <th>helpful</th>\n",
       "      <th>overall</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>summary</th>\n",
       "      <th>unixReviewTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B00000JBLH</td>\n",
       "      <td>[3, 4]</td>\n",
       "      <td>5</td>\n",
       "      <td>I bought my first HP12C in about 1984 or so, a...</td>\n",
       "      <td>09 3, 2004</td>\n",
       "      <td>A32T2H8150OJLU</td>\n",
       "      <td>ARH</td>\n",
       "      <td>A solid performer, and long time friend</td>\n",
       "      <td>1094169600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B00000JBLH</td>\n",
       "      <td>[7, 9]</td>\n",
       "      <td>5</td>\n",
       "      <td>WHY THIS BELATED REVIEW? I feel very obliged t...</td>\n",
       "      <td>12 15, 2007</td>\n",
       "      <td>A3MAFS04ZABRGO</td>\n",
       "      <td>Let it Be \"Alan\"</td>\n",
       "      <td>Price of GOLD is up, so don't bury the golden ...</td>\n",
       "      <td>1197676800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B00000JBLH</td>\n",
       "      <td>[3, 3]</td>\n",
       "      <td>2</td>\n",
       "      <td>I have an HP 48GX that has been kicking for mo...</td>\n",
       "      <td>01 1, 2011</td>\n",
       "      <td>A1F1A0QQP2XVH5</td>\n",
       "      <td>Mark B</td>\n",
       "      <td>Good functionality, but not durable like old HPs</td>\n",
       "      <td>1293840000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B00000JBLH</td>\n",
       "      <td>[7, 8]</td>\n",
       "      <td>5</td>\n",
       "      <td>I've started doing more finance stuff recently...</td>\n",
       "      <td>04 19, 2006</td>\n",
       "      <td>A49R5DBXXQDE5</td>\n",
       "      <td>R. D Johnson</td>\n",
       "      <td>One of the last of an almost extinct species</td>\n",
       "      <td>1145404800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B00000JBLH</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>5</td>\n",
       "      <td>For simple calculations and discounted cash fl...</td>\n",
       "      <td>08 4, 2013</td>\n",
       "      <td>A2XRMQA6PJ5ZJ8</td>\n",
       "      <td>Roger J. Buffington</td>\n",
       "      <td>Still the best</td>\n",
       "      <td>1375574400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         asin helpful  overall  \\\n",
       "0  B00000JBLH  [3, 4]        5   \n",
       "1  B00000JBLH  [7, 9]        5   \n",
       "2  B00000JBLH  [3, 3]        2   \n",
       "3  B00000JBLH  [7, 8]        5   \n",
       "4  B00000JBLH  [0, 0]        5   \n",
       "\n",
       "                                          reviewText   reviewTime  \\\n",
       "0  I bought my first HP12C in about 1984 or so, a...   09 3, 2004   \n",
       "1  WHY THIS BELATED REVIEW? I feel very obliged t...  12 15, 2007   \n",
       "2  I have an HP 48GX that has been kicking for mo...   01 1, 2011   \n",
       "3  I've started doing more finance stuff recently...  04 19, 2006   \n",
       "4  For simple calculations and discounted cash fl...   08 4, 2013   \n",
       "\n",
       "       reviewerID         reviewerName  \\\n",
       "0  A32T2H8150OJLU                  ARH   \n",
       "1  A3MAFS04ZABRGO     Let it Be \"Alan\"   \n",
       "2  A1F1A0QQP2XVH5               Mark B   \n",
       "3   A49R5DBXXQDE5         R. D Johnson   \n",
       "4  A2XRMQA6PJ5ZJ8  Roger J. Buffington   \n",
       "\n",
       "                                             summary  unixReviewTime  \n",
       "0            A solid performer, and long time friend      1094169600  \n",
       "1  Price of GOLD is up, so don't bury the golden ...      1197676800  \n",
       "2   Good functionality, but not durable like old HPs      1293840000  \n",
       "3       One of the last of an almost extinct species      1145404800  \n",
       "4                                     Still the best      1375574400  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data preprocessing\n",
    "data['overall'] = data['overall'].astype(object) # fix datatype error\n",
    "dataset = {\"reviewText\": data[\"reviewText\"], \"overall\": data[\"overall\"]  }\n",
    "dataset = pd.DataFrame(data = dataset)\n",
    "dataset = dataset.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewText</th>\n",
       "      <th>overall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I bought my first HP12C in about 1984 or so, a...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WHY THIS BELATED REVIEW? I feel very obliged t...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I have an HP 48GX that has been kicking for mo...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I've started doing more finance stuff recently...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>For simple calculations and discounted cash fl...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          reviewText overall\n",
       "0  I bought my first HP12C in about 1984 or so, a...       5\n",
       "1  WHY THIS BELATED REVIEW? I feel very obliged t...       5\n",
       "2  I have an HP 48GX that has been kicking for mo...       2\n",
       "3  I've started doing more finance stuff recently...       5\n",
       "4  For simple calculations and discounted cash fl...       5"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "reviewText    object\n",
       "overall       object\n",
       "dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['overall']=dataset['overall'].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(53258, 2)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset[dataset[\"overall\"] != 3] # need datatype=object\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48198, 2)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"overall\"].isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[\"label\"] = dataset[\"overall\"].apply(lambda x : 1 if x > 3 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"label\"].isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewText</th>\n",
       "      <th>overall</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [reviewText, overall, label]\n",
       "Index: []"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[dataset[\"label\"].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewText</th>\n",
       "      <th>overall</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I bought my first HP12C in about 1984 or so, a...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WHY THIS BELATED REVIEW? I feel very obliged t...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I have an HP 48GX that has been kicking for mo...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I've started doing more finance stuff recently...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>For simple calculations and discounted cash fl...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          reviewText  overall  label\n",
       "0  I bought my first HP12C in about 1984 or so, a...        5      1\n",
       "1  WHY THIS BELATED REVIEW? I feel very obliged t...        5      1\n",
       "2  I have an HP 48GX that has been kicking for mo...        2      0\n",
       "3  I've started doing more finance stuff recently...        5      1\n",
       "4  For simple calculations and discounted cash fl...        5      1"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    45342\n",
       "0     2856\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5    30327\n",
       "4    15015\n",
       "2     1726\n",
       "1     1130\n",
       "Name: overall, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.overall.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05925557077057139"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2856/(2856+45342)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['heloo', '!', '@', 'sgdf']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordpunct_tokenize(\"heloo! @ sgdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "stop_words=set(stopwords.words(\"english\"))\n",
    "# print(stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['reviewText']=dataset['reviewText'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtered_sent=[]\n",
    "# for sentence in tokenized_sent:\n",
    "#     tokenized_word=word_tokenize(sentence)\n",
    "#     for w in tokenized_word:\n",
    "#         if w not in stop_words:\n",
    "#             filtered_sent.append(w)\n",
    "# print(\"Tokenized Sentence:\",tokenized_sent)\n",
    "# print(\"Filterd Sentence:\",filtered_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['sentence']=dataset['reviewText'].apply(lambda x: sent_tokenize(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['tokens']=dataset['reviewText'].apply(lambda x: word_tokenize(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"1\".isdigit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_clean_token_list(words):\n",
    "    clean_words=[]\n",
    "    for word in words:\n",
    "        flag=True\n",
    "        for letter in word:\n",
    "            if letter.isdigit() or letter in string.punctuation:\n",
    "                flag=False\n",
    "        if flag:\n",
    "            clean_words.append(word)\n",
    "    return clean_words\n",
    "\n",
    "get_clean_token_list([\"hewy\",\"ho!w\",\"are\",\"yo6u\",\"?dd\",\"111\",\"qwerty\"])\n",
    "\n",
    "def remove_stopwords(words):\n",
    "    \"\"\"\n",
    "    pass series get series\n",
    "    \"\"\"\n",
    "    filtered_sent=[]\n",
    "    for word in words:\n",
    "        if word not in stop_words:\n",
    "            filtered_sent.append(word)\n",
    "    return filtered_sent\n",
    "\n",
    "\n",
    "remove_stopwords([\"hey\",\"how\",\"are\",\"you\",\"?\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['tokens']=dataset['tokens'].apply(remove_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['tokens'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['tokens']=dataset['tokens'].apply(get_clean_token_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['tokens'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.iloc[0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lexicon Normalization\n",
    "#performing stemming and Lemmatization\n",
    "\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "lem = WordNetLemmatizer()\n",
    "\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "stem = PorterStemmer()\n",
    "\n",
    "word = \"troubled\"\n",
    "print(\"Lemmatized Word:\",lem.lemmatize(word,\"v\"))\n",
    "print(\"Stemmed Word:\",stem.stem(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "stem = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text=\"\"\"Hello Mr. Smith, how are you doing today? The weather is great, and city is awesome.\n",
    "The sky is pinkish-blue. You shouldn't eat cardboard\"\"\"\n",
    "tokenized_sent=sent_tokenize(text)\n",
    "print(tokenized_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "tokenized_word=word_tokenize(text)\n",
    "print(tokenized_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stem_sentence(sentence):\n",
    "    stem_sentence=[]\n",
    "    for word in sentence:\n",
    "        stem_sentence.append(stem.stem(word))\n",
    "    return stem_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['stem_sentence']=dataset['tokens'].apply(lambda x: stem_sentence(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[['tokens','stem_sentence']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['pos_tag']=dataset['tokens'].apply(lambda x: nltk.pos_tag(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['pos_tag']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep only adjective and adverb\n",
    "keep_tags=[\"JJ\",\"JJR\",\"JJS\",\"RB\",\"RBR\",\"RBS\",\"UH\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['pos_tag'].apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: not required\n",
    "t=[('asked', 'VBN'),('asked', 'VBN')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in t:\n",
    "    print(x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_tag(pos_list):\n",
    "    pos_clean_list=[]\n",
    "    for t in pos_list:\n",
    "        if t[1] in keep_tags:\n",
    "            pos_clean_list.append(t[0])\n",
    "    return pos_clean_list\n",
    "\n",
    "filter_token([('asked', 'RB'), ('review', 'NN'), ('scale', 'RBS')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['filter_pos_tag']=dataset['pos_tag'].apply(filter_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[['tokens','filter_pos_tag']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_reviews=dataset[dataset['label']==1]['filter_pos_tag']\n",
    "\n",
    "positive_tokens=[word for review in positive_reviews for word in review]\n",
    "\n",
    "fdist = FreqDist(positive_tokens)\n",
    "\n",
    "\n",
    "fdist.most_common(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_reviews=dataset[dataset['label']==0]['filter_pos_tag']\n",
    "\n",
    "negative_tokens=[word for review in negative_reviews for word in review]\n",
    "\n",
    "fdist = FreqDist(negative_tokens)\n",
    "\n",
    "\n",
    "fdist.most_common(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[dataset['label']==0].iloc[25].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['clean_sentence']=dataset['filter_pos_tag'].apply(lambda x: ' '.join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO emoticon , acronymns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to calculate Model Metrics\n",
    "\n",
    "def get_model_metrics(actual,predicted):\n",
    "    \"\"\"\n",
    "    Print Summary Metrics of the Model\n",
    "\n",
    "    Parameters:\n",
    "    actual (pandas.core.series.Series): Series of Boolean values for target column\n",
    "    predicted (pandas.core.series.Series): Series of Boolean values for Model predicted the target column\n",
    "    \n",
    "    Returns:\n",
    "    None\n",
    "\n",
    "   \"\"\"\n",
    "\n",
    "    \n",
    "    confusion = metrics.confusion_matrix(actual,predicted )\n",
    "    TP = confusion[1,1] # true positive \n",
    "    TN = confusion[0,0] # true negatives\n",
    "    FP = confusion[0,1] # false positives\n",
    "    FN = confusion[1,0] # false negatives\n",
    "    accuracy=metrics.accuracy_score(actual,predicted)\n",
    "    sensitivity = TP / float(TP+FN)\n",
    "    specificity = TN / float(TN+FP)\n",
    "    precision=TP/float(FP+TP)\n",
    "    recall=TP/float(FN+TP)\n",
    "    \n",
    "    precision=metrics.precision_score(actual,predicted)\n",
    "    recall=metrics.recall_score(actual,predicted)\n",
    "    f1=metrics.f1_score(actual,predicted, average='weighted') \n",
    "    print(\"Accuracy    : \"+str(round(accuracy,2)))\n",
    "    print(\"Sensitivity : \"+str(round(sensitivity,2)))\n",
    "    print(\"Specificity : \"+str(round(specificity,2)))\n",
    "    print(\"Precision   : \"+str(round(precision,2)))\n",
    "    print(\"Recall      : \"+str(round(recall,2)))\n",
    "    print(\"F1_score    : \"+str(round(f1,2)))\n",
    "\n",
    "def get_cross_validated_model_metrics(X,y,cv=5):\n",
    "    \"\"\"\n",
    "    Get cross validated model metric for k folds\n",
    "\n",
    "    Parameters:\n",
    "    X (pandas.core.frame.DataFrame): DF of all the features excluding target column\n",
    "    y (pandas.core.series.Series): Series of Boolean values of the target column\n",
    "    \n",
    "    Returns:\n",
    "    df (pandas.core.frame.DataFrame): DF will all the metric for k fold\n",
    "\n",
    "   \"\"\"\n",
    "    accuracy=cross_val_score(logregcv, X, y, cv=cv,n_jobs=-1,scoring='accuracy')\n",
    "    precision=cross_val_score(logregcv, X, y, cv=cv,n_jobs=-1,scoring='precision')\n",
    "    recall=cross_val_score(logregcv, X, y, cv=cv,n_jobs=-1,scoring='recall')\n",
    "    f1_weighted=cross_val_score(logregcv, X, y, cv=cv,n_jobs=-1,scoring='f1_weighted')\n",
    "    roc_auc=cross_val_score(logregcv, X, y, cv=cv,n_jobs=-1,scoring='roc_auc')\n",
    "    df=pd.DataFrame(\n",
    "    {'accuracy': accuracy,\n",
    "     'precision': precision,\n",
    "     'recall': recall,\n",
    "     'f1_weighted': f1_weighted,\n",
    "     'roc_auc': roc_auc,\n",
    "    })\n",
    "    return df\n",
    "\n",
    "logregcv = LogisticRegressionCV(class_weight='balanced',cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = pd.DataFrame(dataset, columns = [\"clean_sentence\"])\n",
    "y = pd.DataFrame(dataset, columns = [\"label\"])\n",
    "\n",
    "X_train , X_test , y_train , y_test = train_test_split(X, y, random_state=50,stratify=y,train_size=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lem = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer(token_pattern=r'\\b\\w+\\b')\n",
    "train_vector = vectorizer.fit_transform(X_train[\"clean_sentence\"])\n",
    "test_vector = vectorizer.transform(X_test[\"clean_sentence\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[\"clean_sentence\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "log_reg_model = LogisticRegressionCV(class_weight='balanced')\n",
    "log_reg_model.fit(train_vector, y_train)\n",
    "scores = log_reg_model.score(test_vector, y_test) # accuracy\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Making prediction on the train data\n",
    "y_train_pred = log_reg_model.predict_proba(train_vector)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Making prediction on the test data\n",
    "y_pred = log_reg_model.predict_proba(test_vector)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred=pd.Series(y_train_pred)\n",
    "y_pred=pd.Series(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_bool= y_pred.apply(lambda x: 1 if x>=0.5 else 0)\n",
    "y_train_pred_bool= y_train_pred.apply(lambda x: 1 if x>=0.5 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.confusion_matrix(y_train,y_train_pred_bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_model_metrics(y_train,y_train_pred_bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.confusion_matrix(y_test,y_pred_bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_model_metrics(y_test,y_pred_bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_output=pd.DataFrame({'y_train':y_train['label'],'y_pred':y_train_pred,'y_train_pred_bool':y_train_pred_bool})\n",
    "test_output=pd.DataFrame({'y_test':y_test['label'],'y_pred':y_pred,'y_pred_bool':y_pred_bool})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_output['y_train'].fillna(0,inplace=True)\n",
    "test_output['y_test'].fillna(0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_output.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_output.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "def draw_roc( actual, probs ):\n",
    "    fpr, tpr, thresholds = metrics.roc_curve( actual, probs,\n",
    "                                              drop_intermediate = False )\n",
    "    auc_score = metrics.roc_auc_score( actual, probs )\n",
    "    plt.figure(figsize=(5, 5))\n",
    "    plt.plot( fpr, tpr, label='ROC curve (area = %0.2f)' % auc_score )\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate or [1 - True Negative Rate]')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver operating characteristic example')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = metrics.roc_curve(y_train,y_train_pred , drop_intermediate = False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_roc(y_train,y_train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_roc(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's calculate accuracy sensitivity and specificity for various probability cutoffs.\n",
    "cutoff_df = pd.DataFrame( columns = ['prob','accuracy','sensi','speci'])\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# confusion=confusion_matrix(df['y'],df['y_prob'])\n",
    "\n",
    "# TP = confusion[1,1] # true positive \n",
    "# TN = confusion[0,0] # true negatives\n",
    "# FP = confusion[0,1] # false positives\n",
    "# FN = confusion[1,0] # false negatives\n",
    "\n",
    "def threshold_optimization(y,num):\n",
    "    #pass the prediction_probability series and threshold probabilty cutoff\n",
    "    y_bool= y.apply(lambda x: 1 if x>=num else -1)\n",
    "    return y_bool\n",
    "\n",
    "num = [0.0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9]\n",
    "for i in num:\n",
    "    cm1 = metrics.confusion_matrix(y_train,threshold_optimization(y_train_pred,i))\n",
    "#     print(cm1)\n",
    "    total1=sum(sum(cm1))\n",
    "    accuracy = (cm1[0,0]+cm1[1,1])/total1\n",
    "    \n",
    "    speci = cm1[0,0]/(cm1[0,0]+cm1[0,1])\n",
    "    sensi = cm1[1,1]/(cm1[1,0]+cm1[1,1])\n",
    "    cutoff_df.loc[i] =[ i ,accuracy,sensi,speci]\n",
    "print(cutoff_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cutoff_df.plot.line(x='prob', y=['accuracy','sensi','speci'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_model_metrics(df['y'],df['predict_bool'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_validated_train_metrics=get_cross_validated_model_metrics(train_vector, y_train,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_validated_train_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_validated_train_metrics.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "1. stop words compare model\n",
    "2. naive bayes svm \n",
    "3. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wordpunct_tokenize(\"hello i'd like to order a coffee\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_word=word_tokenize(\"hello i'd like to order a coffee\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hello', 'i', \"'d\", 'like', 'to', 'order', 'a', 'coffee']"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<FreqDist with 8 samples and 8 outcomes>\n"
     ]
    }
   ],
   "source": [
    "from nltk.probability import FreqDist\n",
    "fdist = FreqDist(tokenized_word)\n",
    "print(fdist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('hello', 1), ('i', 1), (\"'d\", 1), ('like', 1), ('to', 1)]"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fdist.most_common(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fdist.plot(30,cumulative=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import string\n",
    "# string.punctuation\n",
    "# import re\n",
    "\n",
    "#lower case\n",
    "# remove punctuation - hold\n",
    "# words containing numbers should be rmove and have only letters-hold\n",
    "#"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
