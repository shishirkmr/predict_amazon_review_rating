{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import pandas\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk import sent_tokenize\n",
    "from textblob import TextBlob\n",
    "from textblob import Word\n",
    "from nltk import ngrams\n",
    "#import plots\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from gensim.models import Phrases\n",
    "from gensim.models.phrases import Phraser\n",
    "import gensim.models.keyedvectors as word2vec\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "s0 = \"Good looking average product by Honor. For 2000 bucks, it is really a good option to buy. Easy to use and looks durable\"\n",
    "s1 = \"Among the best premium wireless headphones. Must buy-product.\"\n",
    "s2 = \"No refund received for microwave oven, delivery guys was quite ignorant to our complaints and queries.\"\n",
    "s3 = \"Very bad experience with the router. Cables are completely damaged.\"\n",
    "s4 = \"Purchased the product based on Mi Brand. Product proves to be a disappointment. Worst Led TV in the market.Pathetic after sales service.\"\n",
    "s5 = \"This earbuds are awesome. Completely value for money.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "rev_list = [s0,s1,s2,s3,s4,s5]\n",
    "new_list = []\n",
    "for i in rev_list:\n",
    "    new_list.append(i)\n",
    "sample = pd.DataFrame(new_list, columns = ['reviews'])\n",
    "sample['ratings'] = [1,1,0,0,0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "The `text` argument passed to `__init__(text)` must be a string, not <class 'pandas.core.series.Series'>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-611a60a3d3d0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mblob_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mblob_list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mngram_textblob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'reviews'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-7-611a60a3d3d0>\u001b[0m in \u001b[0;36mngram_textblob\u001b[0;34m(col, n)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mngram_textblob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mblob_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mTextBlob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mngrams\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m         \u001b[0mblob_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mblob_list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/textblob/blob.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, text, tokenizer, pos_tagger, np_extractor, analyzer, parser, classifier, clean_html)\u001b[0m\n\u001b[1;32m    368\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbasestring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m             raise TypeError('The `text` argument passed to `__init__(text)` '\n\u001b[0;32m--> 370\u001b[0;31m                             'must be a string, not {0}'.format(type(text)))\n\u001b[0m\u001b[1;32m    371\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mclean_html\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    372\u001b[0m             raise NotImplementedError(\"clean_html has been deprecated. \"\n",
      "\u001b[0;31mTypeError\u001b[0m: The `text` argument passed to `__init__(text)` must be a string, not <class 'pandas.core.series.Series'>"
     ]
    }
   ],
   "source": [
    "def ngram_textblob(col,n):\n",
    "    blob_list = []\n",
    "    for word in TextBlob(col).ngrams(n):\n",
    "        blob_list.append(word)\n",
    "        return blob_list\n",
    "ngram_textblob(sample['reviews'],2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ngrams_nltk(col, n):\n",
    "    for sentence in col:\n",
    "        ngram_list = []\n",
    "        grams = ngrams(sentence.split(),n)\n",
    "        for gram in grams:\n",
    "            print(gram)\n",
    "            \n",
    "        return ngram_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'split'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-e135a4cbbae7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m             \"Among the best premium wireless headphones. Must buy-product.\"]\n\u001b[1;32m      3\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0msixgrams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mngrams\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mlist1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mgrams\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msixgrams\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'split'"
     ]
    }
   ],
   "source": [
    "sentence = [\"Good looking average product by Honor. For 2000 bucks, it is really a good option to buy. Easy to use and looks durable\",\n",
    "            \"Among the best premium wireless headphones. Must buy-product.\"]\n",
    "n = 2\n",
    "sixgrams = ngrams(sentence.split(), n)\n",
    "list1 = []\n",
    "for grams in sixgrams:\n",
    "    list1.append(grams)\n",
    "print(list1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['I', 'am', 'a', 'good', 'boy'], ['Rahul', 'Gandhi', 'will', 'never', 'be', 'the', 'next', 'Prime', 'Minister'], ['APJ', 'Abdul', 'Kalam', 'was', 'an', 'Indian', 'scientist']]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'gensim' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-37911e572c23>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mbigram_phraser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPhraser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbigram\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mbigram\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgensim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPhrases\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_words\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_count\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# higher threshold fewer phrases.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mtrigram\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgensim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPhrases\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbigram\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdata_words\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'gensim' is not defined"
     ]
    }
   ],
   "source": [
    "documents = [\"I am a good boy\",\"Rahul Gandhi will never be the next Prime Minister\",\"APJ Abdul Kalam was an Indian scientist\"]\n",
    "\n",
    "sentence_stream = [doc.split(\" \") for doc in documents]\n",
    "print(sentence_stream)\n",
    "bigram = Phrases(sentence_stream, min_count=1, delimiter=b' ')\n",
    "\n",
    "bigram_phraser = Phraser(bigram)\n",
    "bigram = gensim.models.Phrases(data_words, min_count=1, threshold=10) # higher threshold fewer phrases.\n",
    "trigram = gensim.models.Phrases(bigram[data_words], threshold=100) \n",
    "\n",
    "bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
    "trigram_mod = gensim.models.phrases.Phraser(trigram)\n",
    "\n",
    "for sent in sentence_stream:\n",
    "    tokens_ = bigram_phraser[sent]\n",
    "    print(tokens_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
    "trigram_mod = gensim.models.phrases.Phraser(trigram)\n",
    "\n",
    "def make_bigrams(texts):\n",
    "    return [bigram_mod[doc] for doc in texts]\n",
    "\n",
    "def make_trigrams(texts):\n",
    "    return [trigram_mod[bigram_mod[doc]] for doc in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_polarity(col):\n",
    "    return TextBlob(col).sentiment.polarity\n",
    "def detect_subjectivity(col):\n",
    "    return TextBlob(col).sentiment.subjectivity\n",
    "def get_lemma(col):\n",
    "    lemma_list = []\n",
    "    text = TextBlob(col).words\n",
    "    for item in text:\n",
    "        lemma = Word(item).lemmatize()\n",
    "        lemma_list.append(lemma)\n",
    "    return lemma_list\n",
    "def detect_sentence_polarity(col):\n",
    "    scores = []\n",
    "    for sentences in TextBlob(col).sentences:\n",
    "        score = np.round(sentences.sentiment.polarity,2)\n",
    "        scores.append(score)\n",
    "    return scores\n",
    "def sentence_count(col_name, sign = 'total'):\n",
    "    count_list = []\n",
    "    for reviews in col_name:\n",
    "        total_count = len(sent_tokenize(reviews))\n",
    "        if sign == 'total':\n",
    "            count_list.append(total_count)\n",
    "        else:\n",
    "            count = 0\n",
    "            for sentence in sent_tokenize(reviews):\n",
    "                polarity = TextBlob(sentence).sentiment.polarity\n",
    "                if sign == 'positive' and polarity >= 0 :\n",
    "                    count += 1\n",
    "                elif sign == 'negative' and polarity <0 :\n",
    "                    count += 1\n",
    "            count_list.append(count)\n",
    "    return count_list \n",
    "\n",
    "def calc_percentage(col_name, sign = 'positive'):\n",
    "    count_list = []\n",
    "    for reviews in col_name:\n",
    "        total_count = len(sent_tokenize(reviews))\n",
    "        count = 0\n",
    "        for sentence in sent_tokenize(reviews):\n",
    "            polarity = TextBlob(sentence).sentiment.polarity\n",
    "            if sign == 'positive' and polarity >= 0 :\n",
    "                count += 1\n",
    "            elif sign == 'negative' and polarity <0 :\n",
    "                count += 1\n",
    "            percent = np.round((count/total_count)*100)\n",
    "        count_list.append(percent)\n",
    "    return count_list\n",
    "\n",
    "def negative_boolean(col):\n",
    "    value = 0\n",
    "    value_list = []\n",
    "    for sentence in col:\n",
    "        polarity = detect_polarity(sentence)\n",
    "        if polarity >= 0:\n",
    "            value = 0\n",
    "        else: \n",
    "            value = 1\n",
    "        value_list.append(value)\n",
    "    return value_list\n",
    "\n",
    "filter_method = lambda x:'Highly Positive' if x >= 0.5 else 'Fairly Positive' if (x > 0 and x < 0.5) else 'Highly Negative' if x <= -0.5 else 'Fairly Negative' if (x > -0.5 and x < 0) else 'Neutral'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample['polarity'] = round(sample.reviews.apply(detect_polarity),1)\n",
    "sample['subjectivity'] = round(sample.reviews.apply(detect_subjectivity),1)\n",
    "sample['sentiment'] = sample['polarity'].apply(filter_method)\n",
    "sample['sentence_sentiment'] = sample.reviews.apply(detect_sentence_polarity)\n",
    "sample['lemma'] = sample.reviews.apply(get_lemma)\n",
    "sample['#positive_sentences']= sentence_count(sample['reviews'], 'positive')\n",
    "sample['#negative_sentences'] = sentence_count(sample['reviews'], 'negative')\n",
    "sample['% positive_sentences'] = calc_percentage(sample['reviews'], 'positive')\n",
    "sample['% negative_sentences'] = calc_percentage(sample['reviews'], 'negative')\n",
    "sample['negation_or_not'] = negative_boolean(sample['reviews'])\n",
    "sample.head(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Polarity is float which lies within range of [-1,1]. Values closer to 1 have a highly positive sentiment and values closer to -1 have highly negative sentiment. Values closer to 0 on the either sides shows slighty positive and negative indication.\n",
    "\n",
    "Similarly, subjective sentences refer to personal opinion, emotion or judgement whereas objective refers to facts. Subjectivity is also a float which lies in the range of [0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample.sentiment.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "num_bins = 50\n",
    "plt.figure(figsize=(10,6))\n",
    "n, bins, patches = plt.hist(sample.sentiment, num_bins, facecolor='blue', alpha=0.5)\n",
    "plt.xlabel('Polarity')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Histogram of polarity')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x='sentiment', data=sample);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
