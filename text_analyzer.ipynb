{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#import plots\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "import string\n",
    "import logging\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.random.seed(0)\n",
    "import re\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import metrics\n",
    "\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import wordpunct_tokenize\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem import LancasterStemmer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.util import ngrams\n",
    "\n",
    "\n",
    "from collections import Counter\n",
    "from nltk.probability import FreqDist\n",
    "\n",
    "from sklearn.linear_model import LogisticRegressionCV,LogisticRegression\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "#TextBlob\n",
    "from textblob import TextBlob\n",
    "from textblob import Word\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'test pretty print which will be helpful for json and list variable'\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "pp.pprint(\"test pretty print which will be helpful for json and list variable\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asin</th>\n",
       "      <th>helpful</th>\n",
       "      <th>overall</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>summary</th>\n",
       "      <th>unixReviewTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B00000JBLH</td>\n",
       "      <td>[3, 4]</td>\n",
       "      <td>5</td>\n",
       "      <td>I bought my first HP12C in about 1984 or so, a...</td>\n",
       "      <td>09 3, 2004</td>\n",
       "      <td>A32T2H8150OJLU</td>\n",
       "      <td>ARH</td>\n",
       "      <td>A solid performer, and long time friend</td>\n",
       "      <td>1094169600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B00000JBLH</td>\n",
       "      <td>[7, 9]</td>\n",
       "      <td>5</td>\n",
       "      <td>WHY THIS BELATED REVIEW? I feel very obliged t...</td>\n",
       "      <td>12 15, 2007</td>\n",
       "      <td>A3MAFS04ZABRGO</td>\n",
       "      <td>Let it Be \"Alan\"</td>\n",
       "      <td>Price of GOLD is up, so don't bury the golden ...</td>\n",
       "      <td>1197676800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B00000JBLH</td>\n",
       "      <td>[3, 3]</td>\n",
       "      <td>2</td>\n",
       "      <td>I have an HP 48GX that has been kicking for mo...</td>\n",
       "      <td>01 1, 2011</td>\n",
       "      <td>A1F1A0QQP2XVH5</td>\n",
       "      <td>Mark B</td>\n",
       "      <td>Good functionality, but not durable like old HPs</td>\n",
       "      <td>1293840000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B00000JBLH</td>\n",
       "      <td>[7, 8]</td>\n",
       "      <td>5</td>\n",
       "      <td>I've started doing more finance stuff recently...</td>\n",
       "      <td>04 19, 2006</td>\n",
       "      <td>A49R5DBXXQDE5</td>\n",
       "      <td>R. D Johnson</td>\n",
       "      <td>One of the last of an almost extinct species</td>\n",
       "      <td>1145404800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B00000JBLH</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>5</td>\n",
       "      <td>For simple calculations and discounted cash fl...</td>\n",
       "      <td>08 4, 2013</td>\n",
       "      <td>A2XRMQA6PJ5ZJ8</td>\n",
       "      <td>Roger J. Buffington</td>\n",
       "      <td>Still the best</td>\n",
       "      <td>1375574400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         asin helpful  overall  \\\n",
       "0  B00000JBLH  [3, 4]        5   \n",
       "1  B00000JBLH  [7, 9]        5   \n",
       "2  B00000JBLH  [3, 3]        2   \n",
       "3  B00000JBLH  [7, 8]        5   \n",
       "4  B00000JBLH  [0, 0]        5   \n",
       "\n",
       "                                          reviewText   reviewTime  \\\n",
       "0  I bought my first HP12C in about 1984 or so, a...   09 3, 2004   \n",
       "1  WHY THIS BELATED REVIEW? I feel very obliged t...  12 15, 2007   \n",
       "2  I have an HP 48GX that has been kicking for mo...   01 1, 2011   \n",
       "3  I've started doing more finance stuff recently...  04 19, 2006   \n",
       "4  For simple calculations and discounted cash fl...   08 4, 2013   \n",
       "\n",
       "       reviewerID         reviewerName  \\\n",
       "0  A32T2H8150OJLU                  ARH   \n",
       "1  A3MAFS04ZABRGO     Let it Be \"Alan\"   \n",
       "2  A1F1A0QQP2XVH5               Mark B   \n",
       "3   A49R5DBXXQDE5         R. D Johnson   \n",
       "4  A2XRMQA6PJ5ZJ8  Roger J. Buffington   \n",
       "\n",
       "                                             summary  unixReviewTime  \n",
       "0            A solid performer, and long time friend      1094169600  \n",
       "1  Price of GOLD is up, so don't bury the golden ...      1197676800  \n",
       "2   Good functionality, but not durable like old HPs      1293840000  \n",
       "3       One of the last of an almost extinct species      1145404800  \n",
       "4                                     Still the best      1375574400  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=pd.read_json('reviews_Office_Products_5.json',lines=True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewText</th>\n",
       "      <th>overall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I bought my first HP12C in about 1984 or so, a...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WHY THIS BELATED REVIEW? I feel very obliged t...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I have an HP 48GX that has been kicking for mo...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I've started doing more finance stuff recently...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>For simple calculations and discounted cash fl...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          reviewText overall\n",
       "0  I bought my first HP12C in about 1984 or so, a...       5\n",
       "1  WHY THIS BELATED REVIEW? I feel very obliged t...       5\n",
       "2  I have an HP 48GX that has been kicking for mo...       2\n",
       "3  I've started doing more finance stuff recently...       5\n",
       "4  For simple calculations and discounted cash fl...       5"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['overall'] = data['overall'].astype(object) # fix datatype error\n",
    "dataset = {\"reviewText\": data[\"reviewText\"], \"overall\": data[\"overall\"]  }\n",
    "dataset = pd.DataFrame(data = dataset)\n",
    "dataset = dataset.dropna()\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "reviewText    object\n",
       "overall       object\n",
       "dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48198, 2)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['overall']=dataset['overall'].astype('int64')\n",
    "dataset = dataset[dataset[\"overall\"] != 3] # need datatype=object\n",
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewText</th>\n",
       "      <th>overall</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [reviewText, overall, label]\n",
       "Index: []"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"label\"] = dataset[\"overall\"].apply(lambda x : 1 if x > 3 else 0)\n",
    "dataset[dataset[\"label\"].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewText</th>\n",
       "      <th>overall</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I bought my first HP12C in about 1984 or so, a...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WHY THIS BELATED REVIEW? I feel very obliged t...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I have an HP 48GX that has been kicking for mo...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I've started doing more finance stuff recently...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>For simple calculations and discounted cash fl...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          reviewText  overall  label\n",
       "0  I bought my first HP12C in about 1984 or so, a...        5      1\n",
       "1  WHY THIS BELATED REVIEW? I feel very obliged t...        5      1\n",
       "2  I have an HP 48GX that has been kicking for mo...        2      0\n",
       "3  I've started doing more finance stuff recently...        5      1\n",
       "4  For simple calculations and discounted cash fl...        5      1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    45342\n",
       "0     2856\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5    30327\n",
       "4    15015\n",
       "2     1726\n",
       "1     1130\n",
       "Name: overall, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.overall.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "entire_dataset=dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# X = pd.DataFrame(entire_dataset, columns = [\"reviewText\",\"label\"])\n",
    "# y = pd.DataFrame(entire_dataset, columns = [\"label\"])\n",
    "\n",
    "# dataset , X_test , y_train , y_test = train_test_split(X, y, random_state=50,stratify=y,train_size=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words=set(stopwords.words(\"english\"))\n",
    "\n",
    "dataset['reviewText']=dataset['reviewText'].str.lower()\n",
    "\n",
    "dataset['sentence']=dataset['reviewText'].apply(lambda x: sent_tokenize(x))\n",
    "\n",
    "dataset['tokens']=dataset['reviewText'].apply(lambda x: word_tokenize(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hewy', 'are', 'qwerty']\n",
      "['hey', '?']\n"
     ]
    }
   ],
   "source": [
    "def get_clean_token_list(words):\n",
    "    clean_words=[]\n",
    "    for word in words:\n",
    "        flag=True\n",
    "        for letter in word:\n",
    "            if letter.isdigit() or letter in string.punctuation:\n",
    "                flag=False\n",
    "        if flag:\n",
    "            clean_words.append(word)\n",
    "    return clean_words\n",
    "\n",
    "print(get_clean_token_list([\"hewy\",\"ho!w\",\"are\",\"yo6u\",\"?dd\",\"111\",\"qwerty\"]))\n",
    "\n",
    "def remove_stopwords(words):\n",
    "    \"\"\"\n",
    "    pass series get series\n",
    "    \"\"\"\n",
    "    filtered_sent=[]\n",
    "    for word in words:\n",
    "        if word not in stop_words:\n",
    "            filtered_sent.append(word)\n",
    "    return filtered_sent\n",
    "\n",
    "\n",
    "print(remove_stopwords([\"hey\",\"how\",\"are\",\"you\",\"?\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [bought, first, hp12c, 1984, ,, served, faithf...\n",
       "1    [belated, review, ?, feel, obliged, share, vie...\n",
       "2    [hp, 48gx, kicking, twenty, years, hp, 11, 25,...\n",
       "3    ['ve, started, finance, stuff, recently, went,...\n",
       "4    [simple, calculations, discounted, cash, flows...\n",
       "Name: tokens, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['tokens']=dataset['tokens'].apply(remove_stopwords)\n",
    "\n",
    "dataset['tokens'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [bought, first, served, faithfully, lost, trav...\n",
       "1    [belated, review, feel, obliged, share, views,...\n",
       "2    [hp, kicking, twenty, years, hp, years, old, s...\n",
       "3    [started, finance, stuff, recently, went, look...\n",
       "4    [simple, calculations, discounted, cash, flows...\n",
       "Name: tokens, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['tokens']=dataset['tokens'].apply(get_clean_token_list)\n",
    "\n",
    "dataset['tokens'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "stem = PorterStemmer()\n",
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def stem_sentence(sentence):\n",
    "    stem_sentence=[]\n",
    "    for word in sentence:\n",
    "        stem_sentence.append(stem.stem(word))\n",
    "    return stem_sentence\n",
    "\n",
    "def lemmatize_sentence(sentence):\n",
    "    lem_sentence=[]\n",
    "    for word in sentence:\n",
    "        lem_sentence.append(wordnet_lemmatizer.lemmatize(word, pos=\"v\"))\n",
    "    return lem_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewText</th>\n",
       "      <th>overall</th>\n",
       "      <th>label</th>\n",
       "      <th>sentence</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i bought my first hp12c in about 1984 or so, a...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>[i bought my first hp12c in about 1984 or so, ...</td>\n",
       "      <td>[bought, first, served, faithfully, lost, trav...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>why this belated review? i feel very obliged t...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>[why this belated review?, i feel very obliged...</td>\n",
       "      <td>[belated, review, feel, obliged, share, views,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i have an hp 48gx that has been kicking for mo...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>[i have an hp 48gx that has been kicking for m...</td>\n",
       "      <td>[hp, kicking, twenty, years, hp, years, old, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i've started doing more finance stuff recently...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>[i've started doing more finance stuff recentl...</td>\n",
       "      <td>[started, finance, stuff, recently, went, look...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>for simple calculations and discounted cash fl...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>[for simple calculations and discounted cash f...</td>\n",
       "      <td>[simple, calculations, discounted, cash, flows...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          reviewText  overall  label  \\\n",
       "0  i bought my first hp12c in about 1984 or so, a...        5      1   \n",
       "1  why this belated review? i feel very obliged t...        5      1   \n",
       "2  i have an hp 48gx that has been kicking for mo...        2      0   \n",
       "3  i've started doing more finance stuff recently...        5      1   \n",
       "4  for simple calculations and discounted cash fl...        5      1   \n",
       "\n",
       "                                            sentence  \\\n",
       "0  [i bought my first hp12c in about 1984 or so, ...   \n",
       "1  [why this belated review?, i feel very obliged...   \n",
       "2  [i have an hp 48gx that has been kicking for m...   \n",
       "3  [i've started doing more finance stuff recentl...   \n",
       "4  [for simple calculations and discounted cash f...   \n",
       "\n",
       "                                              tokens  \n",
       "0  [bought, first, served, faithfully, lost, trav...  \n",
       "1  [belated, review, feel, obliged, share, views,...  \n",
       "2  [hp, kicking, twenty, years, hp, years, old, s...  \n",
       "3  [started, finance, stuff, recently, went, look...  \n",
       "4  [simple, calculations, discounted, cash, flows...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokens</th>\n",
       "      <th>lemm_sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[bought, first, served, faithfully, lost, trav...</td>\n",
       "      <td>[buy, first, serve, faithfully, lose, travel, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[belated, review, feel, obliged, share, views,...</td>\n",
       "      <td>[belated, review, feel, oblige, share, view, o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[hp, kicking, twenty, years, hp, years, old, s...</td>\n",
       "      <td>[hp, kick, twenty, years, hp, years, old, stil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[started, finance, stuff, recently, went, look...</td>\n",
       "      <td>[start, finance, stuff, recently, go, look, go...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[simple, calculations, discounted, cash, flows...</td>\n",
       "      <td>[simple, calculations, discount, cash, flow, o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[mba, hard, believe, calculator, learned, use,...</td>\n",
       "      <td>[mba, hard, believe, calculator, learn, use, u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[hp, ever, since, first, available, roughly, t...</td>\n",
       "      <td>[hp, ever, since, first, available, roughly, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[bought, boss, lost, loves, calculator, would,...</td>\n",
       "      <td>[buy, boss, lose, love, calculator, would, cat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[simple, calculator, handles, typical, math, l...</td>\n",
       "      <td>[simple, calculator, handle, typical, math, la...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[love, calculator, big, numbers, calculate, ex...</td>\n",
       "      <td>[love, calculator, big, number, calculate, exc...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              tokens  \\\n",
       "0  [bought, first, served, faithfully, lost, trav...   \n",
       "1  [belated, review, feel, obliged, share, views,...   \n",
       "2  [hp, kicking, twenty, years, hp, years, old, s...   \n",
       "3  [started, finance, stuff, recently, went, look...   \n",
       "4  [simple, calculations, discounted, cash, flows...   \n",
       "5  [mba, hard, believe, calculator, learned, use,...   \n",
       "6  [hp, ever, since, first, available, roughly, t...   \n",
       "7  [bought, boss, lost, loves, calculator, would,...   \n",
       "8  [simple, calculator, handles, typical, math, l...   \n",
       "9  [love, calculator, big, numbers, calculate, ex...   \n",
       "\n",
       "                                       lemm_sentence  \n",
       "0  [buy, first, serve, faithfully, lose, travel, ...  \n",
       "1  [belated, review, feel, oblige, share, view, o...  \n",
       "2  [hp, kick, twenty, years, hp, years, old, stil...  \n",
       "3  [start, finance, stuff, recently, go, look, go...  \n",
       "4  [simple, calculations, discount, cash, flow, o...  \n",
       "5  [mba, hard, believe, calculator, learn, use, u...  \n",
       "6  [hp, ever, since, first, available, roughly, t...  \n",
       "7  [buy, boss, lose, love, calculator, would, cat...  \n",
       "8  [simple, calculator, handle, typical, math, la...  \n",
       "9  [love, calculator, big, number, calculate, exc...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['stem_sentence']=dataset['tokens'].apply(lambda x: stem_sentence(x))\n",
    "\n",
    "dataset[['tokens','stem_sentence']].head(10)\n",
    "\n",
    "dataset['lemm_sentence']=dataset['tokens'].apply(lambda x: lemmatize_sentence(x))\n",
    "\n",
    "dataset[['tokens','lemm_sentence']].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewText</th>\n",
       "      <th>overall</th>\n",
       "      <th>label</th>\n",
       "      <th>sentence</th>\n",
       "      <th>tokens</th>\n",
       "      <th>stem_sentence</th>\n",
       "      <th>lemm_sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i bought my first hp12c in about 1984 or so, a...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>[i bought my first hp12c in about 1984 or so, ...</td>\n",
       "      <td>[bought, first, served, faithfully, lost, trav...</td>\n",
       "      <td>[bought, first, serv, faith, lost, travel, sea...</td>\n",
       "      <td>[buy, first, serve, faithfully, lose, travel, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>why this belated review? i feel very obliged t...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>[why this belated review?, i feel very obliged...</td>\n",
       "      <td>[belated, review, feel, obliged, share, views,...</td>\n",
       "      <td>[belat, review, feel, oblig, share, view, old,...</td>\n",
       "      <td>[belated, review, feel, oblige, share, view, o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i have an hp 48gx that has been kicking for mo...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>[i have an hp 48gx that has been kicking for m...</td>\n",
       "      <td>[hp, kicking, twenty, years, hp, years, old, s...</td>\n",
       "      <td>[hp, kick, twenti, year, hp, year, old, still,...</td>\n",
       "      <td>[hp, kick, twenty, years, hp, years, old, stil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i've started doing more finance stuff recently...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>[i've started doing more finance stuff recentl...</td>\n",
       "      <td>[started, finance, stuff, recently, went, look...</td>\n",
       "      <td>[start, financ, stuff, recent, went, look, goo...</td>\n",
       "      <td>[start, finance, stuff, recently, go, look, go...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>for simple calculations and discounted cash fl...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>[for simple calculations and discounted cash f...</td>\n",
       "      <td>[simple, calculations, discounted, cash, flows...</td>\n",
       "      <td>[simpl, calcul, discount, cash, flow, one, sti...</td>\n",
       "      <td>[simple, calculations, discount, cash, flow, o...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          reviewText  overall  label  \\\n",
       "0  i bought my first hp12c in about 1984 or so, a...        5      1   \n",
       "1  why this belated review? i feel very obliged t...        5      1   \n",
       "2  i have an hp 48gx that has been kicking for mo...        2      0   \n",
       "3  i've started doing more finance stuff recently...        5      1   \n",
       "4  for simple calculations and discounted cash fl...        5      1   \n",
       "\n",
       "                                            sentence  \\\n",
       "0  [i bought my first hp12c in about 1984 or so, ...   \n",
       "1  [why this belated review?, i feel very obliged...   \n",
       "2  [i have an hp 48gx that has been kicking for m...   \n",
       "3  [i've started doing more finance stuff recentl...   \n",
       "4  [for simple calculations and discounted cash f...   \n",
       "\n",
       "                                              tokens  \\\n",
       "0  [bought, first, served, faithfully, lost, trav...   \n",
       "1  [belated, review, feel, obliged, share, views,...   \n",
       "2  [hp, kicking, twenty, years, hp, years, old, s...   \n",
       "3  [started, finance, stuff, recently, went, look...   \n",
       "4  [simple, calculations, discounted, cash, flows...   \n",
       "\n",
       "                                       stem_sentence  \\\n",
       "0  [bought, first, serv, faith, lost, travel, sea...   \n",
       "1  [belat, review, feel, oblig, share, view, old,...   \n",
       "2  [hp, kick, twenti, year, hp, year, old, still,...   \n",
       "3  [start, financ, stuff, recent, went, look, goo...   \n",
       "4  [simpl, calcul, discount, cash, flow, one, sti...   \n",
       "\n",
       "                                       lemm_sentence  \n",
       "0  [buy, first, serve, faithfully, lose, travel, ...  \n",
       "1  [belated, review, feel, oblige, share, view, o...  \n",
       "2  [hp, kick, twenty, years, hp, years, old, stil...  \n",
       "3  [start, finance, stuff, recently, go, look, go...  \n",
       "4  [simple, calculations, discount, cash, flow, o...  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('use', 61375),\n",
       " ('print', 30238),\n",
       " ('printer', 29298),\n",
       " ('one', 27926),\n",
       " ('paper', 26963),\n",
       " ('like', 26040),\n",
       " ('work', 24809),\n",
       " ('get', 24176),\n",
       " ('make', 22934),\n",
       " ('label', 21503)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews=[word for review in dataset['lemm_sentence'] for word in review]\n",
    "\n",
    "fdist_reviews = FreqDist(reviews)\n",
    "\n",
    "fdist_reviews.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('use', 58058),\n",
       " ('print', 28033),\n",
       " ('printer', 26633),\n",
       " ('one', 25759),\n",
       " ('paper', 25196),\n",
       " ('like', 24400),\n",
       " ('work', 22932),\n",
       " ('get', 21847),\n",
       " ('make', 21464),\n",
       " ('label', 20859)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive_reviews=dataset[dataset['label']==1]['lemm_sentence']\n",
    "\n",
    "positive_tokens=[word for review in positive_reviews for word in review]\n",
    "\n",
    "fdist_positive_tokens = FreqDist(positive_tokens)\n",
    "\n",
    "fdist_positive_tokens.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('use', 3317),\n",
       " ('printer', 2665),\n",
       " ('get', 2329),\n",
       " ('print', 2205),\n",
       " ('one', 2167),\n",
       " ('would', 1954),\n",
       " ('work', 1877),\n",
       " ('paper', 1767),\n",
       " ('ink', 1652),\n",
       " ('like', 1640)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "negative_reviews=dataset[dataset['label']==0]['lemm_sentence']\n",
    "\n",
    "negative_reviews=[word for review in negative_reviews for word in review]\n",
    "\n",
    "fdist_neagtive_tokens = FreqDist(negative_reviews)\n",
    "\n",
    "fdist_neagtive_tokens.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10454"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(fdist_neagtive_tokens.most_common())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32915"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(fdist_positive_tokens.most_common())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequency_tokens={ x[0]:x[1] for x in fdist_positive_tokens.most_common()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [(bought, VBD), (first, RB), (served, VBN), (f...\n",
       "1    [(belated, VBN), (review, NN), (feel, NN), (ob...\n",
       "2    [(hp, NN), (kicking, VBG), (twenty, CD), (year...\n",
       "3    [(started, VBN), (finance, NN), (stuff, NN), (...\n",
       "4    [(simple, JJ), (calculations, NNS), (discounte...\n",
       "Name: pos_tag, dtype: object"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['pos_tag']=dataset['tokens'].apply(lambda x: nltk.pos_tag(x))\n",
    "\n",
    "dataset['pos_tag'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewText</th>\n",
       "      <th>overall</th>\n",
       "      <th>label</th>\n",
       "      <th>sentence</th>\n",
       "      <th>tokens</th>\n",
       "      <th>stem_sentence</th>\n",
       "      <th>lemm_sentence</th>\n",
       "      <th>pos_tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i bought my first hp12c in about 1984 or so, a...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>[i bought my first hp12c in about 1984 or so, ...</td>\n",
       "      <td>[bought, first, served, faithfully, lost, trav...</td>\n",
       "      <td>[bought, first, serv, faith, lost, travel, sea...</td>\n",
       "      <td>[buy, first, serve, faithfully, lose, travel, ...</td>\n",
       "      <td>[(bought, VBD), (first, RB), (served, VBN), (f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>why this belated review? i feel very obliged t...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>[why this belated review?, i feel very obliged...</td>\n",
       "      <td>[belated, review, feel, obliged, share, views,...</td>\n",
       "      <td>[belat, review, feel, oblig, share, view, old,...</td>\n",
       "      <td>[belated, review, feel, oblige, share, view, o...</td>\n",
       "      <td>[(belated, VBN), (review, NN), (feel, NN), (ob...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i have an hp 48gx that has been kicking for mo...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>[i have an hp 48gx that has been kicking for m...</td>\n",
       "      <td>[hp, kicking, twenty, years, hp, years, old, s...</td>\n",
       "      <td>[hp, kick, twenti, year, hp, year, old, still,...</td>\n",
       "      <td>[hp, kick, twenty, years, hp, years, old, stil...</td>\n",
       "      <td>[(hp, NN), (kicking, VBG), (twenty, CD), (year...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i've started doing more finance stuff recently...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>[i've started doing more finance stuff recentl...</td>\n",
       "      <td>[started, finance, stuff, recently, went, look...</td>\n",
       "      <td>[start, financ, stuff, recent, went, look, goo...</td>\n",
       "      <td>[start, finance, stuff, recently, go, look, go...</td>\n",
       "      <td>[(started, VBN), (finance, NN), (stuff, NN), (...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>for simple calculations and discounted cash fl...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>[for simple calculations and discounted cash f...</td>\n",
       "      <td>[simple, calculations, discounted, cash, flows...</td>\n",
       "      <td>[simpl, calcul, discount, cash, flow, one, sti...</td>\n",
       "      <td>[simple, calculations, discount, cash, flow, o...</td>\n",
       "      <td>[(simple, JJ), (calculations, NNS), (discounte...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          reviewText  overall  label  \\\n",
       "0  i bought my first hp12c in about 1984 or so, a...        5      1   \n",
       "1  why this belated review? i feel very obliged t...        5      1   \n",
       "2  i have an hp 48gx that has been kicking for mo...        2      0   \n",
       "3  i've started doing more finance stuff recently...        5      1   \n",
       "4  for simple calculations and discounted cash fl...        5      1   \n",
       "\n",
       "                                            sentence  \\\n",
       "0  [i bought my first hp12c in about 1984 or so, ...   \n",
       "1  [why this belated review?, i feel very obliged...   \n",
       "2  [i have an hp 48gx that has been kicking for m...   \n",
       "3  [i've started doing more finance stuff recentl...   \n",
       "4  [for simple calculations and discounted cash f...   \n",
       "\n",
       "                                              tokens  \\\n",
       "0  [bought, first, served, faithfully, lost, trav...   \n",
       "1  [belated, review, feel, obliged, share, views,...   \n",
       "2  [hp, kicking, twenty, years, hp, years, old, s...   \n",
       "3  [started, finance, stuff, recently, went, look...   \n",
       "4  [simple, calculations, discounted, cash, flows...   \n",
       "\n",
       "                                       stem_sentence  \\\n",
       "0  [bought, first, serv, faith, lost, travel, sea...   \n",
       "1  [belat, review, feel, oblig, share, view, old,...   \n",
       "2  [hp, kick, twenti, year, hp, year, old, still,...   \n",
       "3  [start, financ, stuff, recent, went, look, goo...   \n",
       "4  [simpl, calcul, discount, cash, flow, one, sti...   \n",
       "\n",
       "                                       lemm_sentence  \\\n",
       "0  [buy, first, serve, faithfully, lose, travel, ...   \n",
       "1  [belated, review, feel, oblige, share, view, o...   \n",
       "2  [hp, kick, twenty, years, hp, years, old, stil...   \n",
       "3  [start, finance, stuff, recently, go, look, go...   \n",
       "4  [simple, calculations, discount, cash, flow, o...   \n",
       "\n",
       "                                             pos_tag  \n",
       "0  [(bought, VBD), (first, RB), (served, VBN), (f...  \n",
       "1  [(belated, VBN), (review, NN), (feel, NN), (ob...  \n",
       "2  [(hp, NN), (kicking, VBG), (twenty, CD), (year...  \n",
       "3  [(started, VBN), (finance, NN), (stuff, NN), (...  \n",
       "4  [(simple, JJ), (calculations, NNS), (discounte...  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['asked', 'review', 'scale']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# keep only noun adjective and adverb\n",
    "keep_tags=[\"JJ\",\"JJR\",\"JJS\",\"RB\",\"RBR\",\"RBS\",\"UH\",\"NN\",\"NNS\",\"NNP\",\"NNPS\"]\n",
    "\n",
    "def filter_tag(pos_list):\n",
    "    pos_clean_list=[]\n",
    "    for t in pos_list:\n",
    "        if t[1] in keep_tags:\n",
    "            pos_clean_list.append(t[0])\n",
    "    return pos_clean_list\n",
    "\n",
    "filter_tag([('asked', 'RB'), ('review', 'NN'), ('scale', 'RBS')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokens</th>\n",
       "      <th>filter_pos_tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[bought, first, served, faithfully, lost, trav...</td>\n",
       "      <td>[first, faithfully, travelling, difficult, com...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[belated, review, feel, obliged, share, views,...</td>\n",
       "      <td>[review, feel, share, views, old, workhorse, g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[hp, kicking, twenty, years, hp, years, old, s...</td>\n",
       "      <td>[hp, years, years, old, still, flawless, month...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[started, finance, stuff, recently, went, look...</td>\n",
       "      <td>[finance, stuff, recently, good, calculator, p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[simple, calculations, discounted, cash, flows...</td>\n",
       "      <td>[simple, calculations, cash, flows, still, bes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[mba, hard, believe, calculator, learned, use,...</td>\n",
       "      <td>[mba, hard, calculator, use, undergraduate, bu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[hp, ever, since, first, available, roughly, t...</td>\n",
       "      <td>[hp, ever, first, available, roughly, years, a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[bought, boss, lost, loves, calculator, would,...</td>\n",
       "      <td>[boss, loves, calculator, really, helps, day, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[simple, calculator, handles, typical, math, l...</td>\n",
       "      <td>[simple, calculator, handles, typical, math, l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[love, calculator, big, numbers, calculate, ex...</td>\n",
       "      <td>[love, calculator, big, numbers, excellent, ea...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              tokens  \\\n",
       "0  [bought, first, served, faithfully, lost, trav...   \n",
       "1  [belated, review, feel, obliged, share, views,...   \n",
       "2  [hp, kicking, twenty, years, hp, years, old, s...   \n",
       "3  [started, finance, stuff, recently, went, look...   \n",
       "4  [simple, calculations, discounted, cash, flows...   \n",
       "5  [mba, hard, believe, calculator, learned, use,...   \n",
       "6  [hp, ever, since, first, available, roughly, t...   \n",
       "7  [bought, boss, lost, loves, calculator, would,...   \n",
       "8  [simple, calculator, handles, typical, math, l...   \n",
       "9  [love, calculator, big, numbers, calculate, ex...   \n",
       "\n",
       "                                      filter_pos_tag  \n",
       "0  [first, faithfully, travelling, difficult, com...  \n",
       "1  [review, feel, share, views, old, workhorse, g...  \n",
       "2  [hp, years, years, old, still, flawless, month...  \n",
       "3  [finance, stuff, recently, good, calculator, p...  \n",
       "4  [simple, calculations, cash, flows, still, bes...  \n",
       "5  [mba, hard, calculator, use, undergraduate, bu...  \n",
       "6  [hp, ever, first, available, roughly, years, a...  \n",
       "7  [boss, loves, calculator, really, helps, day, ...  \n",
       "8  [simple, calculator, handles, typical, math, l...  \n",
       "9  [love, calculator, big, numbers, excellent, ea...  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['filter_pos_tag']=dataset['pos_tag'].apply(filter_tag)\n",
    "\n",
    "dataset[['tokens','filter_pos_tag']].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['clean_sentence']=dataset['filter_pos_tag'].apply(lambda x: ' '.join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewText</th>\n",
       "      <th>overall</th>\n",
       "      <th>label</th>\n",
       "      <th>sentence</th>\n",
       "      <th>tokens</th>\n",
       "      <th>stem_sentence</th>\n",
       "      <th>lemm_sentence</th>\n",
       "      <th>pos_tag</th>\n",
       "      <th>filter_pos_tag</th>\n",
       "      <th>clean_sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i bought my first hp12c in about 1984 or so, a...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>[i bought my first hp12c in about 1984 or so, ...</td>\n",
       "      <td>[bought, first, served, faithfully, lost, trav...</td>\n",
       "      <td>[bought, first, serv, faith, lost, travel, sea...</td>\n",
       "      <td>[buy, first, serve, faithfully, lose, travel, ...</td>\n",
       "      <td>[(bought, VBD), (first, RB), (served, VBN), (f...</td>\n",
       "      <td>[first, faithfully, travelling, difficult, com...</td>\n",
       "      <td>first faithfully travelling difficult come are...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>why this belated review? i feel very obliged t...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>[why this belated review?, i feel very obliged...</td>\n",
       "      <td>[belated, review, feel, obliged, share, views,...</td>\n",
       "      <td>[belat, review, feel, oblig, share, view, old,...</td>\n",
       "      <td>[belated, review, feel, oblige, share, view, o...</td>\n",
       "      <td>[(belated, VBN), (review, NN), (feel, NN), (ob...</td>\n",
       "      <td>[review, feel, share, views, old, workhorse, g...</td>\n",
       "      <td>review feel share views old workhorse gold ann...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i have an hp 48gx that has been kicking for mo...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>[i have an hp 48gx that has been kicking for m...</td>\n",
       "      <td>[hp, kicking, twenty, years, hp, years, old, s...</td>\n",
       "      <td>[hp, kick, twenti, year, hp, year, old, still,...</td>\n",
       "      <td>[hp, kick, twenty, years, hp, years, old, stil...</td>\n",
       "      <td>[(hp, NN), (kicking, VBG), (twenty, CD), (year...</td>\n",
       "      <td>[hp, years, years, old, still, flawless, month...</td>\n",
       "      <td>hp years years old still flawless months numbe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i've started doing more finance stuff recently...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>[i've started doing more finance stuff recentl...</td>\n",
       "      <td>[started, finance, stuff, recently, went, look...</td>\n",
       "      <td>[start, financ, stuff, recent, went, look, goo...</td>\n",
       "      <td>[start, finance, stuff, recently, go, look, go...</td>\n",
       "      <td>[(started, VBN), (finance, NN), (stuff, NN), (...</td>\n",
       "      <td>[finance, stuff, recently, good, calculator, p...</td>\n",
       "      <td>finance stuff recently good calculator pleasan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>for simple calculations and discounted cash fl...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>[for simple calculations and discounted cash f...</td>\n",
       "      <td>[simple, calculations, discounted, cash, flows...</td>\n",
       "      <td>[simpl, calcul, discount, cash, flow, one, sti...</td>\n",
       "      <td>[simple, calculations, discount, cash, flow, o...</td>\n",
       "      <td>[(simple, JJ), (calculations, NNS), (discounte...</td>\n",
       "      <td>[simple, calculations, cash, flows, still, bes...</td>\n",
       "      <td>simple calculations cash flows still best used...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          reviewText  overall  label  \\\n",
       "0  i bought my first hp12c in about 1984 or so, a...        5      1   \n",
       "1  why this belated review? i feel very obliged t...        5      1   \n",
       "2  i have an hp 48gx that has been kicking for mo...        2      0   \n",
       "3  i've started doing more finance stuff recently...        5      1   \n",
       "4  for simple calculations and discounted cash fl...        5      1   \n",
       "\n",
       "                                            sentence  \\\n",
       "0  [i bought my first hp12c in about 1984 or so, ...   \n",
       "1  [why this belated review?, i feel very obliged...   \n",
       "2  [i have an hp 48gx that has been kicking for m...   \n",
       "3  [i've started doing more finance stuff recentl...   \n",
       "4  [for simple calculations and discounted cash f...   \n",
       "\n",
       "                                              tokens  \\\n",
       "0  [bought, first, served, faithfully, lost, trav...   \n",
       "1  [belated, review, feel, obliged, share, views,...   \n",
       "2  [hp, kicking, twenty, years, hp, years, old, s...   \n",
       "3  [started, finance, stuff, recently, went, look...   \n",
       "4  [simple, calculations, discounted, cash, flows...   \n",
       "\n",
       "                                       stem_sentence  \\\n",
       "0  [bought, first, serv, faith, lost, travel, sea...   \n",
       "1  [belat, review, feel, oblig, share, view, old,...   \n",
       "2  [hp, kick, twenti, year, hp, year, old, still,...   \n",
       "3  [start, financ, stuff, recent, went, look, goo...   \n",
       "4  [simpl, calcul, discount, cash, flow, one, sti...   \n",
       "\n",
       "                                       lemm_sentence  \\\n",
       "0  [buy, first, serve, faithfully, lose, travel, ...   \n",
       "1  [belated, review, feel, oblige, share, view, o...   \n",
       "2  [hp, kick, twenty, years, hp, years, old, stil...   \n",
       "3  [start, finance, stuff, recently, go, look, go...   \n",
       "4  [simple, calculations, discount, cash, flow, o...   \n",
       "\n",
       "                                             pos_tag  \\\n",
       "0  [(bought, VBD), (first, RB), (served, VBN), (f...   \n",
       "1  [(belated, VBN), (review, NN), (feel, NN), (ob...   \n",
       "2  [(hp, NN), (kicking, VBG), (twenty, CD), (year...   \n",
       "3  [(started, VBN), (finance, NN), (stuff, NN), (...   \n",
       "4  [(simple, JJ), (calculations, NNS), (discounte...   \n",
       "\n",
       "                                      filter_pos_tag  \\\n",
       "0  [first, faithfully, travelling, difficult, com...   \n",
       "1  [review, feel, share, views, old, workhorse, g...   \n",
       "2  [hp, years, years, old, still, flawless, month...   \n",
       "3  [finance, stuff, recently, good, calculator, p...   \n",
       "4  [simple, calculations, cash, flows, still, bes...   \n",
       "\n",
       "                                      clean_sentence  \n",
       "0  first faithfully travelling difficult come are...  \n",
       "1  review feel share views old workhorse gold ann...  \n",
       "2  hp years years old still flawless months numbe...  \n",
       "3  finance stuff recently good calculator pleasan...  \n",
       "4  simple calculations cash flows still best used...  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_polarity(col):\n",
    "    return TextBlob(col).sentiment.polarity\n",
    "\n",
    "def detect_subjectivity(col):\n",
    "    return TextBlob(col).sentiment.subjectivity\n",
    "\n",
    "def get_lemma(col):\n",
    "    lemma_list = []\n",
    "    text = TextBlob(col).words\n",
    "    for item in text:\n",
    "        lemma = Word(item).lemmatize()\n",
    "        lemma_list.append(lemma)\n",
    "    return lemma_list\n",
    "\n",
    "def detect_sentence_polarity(col):\n",
    "    scores = []\n",
    "    for sentences in TextBlob(col).sentences:\n",
    "        score = np.round(sentences.sentiment.polarity,2)\n",
    "        scores.append(score)\n",
    "    return scores\n",
    "\n",
    "def sentence_count(col_name, sign = 'total'):\n",
    "    # TODO : OPTIMIZE this\n",
    "    count_list = []\n",
    "    for reviews in col_name:\n",
    "        total_count = len(reviews)\n",
    "        if sign == 'total':\n",
    "            count_list.append(total_count)\n",
    "        else:\n",
    "            count = 0\n",
    "            for polarity in reviews:\n",
    "                if sign == 'positive' and polarity >= 0.2 :\n",
    "                    count += 1\n",
    "                elif sign == 'neutral' and polarity >=0 and polarity<0.2:\n",
    "                    count += 1\n",
    "                elif sign == 'negative' and polarity <0 :\n",
    "                    count += 1\n",
    "            count_list.append(count)\n",
    "    return count_list \n",
    "\n",
    "\n",
    "\n",
    "def negative_boolean(col):\n",
    "    value = 0\n",
    "    value_list = []\n",
    "    for sentence in col:\n",
    "        polarity = detect_polarity(sentence)\n",
    "        if polarity < 0:\n",
    "            value = 1\n",
    "        else: \n",
    "            value = 0\n",
    "        value_list.append(value)\n",
    "    return value_list\n",
    "\n",
    "filter_method = lambda x:'Highly Positive' if x >= 0.5 else 'Fairly Positive' if (x > 0 and x < 0.5) else 'Highly Negative' if x <= -0.5 else 'Fairly Negative' if (x > -0.5 and x < 0) else 'Neutral'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewText</th>\n",
       "      <th>overall</th>\n",
       "      <th>label</th>\n",
       "      <th>sentence</th>\n",
       "      <th>tokens</th>\n",
       "      <th>stem_sentence</th>\n",
       "      <th>lemm_sentence</th>\n",
       "      <th>pos_tag</th>\n",
       "      <th>filter_pos_tag</th>\n",
       "      <th>clean_sentence</th>\n",
       "      <th>sentence_sentiment</th>\n",
       "      <th>#positive_sentences</th>\n",
       "      <th>#negative_sentences</th>\n",
       "      <th>#neutral_sentences</th>\n",
       "      <th>% positive_sentences</th>\n",
       "      <th>% negative_sentences</th>\n",
       "      <th>% neutral_sentences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i bought my first hp12c in about 1984 or so, a...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>[i bought my first hp12c in about 1984 or so, ...</td>\n",
       "      <td>[bought, first, served, faithfully, lost, trav...</td>\n",
       "      <td>[bought, first, serv, faith, lost, travel, sea...</td>\n",
       "      <td>[buy, first, serve, faithfully, lose, travel, ...</td>\n",
       "      <td>[(bought, VBD), (first, RB), (served, VBN), (f...</td>\n",
       "      <td>[first, faithfully, travelling, difficult, com...</td>\n",
       "      <td>first faithfully travelling difficult come are...</td>\n",
       "      <td>[0.25, -0.5, 0.0, 0.0, 0.42, 0.19, 0.0, 0.25, ...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>30.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>60.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>why this belated review? i feel very obliged t...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>[why this belated review?, i feel very obliged...</td>\n",
       "      <td>[belated, review, feel, obliged, share, views,...</td>\n",
       "      <td>[belat, review, feel, oblig, share, view, old,...</td>\n",
       "      <td>[belated, review, feel, oblige, share, view, o...</td>\n",
       "      <td>[(belated, VBN), (review, NN), (feel, NN), (ob...</td>\n",
       "      <td>[review, feel, share, views, old, workhorse, g...</td>\n",
       "      <td>review feel share views old workhorse gold ann...</td>\n",
       "      <td>[0.0, 0.27, 0.0, 0.18, 0.7, -0.03, 0.08, 0.4, ...</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>44.44</td>\n",
       "      <td>5.56</td>\n",
       "      <td>50.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i have an hp 48gx that has been kicking for mo...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>[i have an hp 48gx that has been kicking for m...</td>\n",
       "      <td>[hp, kicking, twenty, years, hp, years, old, s...</td>\n",
       "      <td>[hp, kick, twenti, year, hp, year, old, still,...</td>\n",
       "      <td>[hp, kick, twenty, years, hp, years, old, stil...</td>\n",
       "      <td>[(hp, NN), (kicking, VBG), (twenty, CD), (year...</td>\n",
       "      <td>[hp, years, years, old, still, flawless, month...</td>\n",
       "      <td>hp years years old still flawless months numbe...</td>\n",
       "      <td>[0.52, -0.16, 0.0, 0.07, 0.15, 0.6, 0.17, -0.35]</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>25.00</td>\n",
       "      <td>25.00</td>\n",
       "      <td>50.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i've started doing more finance stuff recently...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>[i've started doing more finance stuff recentl...</td>\n",
       "      <td>[started, finance, stuff, recently, went, look...</td>\n",
       "      <td>[start, financ, stuff, recent, went, look, goo...</td>\n",
       "      <td>[start, finance, stuff, recently, go, look, go...</td>\n",
       "      <td>[(started, VBN), (finance, NN), (stuff, NN), (...</td>\n",
       "      <td>[finance, stuff, recently, good, calculator, p...</td>\n",
       "      <td>finance stuff recently good calculator pleasan...</td>\n",
       "      <td>[0.4, 0.25, 0.8, 0.38, 0.2, 0.0, 0.25, 0.35, 0...</td>\n",
       "      <td>25</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>59.52</td>\n",
       "      <td>11.90</td>\n",
       "      <td>28.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>for simple calculations and discounted cash fl...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>[for simple calculations and discounted cash f...</td>\n",
       "      <td>[simple, calculations, discounted, cash, flows...</td>\n",
       "      <td>[simpl, calcul, discount, cash, flow, one, sti...</td>\n",
       "      <td>[simple, calculations, discount, cash, flow, o...</td>\n",
       "      <td>[(simple, JJ), (calculations, NNS), (discounte...</td>\n",
       "      <td>[simple, calculations, cash, flows, still, bes...</td>\n",
       "      <td>simple calculations cash flows still best used...</td>\n",
       "      <td>[0.5, 0.0, 0.18, 0.5, 0.72, 0.0, 0.0, 0.0]</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>37.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>62.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>while i don't have an mba, it's hard to believ...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>[while i don't have an mba, it's hard to belie...</td>\n",
       "      <td>[mba, hard, believe, calculator, learned, use,...</td>\n",
       "      <td>[mba, hard, believ, calcul, learn, use, underg...</td>\n",
       "      <td>[mba, hard, believe, calculator, learn, use, u...</td>\n",
       "      <td>[(mba, RB), (hard, JJ), (believe, VBP), (calcu...</td>\n",
       "      <td>[mba, hard, calculator, use, undergraduate, bu...</td>\n",
       "      <td>mba hard calculator use undergraduate business...</td>\n",
       "      <td>[0.01, 0.1, 0.17, 0.03, -0.02, 0.07, 0.0]</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0.00</td>\n",
       "      <td>14.29</td>\n",
       "      <td>85.71</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          reviewText  overall  label  \\\n",
       "0  i bought my first hp12c in about 1984 or so, a...        5      1   \n",
       "1  why this belated review? i feel very obliged t...        5      1   \n",
       "2  i have an hp 48gx that has been kicking for mo...        2      0   \n",
       "3  i've started doing more finance stuff recently...        5      1   \n",
       "4  for simple calculations and discounted cash fl...        5      1   \n",
       "5  while i don't have an mba, it's hard to believ...        5      1   \n",
       "\n",
       "                                            sentence  \\\n",
       "0  [i bought my first hp12c in about 1984 or so, ...   \n",
       "1  [why this belated review?, i feel very obliged...   \n",
       "2  [i have an hp 48gx that has been kicking for m...   \n",
       "3  [i've started doing more finance stuff recentl...   \n",
       "4  [for simple calculations and discounted cash f...   \n",
       "5  [while i don't have an mba, it's hard to belie...   \n",
       "\n",
       "                                              tokens  \\\n",
       "0  [bought, first, served, faithfully, lost, trav...   \n",
       "1  [belated, review, feel, obliged, share, views,...   \n",
       "2  [hp, kicking, twenty, years, hp, years, old, s...   \n",
       "3  [started, finance, stuff, recently, went, look...   \n",
       "4  [simple, calculations, discounted, cash, flows...   \n",
       "5  [mba, hard, believe, calculator, learned, use,...   \n",
       "\n",
       "                                       stem_sentence  \\\n",
       "0  [bought, first, serv, faith, lost, travel, sea...   \n",
       "1  [belat, review, feel, oblig, share, view, old,...   \n",
       "2  [hp, kick, twenti, year, hp, year, old, still,...   \n",
       "3  [start, financ, stuff, recent, went, look, goo...   \n",
       "4  [simpl, calcul, discount, cash, flow, one, sti...   \n",
       "5  [mba, hard, believ, calcul, learn, use, underg...   \n",
       "\n",
       "                                       lemm_sentence  \\\n",
       "0  [buy, first, serve, faithfully, lose, travel, ...   \n",
       "1  [belated, review, feel, oblige, share, view, o...   \n",
       "2  [hp, kick, twenty, years, hp, years, old, stil...   \n",
       "3  [start, finance, stuff, recently, go, look, go...   \n",
       "4  [simple, calculations, discount, cash, flow, o...   \n",
       "5  [mba, hard, believe, calculator, learn, use, u...   \n",
       "\n",
       "                                             pos_tag  \\\n",
       "0  [(bought, VBD), (first, RB), (served, VBN), (f...   \n",
       "1  [(belated, VBN), (review, NN), (feel, NN), (ob...   \n",
       "2  [(hp, NN), (kicking, VBG), (twenty, CD), (year...   \n",
       "3  [(started, VBN), (finance, NN), (stuff, NN), (...   \n",
       "4  [(simple, JJ), (calculations, NNS), (discounte...   \n",
       "5  [(mba, RB), (hard, JJ), (believe, VBP), (calcu...   \n",
       "\n",
       "                                      filter_pos_tag  \\\n",
       "0  [first, faithfully, travelling, difficult, com...   \n",
       "1  [review, feel, share, views, old, workhorse, g...   \n",
       "2  [hp, years, years, old, still, flawless, month...   \n",
       "3  [finance, stuff, recently, good, calculator, p...   \n",
       "4  [simple, calculations, cash, flows, still, bes...   \n",
       "5  [mba, hard, calculator, use, undergraduate, bu...   \n",
       "\n",
       "                                      clean_sentence  \\\n",
       "0  first faithfully travelling difficult come are...   \n",
       "1  review feel share views old workhorse gold ann...   \n",
       "2  hp years years old still flawless months numbe...   \n",
       "3  finance stuff recently good calculator pleasan...   \n",
       "4  simple calculations cash flows still best used...   \n",
       "5  mba hard calculator use undergraduate business...   \n",
       "\n",
       "                                  sentence_sentiment  #positive_sentences  \\\n",
       "0  [0.25, -0.5, 0.0, 0.0, 0.42, 0.19, 0.0, 0.25, ...                    3   \n",
       "1  [0.0, 0.27, 0.0, 0.18, 0.7, -0.03, 0.08, 0.4, ...                    8   \n",
       "2   [0.52, -0.16, 0.0, 0.07, 0.15, 0.6, 0.17, -0.35]                    2   \n",
       "3  [0.4, 0.25, 0.8, 0.38, 0.2, 0.0, 0.25, 0.35, 0...                   25   \n",
       "4         [0.5, 0.0, 0.18, 0.5, 0.72, 0.0, 0.0, 0.0]                    3   \n",
       "5          [0.01, 0.1, 0.17, 0.03, -0.02, 0.07, 0.0]                    0   \n",
       "\n",
       "   #negative_sentences  #neutral_sentences  % positive_sentences  \\\n",
       "0                    1                   6                 30.00   \n",
       "1                    1                   9                 44.44   \n",
       "2                    2                   4                 25.00   \n",
       "3                    5                  12                 59.52   \n",
       "4                    0                   5                 37.50   \n",
       "5                    1                   6                  0.00   \n",
       "\n",
       "   % negative_sentences  % neutral_sentences  \n",
       "0                 10.00                60.00  \n",
       "1                  5.56                50.00  \n",
       "2                 25.00                50.00  \n",
       "3                 11.90                28.57  \n",
       "4                  0.00                62.50  \n",
       "5                 14.29                85.71  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dataset['polarity'] = round(dataset.reviewText.apply(detect_polarity),1)\n",
    "# dataset['subjectivity'] = round(dataset.reviewText.apply(detect_subjectivity),1)\n",
    "# dataset['sentiment'] = dataset['polarity'].apply(filter_method)\n",
    "# dataset['lemma'] = dataset.reviewText.apply(get_lemma)\n",
    "\n",
    "dataset['sentence_sentiment'] = dataset.reviewText.apply(detect_sentence_polarity)\n",
    "\n",
    "dataset['#positive_sentences'] = sentence_count(dataset['sentence_sentiment'], 'positive')\n",
    "dataset['#negative_sentences'] = sentence_count(dataset['sentence_sentiment'], 'negative')\n",
    "dataset['#neutral_sentences']= sentence_count(dataset['sentence_sentiment'], 'neutral')\n",
    "\n",
    "dataset['% positive_sentences'] =np.round(dataset['#positive_sentences']*100/(dataset['#positive_sentences']+dataset['#negative_sentences']+dataset['#neutral_sentences']),2)\n",
    "dataset['% negative_sentences'] =np.round(dataset['#negative_sentences']*100/(dataset['#positive_sentences']+dataset['#negative_sentences']+dataset['#neutral_sentences']),2)\n",
    "dataset['% neutral_sentences'] =np.round(dataset['#neutral_sentences']*100/(dataset['#positive_sentences']+dataset['#negative_sentences']+dataset['#neutral_sentences']),2)\n",
    "\n",
    "dataset.head(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Polarity is float which lies within range of [-1,1]. Values closer to 1 have a highly positive sentiment and values closer to -1 have highly negative sentiment. Values closer to 0 on the either sides shows slighty positive and negative indication.\n",
    "\n",
    "Similarly, subjective sentences refer to personal opinion, emotion or judgement whereas objective refers to facts. Subjectivity is also a float which lies in the range of [0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewText</th>\n",
       "      <th>overall</th>\n",
       "      <th>label</th>\n",
       "      <th>sentence</th>\n",
       "      <th>tokens</th>\n",
       "      <th>stem_sentence</th>\n",
       "      <th>lemm_sentence</th>\n",
       "      <th>pos_tag</th>\n",
       "      <th>filter_pos_tag</th>\n",
       "      <th>clean_sentence</th>\n",
       "      <th>sentence_sentiment</th>\n",
       "      <th>#positive_sentences</th>\n",
       "      <th>#negative_sentences</th>\n",
       "      <th>#neutral_sentences</th>\n",
       "      <th>% positive_sentences</th>\n",
       "      <th>% negative_sentences</th>\n",
       "      <th>% neutral_sentences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i bought my first hp12c in about 1984 or so, a...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>[i bought my first hp12c in about 1984 or so, ...</td>\n",
       "      <td>[bought, first, served, faithfully, lost, trav...</td>\n",
       "      <td>[bought, first, serv, faith, lost, travel, sea...</td>\n",
       "      <td>[buy, first, serve, faithfully, lose, travel, ...</td>\n",
       "      <td>[(bought, VBD), (first, RB), (served, VBN), (f...</td>\n",
       "      <td>[first, faithfully, travelling, difficult, com...</td>\n",
       "      <td>first faithfully travelling difficult come are...</td>\n",
       "      <td>[0.25, -0.5, 0.0, 0.0, 0.42, 0.19, 0.0, 0.25, ...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>30.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>60.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>why this belated review? i feel very obliged t...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>[why this belated review?, i feel very obliged...</td>\n",
       "      <td>[belated, review, feel, obliged, share, views,...</td>\n",
       "      <td>[belat, review, feel, oblig, share, view, old,...</td>\n",
       "      <td>[belated, review, feel, oblige, share, view, o...</td>\n",
       "      <td>[(belated, VBN), (review, NN), (feel, NN), (ob...</td>\n",
       "      <td>[review, feel, share, views, old, workhorse, g...</td>\n",
       "      <td>review feel share views old workhorse gold ann...</td>\n",
       "      <td>[0.0, 0.27, 0.0, 0.18, 0.7, -0.03, 0.08, 0.4, ...</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>44.44</td>\n",
       "      <td>5.56</td>\n",
       "      <td>50.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i have an hp 48gx that has been kicking for mo...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>[i have an hp 48gx that has been kicking for m...</td>\n",
       "      <td>[hp, kicking, twenty, years, hp, years, old, s...</td>\n",
       "      <td>[hp, kick, twenti, year, hp, year, old, still,...</td>\n",
       "      <td>[hp, kick, twenty, years, hp, years, old, stil...</td>\n",
       "      <td>[(hp, NN), (kicking, VBG), (twenty, CD), (year...</td>\n",
       "      <td>[hp, years, years, old, still, flawless, month...</td>\n",
       "      <td>hp years years old still flawless months numbe...</td>\n",
       "      <td>[0.52, -0.16, 0.0, 0.07, 0.15, 0.6, 0.17, -0.35]</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>25.00</td>\n",
       "      <td>25.00</td>\n",
       "      <td>50.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i've started doing more finance stuff recently...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>[i've started doing more finance stuff recentl...</td>\n",
       "      <td>[started, finance, stuff, recently, went, look...</td>\n",
       "      <td>[start, financ, stuff, recent, went, look, goo...</td>\n",
       "      <td>[start, finance, stuff, recently, go, look, go...</td>\n",
       "      <td>[(started, VBN), (finance, NN), (stuff, NN), (...</td>\n",
       "      <td>[finance, stuff, recently, good, calculator, p...</td>\n",
       "      <td>finance stuff recently good calculator pleasan...</td>\n",
       "      <td>[0.4, 0.25, 0.8, 0.38, 0.2, 0.0, 0.25, 0.35, 0...</td>\n",
       "      <td>25</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>59.52</td>\n",
       "      <td>11.90</td>\n",
       "      <td>28.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>for simple calculations and discounted cash fl...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>[for simple calculations and discounted cash f...</td>\n",
       "      <td>[simple, calculations, discounted, cash, flows...</td>\n",
       "      <td>[simpl, calcul, discount, cash, flow, one, sti...</td>\n",
       "      <td>[simple, calculations, discount, cash, flow, o...</td>\n",
       "      <td>[(simple, JJ), (calculations, NNS), (discounte...</td>\n",
       "      <td>[simple, calculations, cash, flows, still, bes...</td>\n",
       "      <td>simple calculations cash flows still best used...</td>\n",
       "      <td>[0.5, 0.0, 0.18, 0.5, 0.72, 0.0, 0.0, 0.0]</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>37.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>62.50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          reviewText  overall  label  \\\n",
       "0  i bought my first hp12c in about 1984 or so, a...        5      1   \n",
       "1  why this belated review? i feel very obliged t...        5      1   \n",
       "2  i have an hp 48gx that has been kicking for mo...        2      0   \n",
       "3  i've started doing more finance stuff recently...        5      1   \n",
       "4  for simple calculations and discounted cash fl...        5      1   \n",
       "\n",
       "                                            sentence  \\\n",
       "0  [i bought my first hp12c in about 1984 or so, ...   \n",
       "1  [why this belated review?, i feel very obliged...   \n",
       "2  [i have an hp 48gx that has been kicking for m...   \n",
       "3  [i've started doing more finance stuff recentl...   \n",
       "4  [for simple calculations and discounted cash f...   \n",
       "\n",
       "                                              tokens  \\\n",
       "0  [bought, first, served, faithfully, lost, trav...   \n",
       "1  [belated, review, feel, obliged, share, views,...   \n",
       "2  [hp, kicking, twenty, years, hp, years, old, s...   \n",
       "3  [started, finance, stuff, recently, went, look...   \n",
       "4  [simple, calculations, discounted, cash, flows...   \n",
       "\n",
       "                                       stem_sentence  \\\n",
       "0  [bought, first, serv, faith, lost, travel, sea...   \n",
       "1  [belat, review, feel, oblig, share, view, old,...   \n",
       "2  [hp, kick, twenti, year, hp, year, old, still,...   \n",
       "3  [start, financ, stuff, recent, went, look, goo...   \n",
       "4  [simpl, calcul, discount, cash, flow, one, sti...   \n",
       "\n",
       "                                       lemm_sentence  \\\n",
       "0  [buy, first, serve, faithfully, lose, travel, ...   \n",
       "1  [belated, review, feel, oblige, share, view, o...   \n",
       "2  [hp, kick, twenty, years, hp, years, old, stil...   \n",
       "3  [start, finance, stuff, recently, go, look, go...   \n",
       "4  [simple, calculations, discount, cash, flow, o...   \n",
       "\n",
       "                                             pos_tag  \\\n",
       "0  [(bought, VBD), (first, RB), (served, VBN), (f...   \n",
       "1  [(belated, VBN), (review, NN), (feel, NN), (ob...   \n",
       "2  [(hp, NN), (kicking, VBG), (twenty, CD), (year...   \n",
       "3  [(started, VBN), (finance, NN), (stuff, NN), (...   \n",
       "4  [(simple, JJ), (calculations, NNS), (discounte...   \n",
       "\n",
       "                                      filter_pos_tag  \\\n",
       "0  [first, faithfully, travelling, difficult, com...   \n",
       "1  [review, feel, share, views, old, workhorse, g...   \n",
       "2  [hp, years, years, old, still, flawless, month...   \n",
       "3  [finance, stuff, recently, good, calculator, p...   \n",
       "4  [simple, calculations, cash, flows, still, bes...   \n",
       "\n",
       "                                      clean_sentence  \\\n",
       "0  first faithfully travelling difficult come are...   \n",
       "1  review feel share views old workhorse gold ann...   \n",
       "2  hp years years old still flawless months numbe...   \n",
       "3  finance stuff recently good calculator pleasan...   \n",
       "4  simple calculations cash flows still best used...   \n",
       "\n",
       "                                  sentence_sentiment  #positive_sentences  \\\n",
       "0  [0.25, -0.5, 0.0, 0.0, 0.42, 0.19, 0.0, 0.25, ...                    3   \n",
       "1  [0.0, 0.27, 0.0, 0.18, 0.7, -0.03, 0.08, 0.4, ...                    8   \n",
       "2   [0.52, -0.16, 0.0, 0.07, 0.15, 0.6, 0.17, -0.35]                    2   \n",
       "3  [0.4, 0.25, 0.8, 0.38, 0.2, 0.0, 0.25, 0.35, 0...                   25   \n",
       "4         [0.5, 0.0, 0.18, 0.5, 0.72, 0.0, 0.0, 0.0]                    3   \n",
       "\n",
       "   #negative_sentences  #neutral_sentences  % positive_sentences  \\\n",
       "0                    1                   6                 30.00   \n",
       "1                    1                   9                 44.44   \n",
       "2                    2                   4                 25.00   \n",
       "3                    5                  12                 59.52   \n",
       "4                    0                   5                 37.50   \n",
       "\n",
       "   % negative_sentences  % neutral_sentences  \n",
       "0                 10.00                60.00  \n",
       "1                  5.56                50.00  \n",
       "2                 25.00                50.00  \n",
       "3                 11.90                28.57  \n",
       "4                  0.00                62.50  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['% negative > % positive']=dataset['% negative_sentences']>dataset['% positive_sentences']\n",
    "dataset['% negative > 10']=dataset['% negative_sentences']>10\n",
    "dataset['% positive > 50']=dataset['% positive_sentences']>50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(x='label', data=dataset);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(x='label', data=dataset,hue='% negative > 10');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(x='label', data=dataset,hue='% positive > 50');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewText</th>\n",
       "      <th>overall</th>\n",
       "      <th>label</th>\n",
       "      <th>sentence</th>\n",
       "      <th>tokens</th>\n",
       "      <th>stem_sentence</th>\n",
       "      <th>lemm_sentence</th>\n",
       "      <th>pos_tag</th>\n",
       "      <th>filter_pos_tag</th>\n",
       "      <th>clean_sentence</th>\n",
       "      <th>sentence_sentiment</th>\n",
       "      <th>#positive_sentences</th>\n",
       "      <th>#negative_sentences</th>\n",
       "      <th>#neutral_sentences</th>\n",
       "      <th>% positive_sentences</th>\n",
       "      <th>% negative_sentences</th>\n",
       "      <th>% neutral_sentences</th>\n",
       "      <th>% negative &gt; % positive</th>\n",
       "      <th>% negative &gt; 10</th>\n",
       "      <th>% positive &gt; 50</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i have an hp 48gx that has been kicking for mo...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>[i have an hp 48gx that has been kicking for m...</td>\n",
       "      <td>[hp, kicking, twenty, years, hp, years, old, s...</td>\n",
       "      <td>[hp, kick, twenti, year, hp, year, old, still,...</td>\n",
       "      <td>[hp, kick, twenty, years, hp, years, old, stil...</td>\n",
       "      <td>[(hp, NN), (kicking, VBG), (twenty, CD), (year...</td>\n",
       "      <td>[hp, years, years, old, still, flawless, month...</td>\n",
       "      <td>hp years years old still flawless months numbe...</td>\n",
       "      <td>[0.52, -0.16, 0.0, 0.07, 0.15, 0.6, 0.17, -0.35]</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>25.00</td>\n",
       "      <td>25.00</td>\n",
       "      <td>50.00</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>these ubiquitous texas instrument calculator t...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[these ubiquitous texas instrument calculator ...</td>\n",
       "      <td>[ubiquitous, texas, instrument, calculator, ev...</td>\n",
       "      <td>[ubiquit, texa, instrument, calcul, everyon, t...</td>\n",
       "      <td>[ubiquitous, texas, instrument, calculator, ev...</td>\n",
       "      <td>[(ubiquitous, JJ), (texas, NN), (instrument, N...</td>\n",
       "      <td>[ubiquitous, texas, instrument, calculator, ev...</td>\n",
       "      <td>ubiquitous texas instrument calculator everyon...</td>\n",
       "      <td>[0.45, 0.0]</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>50.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>50.00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>overall i do not recommend this product. i rem...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>[overall i do not recommend this product., i r...</td>\n",
       "      <td>[overall, recommend, product, remember, calcul...</td>\n",
       "      <td>[overal, recommend, product, rememb, calcul, s...</td>\n",
       "      <td>[overall, recommend, product, remember, calcul...</td>\n",
       "      <td>[(overall, JJ), (recommend, VB), (product, NN)...</td>\n",
       "      <td>[overall, product, calculator, several, years,...</td>\n",
       "      <td>overall product calculator several years ago v...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.14, -0.4, 0.0]</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>16.67</td>\n",
       "      <td>83.33</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>bought this product recently based on recommen...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[bought this product recently based on recomme...</td>\n",
       "      <td>[bought, product, recently, based, recommendat...</td>\n",
       "      <td>[bought, product, recent, base, recommend, adv...</td>\n",
       "      <td>[buy, product, recently, base, recommendations...</td>\n",
       "      <td>[(bought, JJ), (product, NN), (recently, RB), ...</td>\n",
       "      <td>[bought, product, recently, recommendations, s...</td>\n",
       "      <td>bought product recently recommendations scient...</td>\n",
       "      <td>[0.2, 0.35, -0.5, -0.25, 0.25]</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>60.00</td>\n",
       "      <td>40.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>parents: if you're going to buy your child a g...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>[parents: if you're going to buy your child a ...</td>\n",
       "      <td>[parents, going, buy, child, graphing, calcula...</td>\n",
       "      <td>[parent, go, buy, child, graph, calcul, school...</td>\n",
       "      <td>[parent, go, buy, child, graph, calculator, sc...</td>\n",
       "      <td>[(parents, NNS), (going, VBG), (buy, NN), (chi...</td>\n",
       "      <td>[parents, buy, child, calculator, school, insu...</td>\n",
       "      <td>parents buy child calculator school insult int...</td>\n",
       "      <td>[-0.07, 0.0, 0.4, 0.0, 0.27, 0.29, 0.0, 0.07, ...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>23.08</td>\n",
       "      <td>15.38</td>\n",
       "      <td>61.54</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           reviewText  overall  label  \\\n",
       "2   i have an hp 48gx that has been kicking for mo...        2      0   \n",
       "32  these ubiquitous texas instrument calculator t...        1      0   \n",
       "37  overall i do not recommend this product. i rem...        2      0   \n",
       "40  bought this product recently based on recommen...        1      0   \n",
       "43  parents: if you're going to buy your child a g...        2      0   \n",
       "\n",
       "                                             sentence  \\\n",
       "2   [i have an hp 48gx that has been kicking for m...   \n",
       "32  [these ubiquitous texas instrument calculator ...   \n",
       "37  [overall i do not recommend this product., i r...   \n",
       "40  [bought this product recently based on recomme...   \n",
       "43  [parents: if you're going to buy your child a ...   \n",
       "\n",
       "                                               tokens  \\\n",
       "2   [hp, kicking, twenty, years, hp, years, old, s...   \n",
       "32  [ubiquitous, texas, instrument, calculator, ev...   \n",
       "37  [overall, recommend, product, remember, calcul...   \n",
       "40  [bought, product, recently, based, recommendat...   \n",
       "43  [parents, going, buy, child, graphing, calcula...   \n",
       "\n",
       "                                        stem_sentence  \\\n",
       "2   [hp, kick, twenti, year, hp, year, old, still,...   \n",
       "32  [ubiquit, texa, instrument, calcul, everyon, t...   \n",
       "37  [overal, recommend, product, rememb, calcul, s...   \n",
       "40  [bought, product, recent, base, recommend, adv...   \n",
       "43  [parent, go, buy, child, graph, calcul, school...   \n",
       "\n",
       "                                        lemm_sentence  \\\n",
       "2   [hp, kick, twenty, years, hp, years, old, stil...   \n",
       "32  [ubiquitous, texas, instrument, calculator, ev...   \n",
       "37  [overall, recommend, product, remember, calcul...   \n",
       "40  [buy, product, recently, base, recommendations...   \n",
       "43  [parent, go, buy, child, graph, calculator, sc...   \n",
       "\n",
       "                                              pos_tag  \\\n",
       "2   [(hp, NN), (kicking, VBG), (twenty, CD), (year...   \n",
       "32  [(ubiquitous, JJ), (texas, NN), (instrument, N...   \n",
       "37  [(overall, JJ), (recommend, VB), (product, NN)...   \n",
       "40  [(bought, JJ), (product, NN), (recently, RB), ...   \n",
       "43  [(parents, NNS), (going, VBG), (buy, NN), (chi...   \n",
       "\n",
       "                                       filter_pos_tag  \\\n",
       "2   [hp, years, years, old, still, flawless, month...   \n",
       "32  [ubiquitous, texas, instrument, calculator, ev...   \n",
       "37  [overall, product, calculator, several, years,...   \n",
       "40  [bought, product, recently, recommendations, s...   \n",
       "43  [parents, buy, child, calculator, school, insu...   \n",
       "\n",
       "                                       clean_sentence  \\\n",
       "2   hp years years old still flawless months numbe...   \n",
       "32  ubiquitous texas instrument calculator everyon...   \n",
       "37  overall product calculator several years ago v...   \n",
       "40  bought product recently recommendations scient...   \n",
       "43  parents buy child calculator school insult int...   \n",
       "\n",
       "                                   sentence_sentiment  #positive_sentences  \\\n",
       "2    [0.52, -0.16, 0.0, 0.07, 0.15, 0.6, 0.17, -0.35]                    2   \n",
       "32                                        [0.45, 0.0]                    1   \n",
       "37                   [0.0, 0.0, 0.0, 0.14, -0.4, 0.0]                    0   \n",
       "40                     [0.2, 0.35, -0.5, -0.25, 0.25]                    3   \n",
       "43  [-0.07, 0.0, 0.4, 0.0, 0.27, 0.29, 0.0, 0.07, ...                    3   \n",
       "\n",
       "    #negative_sentences  #neutral_sentences  % positive_sentences  \\\n",
       "2                     2                   4                 25.00   \n",
       "32                    0                   1                 50.00   \n",
       "37                    1                   5                  0.00   \n",
       "40                    2                   0                 60.00   \n",
       "43                    2                   8                 23.08   \n",
       "\n",
       "    % negative_sentences  % neutral_sentences  % negative > % positive  \\\n",
       "2                  25.00                50.00                    False   \n",
       "32                  0.00                50.00                    False   \n",
       "37                 16.67                83.33                     True   \n",
       "40                 40.00                 0.00                    False   \n",
       "43                 15.38                61.54                    False   \n",
       "\n",
       "    % negative > 10  % positive > 50  \n",
       "2              True            False  \n",
       "32            False            False  \n",
       "37             True            False  \n",
       "40             True             True  \n",
       "43             True            False  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[dataset['label']==0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to calculate Model Metrics\n",
    "\n",
    "def get_model_metrics(actual,predicted):\n",
    "    \"\"\"\n",
    "    Print Summary Metrics of the Model\n",
    "\n",
    "    Parameters:\n",
    "    actual (pandas.core.series.Series): Series of Boolean values for target column\n",
    "    predicted (pandas.core.series.Series): Series of Boolean values for Model predicted the target column\n",
    "    \n",
    "    Returns:\n",
    "    None\n",
    "\n",
    "   \"\"\"\n",
    "\n",
    "    \n",
    "    confusion = metrics.confusion_matrix(actual,predicted )\n",
    "    TP = confusion[1,1] # true positive \n",
    "    TN = confusion[0,0] # true negatives\n",
    "    FP = confusion[0,1] # false positives\n",
    "    FN = confusion[1,0] # false negatives\n",
    "    accuracy=metrics.accuracy_score(actual,predicted)\n",
    "    sensitivity = TP / float(TP+FN)\n",
    "    specificity = TN / float(TN+FP)\n",
    "    precision=TP/float(FP+TP)\n",
    "    recall=TP/float(FN+TP)\n",
    "    \n",
    "    precision=metrics.precision_score(actual,predicted)\n",
    "    recall=metrics.recall_score(actual,predicted)\n",
    "    f1=metrics.f1_score(actual,predicted, average='weighted') \n",
    "    print(\"Accuracy    : \"+str(round(accuracy,2)))\n",
    "    print(\"Sensitivity : \"+str(round(sensitivity,2)))\n",
    "    print(\"Specificity : \"+str(round(specificity,2)))\n",
    "    print(\"Precision   : \"+str(round(precision,2)))\n",
    "    print(\"Recall      : \"+str(round(recall,2)))\n",
    "    print(\"F1_score    : \"+str(round(f1,2)))\n",
    "    \n",
    "# fokal ml utils\n",
    "\n",
    "def get_cross_validated_model_metrics(X,y,cv=5):\n",
    "    \"\"\"\n",
    "    Get cross validated model metric for k folds\n",
    "\n",
    "    Parameters:\n",
    "    X (pandas.core.frame.DataFrame): DF of all the features excluding target column\n",
    "    y (pandas.core.series.Series): Series of Boolean values of the target column\n",
    "    \n",
    "    Returns:\n",
    "    df (pandas.core.frame.DataFrame): DF will all the metric for k fold\n",
    "\n",
    "   \"\"\"\n",
    "    accuracy=cross_val_score(logregcv, X, y, cv=cv,n_jobs=-1,scoring='accuracy')\n",
    "    precision=cross_val_score(logregcv, X, y, cv=cv,n_jobs=-1,scoring='precision')\n",
    "    recall=cross_val_score(logregcv, X, y, cv=cv,n_jobs=-1,scoring='recall')\n",
    "    f1_weighted=cross_val_score(logregcv, X, y, cv=cv,n_jobs=-1,scoring='f1_weighted')\n",
    "    roc_auc=cross_val_score(logregcv, X, y, cv=cv,n_jobs=-1,scoring='roc_auc')\n",
    "    df=pd.DataFrame(\n",
    "    {'accuracy': accuracy,\n",
    "     'precision': precision,\n",
    "     'recall': recall,\n",
    "     'f1_weighted': f1_weighted,\n",
    "     'roc_auc': roc_auc,\n",
    "    })\n",
    "    return df\n",
    "\n",
    "logregcv = LogisticRegressionCV(class_weight='balanced',cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "class TfIdfExtractor(object):\n",
    "\n",
    "    def gen_tf_score(self, doc):\n",
    "        return Counter(doc)\n",
    "\n",
    "    def gen_df_score(self, doc_list):\n",
    "\n",
    "        idf_corpus = {}\n",
    "        doc_cntr = 0\n",
    "        for doc in doc_list:\n",
    "            ## TODO: Handle Bad docs\n",
    "            if len(doc) == 0: continue\n",
    "\n",
    "            doc_cntr += 1\n",
    "            tf_doc = self.gen_tf_score(doc)\n",
    "            idf_corpus.update(\n",
    "                {_k: idf_corpus.get(_k, 0) + 1 for _k, _v in tf_doc.items()})  # Add for the presence of term\n",
    "            #tf_doc = {_k: _v / len(doc) for _k, _v in tf_doc.items()}\n",
    "\n",
    "        return idf_corpus, doc_cntr\n",
    "\n",
    "    def gen_tf_idf_scores(self, doc_list):\n",
    "\n",
    "        global_tfidf= {}\n",
    "\n",
    "        # Obtain the document frequency scores\n",
    "        df_scores, num_doc = self.gen_df_score(doc_list)\n",
    "\n",
    "        for doc in doc_list:\n",
    "            tf_doc = Counter(doc)\n",
    "\n",
    "            for _term, _freq in tf_doc.items():\n",
    "                _term_idf = df_scores.get(_term, 0)\n",
    "                if _term_idf > 0:\n",
    "                    tfidf_score = _freq * math.log10(num_doc / _term_idf)\n",
    "                else:\n",
    "                    raise Exception(\"TFIDF calculation failed!\")\n",
    "\n",
    "                if _term in global_tfidf:\n",
    "                    global_tfidf[_term].append(tfidf_score)\n",
    "                else:\n",
    "                    global_tfidf[_term] = [tfidf_score]\n",
    "\n",
    "                #global_tfidf[_term] = [tfidf_score]\n",
    "\n",
    "        return global_tfidf\n",
    "\n",
    "    def gen_tf_idf_stats_df(self, doc_list):\n",
    "\n",
    "        global_tfidf = self.gen_tf_idf_scores(doc_list)\n",
    "\n",
    "        tfidf_list = []\n",
    "        for _term in global_tfidf:\n",
    "            tfidf_dict = {}\n",
    "            tfidf_scores = global_tfidf[_term]\n",
    "            tfidf_dict['term'] = _term\n",
    "            # tfidf_dict['mode'] = mode(tfidf_scores)\n",
    "            tfidf_dict['mean'] = np.mean(tfidf_scores)\n",
    "            tfidf_dict['median'] = np.median(tfidf_scores)\n",
    "            tfidf_dict['min'] = min(tfidf_scores)\n",
    "            tfidf_dict['max'] = max(tfidf_scores)\n",
    "            tfidf_dict['freq'] = len(tfidf_scores)\n",
    "            tfidf_list.append(tfidf_dict)\n",
    "\n",
    "        tfidf_df = pd.DataFrame(tfidf_list)\n",
    "        return tfidf_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# corp_proc_tokens = list(dataset[''])\n",
    "# tfidf_df = TfIdfExtractor().gen_tf_idf_stats_df(corp_proc_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = dataset\n",
    "y = pd.DataFrame(dataset, columns = [\"label\"])\n",
    "\n",
    "X_train , X_test , y_train , y_test = train_test_split(X, y, random_state=50,stratify=y,train_size=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    31739\n",
       "0     1999\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1340885407912871"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "3989/29749"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(token_pattern=r'\\b\\w+\\b')\n",
    "dataset_vector = vectorizer.fit_transform(X_train[\"clean_sentence\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 30443)\n"
     ]
    }
   ],
   "source": [
    "print(dataset_vector[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(33738, 30443)\n"
     ]
    }
   ],
   "source": [
    "print(dataset_vector.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48198, 20)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30443"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vectorizer.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorizer.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "vectorizer = CountVectorizer(token_pattern=r'\\b\\w+\\b')\n",
    "dataset_vector = vectorizer.fit_transform(X_train[\"clean_sentence\"])\n",
    "\n",
    "\n",
    "chi2_selector = chi2(dataset_vector, X_train['label'])\n",
    "\n",
    "list_tokens=[]\n",
    "for key, val in vectorizer.vocabulary_.items():    # for name, age in dictionary.iteritems():  (for Python 2.x)\n",
    "        if key in frequency_tokens:\n",
    "            list_tokens.append([key,val,frequency_tokens[key],chi2_selector[0][val],chi2_selector[1][val]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "unigram_df=pd.DataFrame(list_tokens,columns=['token','index','frquency','chi2','p_value'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>index</th>\n",
       "      <th>frquency</th>\n",
       "      <th>chi2</th>\n",
       "      <th>p_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sharpie</td>\n",
       "      <td>23604</td>\n",
       "      <td>951</td>\n",
       "      <td>0.041787</td>\n",
       "      <td>8.380266e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bold</td>\n",
       "      <td>2734</td>\n",
       "      <td>568</td>\n",
       "      <td>0.707124</td>\n",
       "      <td>4.004003e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>clean</td>\n",
       "      <td>4454</td>\n",
       "      <td>2677</td>\n",
       "      <td>0.998970</td>\n",
       "      <td>3.175598e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>solid</td>\n",
       "      <td>24553</td>\n",
       "      <td>1866</td>\n",
       "      <td>6.256164</td>\n",
       "      <td>1.237619e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>product</td>\n",
       "      <td>20499</td>\n",
       "      <td>10598</td>\n",
       "      <td>174.238228</td>\n",
       "      <td>8.781325e-40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     token  index  frquency        chi2       p_value\n",
       "0  sharpie  23604       951    0.041787  8.380266e-01\n",
       "1     bold   2734       568    0.707124  4.004003e-01\n",
       "2    clean   4454      2677    0.998970  3.175598e-01\n",
       "3    solid  24553      1866    6.256164  1.237619e-02\n",
       "4  product  20499     10598  174.238228  8.781325e-40"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unigram_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>index</th>\n",
       "      <th>frquency</th>\n",
       "      <th>chi2</th>\n",
       "      <th>p_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1573</th>\n",
       "      <td>poor</td>\n",
       "      <td>19771</td>\n",
       "      <td>290</td>\n",
       "      <td>448.821425</td>\n",
       "      <td>1.301987e-99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>printer</td>\n",
       "      <td>20290</td>\n",
       "      <td>26633</td>\n",
       "      <td>426.733519</td>\n",
       "      <td>8.353022e-95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1560</th>\n",
       "      <td>useless</td>\n",
       "      <td>28771</td>\n",
       "      <td>229</td>\n",
       "      <td>371.991124</td>\n",
       "      <td>6.897120e-83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>710</th>\n",
       "      <td>support</td>\n",
       "      <td>25883</td>\n",
       "      <td>1915</td>\n",
       "      <td>365.103304</td>\n",
       "      <td>2.179594e-81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>845</th>\n",
       "      <td>customer</td>\n",
       "      <td>6135</td>\n",
       "      <td>488</td>\n",
       "      <td>357.687075</td>\n",
       "      <td>8.978858e-80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>hp</td>\n",
       "      <td>12254</td>\n",
       "      <td>4094</td>\n",
       "      <td>350.685178</td>\n",
       "      <td>3.005612e-78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4977</th>\n",
       "      <td>refund</td>\n",
       "      <td>21622</td>\n",
       "      <td>35</td>\n",
       "      <td>325.801453</td>\n",
       "      <td>7.893216e-73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>service</td>\n",
       "      <td>23443</td>\n",
       "      <td>1145</td>\n",
       "      <td>305.610285</td>\n",
       "      <td>1.974769e-68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1552</th>\n",
       "      <td>worst</td>\n",
       "      <td>30089</td>\n",
       "      <td>97</td>\n",
       "      <td>301.471966</td>\n",
       "      <td>1.574281e-67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1241</th>\n",
       "      <td>bad</td>\n",
       "      <td>1950</td>\n",
       "      <td>1363</td>\n",
       "      <td>300.815176</td>\n",
       "      <td>2.188632e-67</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         token  index  frquency        chi2       p_value\n",
       "1573      poor  19771       290  448.821425  1.301987e-99\n",
       "110    printer  20290     26633  426.733519  8.353022e-95\n",
       "1560   useless  28771       229  371.991124  6.897120e-83\n",
       "710    support  25883      1915  365.103304  2.179594e-81\n",
       "845   customer   6135       488  357.687075  8.978858e-80\n",
       "86          hp  12254      4094  350.685178  3.005612e-78\n",
       "4977    refund  21622        35  325.801453  7.893216e-73\n",
       "124    service  23443      1145  305.610285  1.974769e-68\n",
       "1552     worst  30089        97  301.471966  1.574281e-67\n",
       "1241       bad   1950      1363  300.815176  2.188632e-67"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unigram_df.sort_values(by='chi2',ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter on chi pvalue and frequency\n",
    "unigram_df=unigram_df[(unigram_df['chi2']>10)&(unigram_df['frquency']>10)&(unigram_df['p_value']<0.05)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>index</th>\n",
       "      <th>frquency</th>\n",
       "      <th>chi2</th>\n",
       "      <th>p_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4143</th>\n",
       "      <td>garbage</td>\n",
       "      <td>10593</td>\n",
       "      <td>109</td>\n",
       "      <td>82.266333</td>\n",
       "      <td>1.189308e-19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        token  index  frquency       chi2       p_value\n",
       "4143  garbage  10593       109  82.266333  1.189308e-19"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unigram_df[unigram_df.token.str.contains('garbage')]\n",
    "# significant\n",
    "#frequency cutoff -5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>index</th>\n",
       "      <th>frquency</th>\n",
       "      <th>chi2</th>\n",
       "      <th>p_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6246</th>\n",
       "      <td>profit</td>\n",
       "      <td>20537</td>\n",
       "      <td>55</td>\n",
       "      <td>10.030704</td>\n",
       "      <td>0.001540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4680</th>\n",
       "      <td>recognize</td>\n",
       "      <td>21445</td>\n",
       "      <td>422</td>\n",
       "      <td>10.030704</td>\n",
       "      <td>0.001540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3141</th>\n",
       "      <td>bug</td>\n",
       "      <td>3202</td>\n",
       "      <td>103</td>\n",
       "      <td>10.030704</td>\n",
       "      <td>0.001540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>959</th>\n",
       "      <td>restart</td>\n",
       "      <td>22122</td>\n",
       "      <td>77</td>\n",
       "      <td>10.030704</td>\n",
       "      <td>0.001540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1750</th>\n",
       "      <td>workforce</td>\n",
       "      <td>30027</td>\n",
       "      <td>1151</td>\n",
       "      <td>10.041827</td>\n",
       "      <td>0.001530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1855</th>\n",
       "      <td>oem</td>\n",
       "      <td>17651</td>\n",
       "      <td>328</td>\n",
       "      <td>10.109230</td>\n",
       "      <td>0.001475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>511</th>\n",
       "      <td>ago</td>\n",
       "      <td>614</td>\n",
       "      <td>1124</td>\n",
       "      <td>10.112687</td>\n",
       "      <td>0.001473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2974</th>\n",
       "      <td>c</td>\n",
       "      <td>3396</td>\n",
       "      <td>74</td>\n",
       "      <td>10.115090</td>\n",
       "      <td>0.001471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1655</th>\n",
       "      <td>english</td>\n",
       "      <td>8451</td>\n",
       "      <td>145</td>\n",
       "      <td>10.214721</td>\n",
       "      <td>0.001393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3404</th>\n",
       "      <td>twenty</td>\n",
       "      <td>27859</td>\n",
       "      <td>156</td>\n",
       "      <td>10.235114</td>\n",
       "      <td>0.001378</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          token  index  frquency       chi2   p_value\n",
       "6246     profit  20537        55  10.030704  0.001540\n",
       "4680  recognize  21445       422  10.030704  0.001540\n",
       "3141        bug   3202       103  10.030704  0.001540\n",
       "959     restart  22122        77  10.030704  0.001540\n",
       "1750  workforce  30027      1151  10.041827  0.001530\n",
       "1855        oem  17651       328  10.109230  0.001475\n",
       "511         ago    614      1124  10.112687  0.001473\n",
       "2974          c   3396        74  10.115090  0.001471\n",
       "1655    english   8451       145  10.214721  0.001393\n",
       "3404     twenty  27859       156  10.235114  0.001378"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unigram_df.sort_values(by='p_value',ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "s=' '.join(list(X_train['clean_sentence']))\n",
    "\n",
    "s = s.lower()\n",
    "s = re.sub(r'[^a-zA-Z0-9\\s]', ' ', s)\n",
    "tokens = [token for token in s.split(\" \") if token != \"\"]\n",
    "\n",
    "# 2grams\n",
    "bgs = nltk.bigrams(tokens)\n",
    "\n",
    "#compute frequency distribution for all the bigrams in the text\n",
    "bigram_fdist = nltk.FreqDist(bgs)\n",
    "tmp_bigram_frequency_tokens={ x[0]:x[1] for x in bigram_fdist.most_common()}\n",
    "# pp.pprint(bigram_frequency_tokens)\n",
    "\n",
    "#3grams\n",
    "bgs = nltk.trigrams(tokens)\n",
    "\n",
    "#compute frequency distribution for all the trigrams in the text\n",
    "trigram_fdist = nltk.FreqDist(bgs)\n",
    "tmp_trigram_frequency_tokens={ x[0]:x[1] for x in trigram_fdist.most_common()}\n",
    "# pp.pprint(trigram_frequency_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram_frequency_tokens={}\n",
    "for key , value in tmp_bigram_frequency_tokens.items():\n",
    "    bigram_frequency_tokens[key[0]+\" \"+key[1]]=value\n",
    "\n",
    "trigram_frequency_tokens={}\n",
    "for key , value in tmp_trigram_frequency_tokens.items():\n",
    "    trigram_frequency_tokens[key[0]+\" \"+key[1]+\" \"+key[2]]=value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(token_pattern=r'\\b\\w+\\b', ngram_range=(2, 2))\n",
    "dataset_vector = vectorizer.fit_transform(X_train[\"clean_sentence\"])\n",
    "\n",
    "\n",
    "chi2_selector = chi2(dataset_vector, X_train['label'])\n",
    "\n",
    "list_tokens=[]\n",
    "for key, val in vectorizer.vocabulary_.items():\n",
    "        if key in bigram_frequency_tokens:\n",
    "            list_tokens.append([key,val,bigram_frequency_tokens[key],chi2_selector[0][val],chi2_selector[1][val]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram_df=pd.DataFrame(list_tokens,columns=['token','index','frquency','chi2','p_value'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>index</th>\n",
       "      <th>frquency</th>\n",
       "      <th>chi2</th>\n",
       "      <th>p_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2848</th>\n",
       "      <td>file box</td>\n",
       "      <td>239685</td>\n",
       "      <td>92</td>\n",
       "      <td>404.577083</td>\n",
       "      <td>5.553609e-90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7027</th>\n",
       "      <td>waste money</td>\n",
       "      <td>758191</td>\n",
       "      <td>56</td>\n",
       "      <td>385.346925</td>\n",
       "      <td>8.528500e-86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2505</th>\n",
       "      <td>tech support</td>\n",
       "      <td>695770</td>\n",
       "      <td>133</td>\n",
       "      <td>366.424157</td>\n",
       "      <td>1.124025e-81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>433706</th>\n",
       "      <td>buy store</td>\n",
       "      <td>83397</td>\n",
       "      <td>17</td>\n",
       "      <td>206.627979</td>\n",
       "      <td>7.474343e-47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13001</th>\n",
       "      <td>customer service</td>\n",
       "      <td>151174</td>\n",
       "      <td>209</td>\n",
       "      <td>202.887641</td>\n",
       "      <td>4.894472e-46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113644</th>\n",
       "      <td>refillable cartridges</td>\n",
       "      <td>568609</td>\n",
       "      <td>16</td>\n",
       "      <td>191.014370</td>\n",
       "      <td>1.909497e-43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23058</th>\n",
       "      <td>poor quality</td>\n",
       "      <td>512171</td>\n",
       "      <td>48</td>\n",
       "      <td>167.285054</td>\n",
       "      <td>2.898445e-38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57030</th>\n",
       "      <td>piece junk</td>\n",
       "      <td>500999</td>\n",
       "      <td>22</td>\n",
       "      <td>152.977721</td>\n",
       "      <td>3.873843e-35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33739</th>\n",
       "      <td>best buy</td>\n",
       "      <td>54129</td>\n",
       "      <td>60</td>\n",
       "      <td>150.632605</td>\n",
       "      <td>1.260925e-34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110974</th>\n",
       "      <td>free postage</td>\n",
       "      <td>260177</td>\n",
       "      <td>13</td>\n",
       "      <td>144.417078</td>\n",
       "      <td>2.880076e-33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        token   index  frquency        chi2       p_value\n",
       "2848                 file box  239685        92  404.577083  5.553609e-90\n",
       "7027              waste money  758191        56  385.346925  8.528500e-86\n",
       "2505             tech support  695770       133  366.424157  1.124025e-81\n",
       "433706              buy store   83397        17  206.627979  7.474343e-47\n",
       "13001        customer service  151174       209  202.887641  4.894472e-46\n",
       "113644  refillable cartridges  568609        16  191.014370  1.909497e-43\n",
       "23058            poor quality  512171        48  167.285054  2.898445e-38\n",
       "57030              piece junk  500999        22  152.977721  3.873843e-35\n",
       "33739                best buy   54129        60  150.632605  1.260925e-34\n",
       "110974           free postage  260177        13  144.417078  2.880076e-33"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigram_df.sort_values(by='chi2',ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Just to update: \n",
    "This clearly tells us the Negative reviews bigrams tokens which have decent frequency and large chi-square results.\n",
    "*waste money*\n",
    "*tech support*\n",
    "*customer service*\n",
    "*piece junk*\n",
    "*poor quality*\n",
    "*really disappointed*\n",
    "*full refund*\n",
    "*error message*\n",
    "\n",
    "Following are the bigram product which negative review revolve around. \n",
    "*worst printer*\n",
    "*refillable cartridges*\n",
    "*head cleanings*\n",
    "*pixel granularity*\n",
    "*cents laser*\n",
    "\n",
    "Yesterday night finished 30 plus positive negative review comments. Bigrams trigram and single tokens features are ready. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>index</th>\n",
       "      <th>frquency</th>\n",
       "      <th>chi2</th>\n",
       "      <th>p_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>54109</th>\n",
       "      <td>fit right</td>\n",
       "      <td>247762</td>\n",
       "      <td>17</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>0.994048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69626</th>\n",
       "      <td>messenger bag</td>\n",
       "      <td>406615</td>\n",
       "      <td>17</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>0.994048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37048</th>\n",
       "      <td>pencil work</td>\n",
       "      <td>486317</td>\n",
       "      <td>17</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>0.994048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51362</th>\n",
       "      <td>front computer</td>\n",
       "      <td>262251</td>\n",
       "      <td>17</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>0.994048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29377</th>\n",
       "      <td>ever problem</td>\n",
       "      <td>215554</td>\n",
       "      <td>17</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>0.994048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114163</th>\n",
       "      <td>printers scanners</td>\n",
       "      <td>531074</td>\n",
       "      <td>17</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>0.994048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118715</th>\n",
       "      <td>kids also</td>\n",
       "      <td>344239</td>\n",
       "      <td>17</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>0.994048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26243</th>\n",
       "      <td>minutes install</td>\n",
       "      <td>411251</td>\n",
       "      <td>17</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>0.994048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72003</th>\n",
       "      <td>well smooth</td>\n",
       "      <td>766333</td>\n",
       "      <td>17</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>0.994048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19947</th>\n",
       "      <td>printer larger</td>\n",
       "      <td>528791</td>\n",
       "      <td>17</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>0.994048</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    token   index  frquency      chi2   p_value\n",
       "54109           fit right  247762        17  0.000056  0.994048\n",
       "69626       messenger bag  406615        17  0.000056  0.994048\n",
       "37048         pencil work  486317        17  0.000056  0.994048\n",
       "51362      front computer  262251        17  0.000056  0.994048\n",
       "29377        ever problem  215554        17  0.000056  0.994048\n",
       "114163  printers scanners  531074        17  0.000056  0.994048\n",
       "118715          kids also  344239        17  0.000056  0.994048\n",
       "26243     minutes install  411251        17  0.000056  0.994048\n",
       "72003         well smooth  766333        17  0.000056  0.994048\n",
       "19947      printer larger  528791        17  0.000056  0.994048"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigram_df.sort_values(by='p_value',ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter on chi pvalue and frequency\n",
    "bigram_df=bigram_df[(bigram_df['chi2']>10)&(bigram_df['frquency']>10)&(bigram_df['p_value']<0.05)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(token_pattern=r'\\b\\w+\\b', ngram_range=(3, 3))\n",
    "dataset_vector = vectorizer.fit_transform(X_train[\"clean_sentence\"])\n",
    "\n",
    "\n",
    "chi2_selector = chi2(dataset_vector, X_train['label'])\n",
    "\n",
    "list_tokens=[]\n",
    "for key, val in vectorizer.vocabulary_.items():\n",
    "        if key in trigram_frequency_tokens:\n",
    "            list_tokens.append([key,val,trigram_frequency_tokens[key],chi2_selector[0][val],chi2_selector[1][val]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigram_df=pd.DataFrame(list_tokens,columns=['token','index','frquency','chi2','p_value'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>index</th>\n",
       "      <th>frquency</th>\n",
       "      <th>chi2</th>\n",
       "      <th>p_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>983539</th>\n",
       "      <td>best buy store</td>\n",
       "      <td>92563</td>\n",
       "      <td>14</td>\n",
       "      <td>222.284142</td>\n",
       "      <td>2.871874e-50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49623</th>\n",
       "      <td>worst printer ever</td>\n",
       "      <td>1449326</td>\n",
       "      <td>6</td>\n",
       "      <td>95.264632</td>\n",
       "      <td>1.665625e-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96702</th>\n",
       "      <td>full list price</td>\n",
       "      <td>465946</td>\n",
       "      <td>7</td>\n",
       "      <td>79.950111</td>\n",
       "      <td>3.839836e-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214366</th>\n",
       "      <td>press start button</td>\n",
       "      <td>955109</td>\n",
       "      <td>8</td>\n",
       "      <td>68.479965</td>\n",
       "      <td>1.281732e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96707</th>\n",
       "      <td>genuine brother supplies</td>\n",
       "      <td>475327</td>\n",
       "      <td>8</td>\n",
       "      <td>68.479965</td>\n",
       "      <td>1.281732e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59739</th>\n",
       "      <td>ink system failure</td>\n",
       "      <td>581853</td>\n",
       "      <td>6</td>\n",
       "      <td>64.499825</td>\n",
       "      <td>9.654092e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>801984</th>\n",
       "      <td>read fine print</td>\n",
       "      <td>1045494</td>\n",
       "      <td>6</td>\n",
       "      <td>64.499825</td>\n",
       "      <td>9.654092e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>692319</th>\n",
       "      <td>hp printer best</td>\n",
       "      <td>555961</td>\n",
       "      <td>6</td>\n",
       "      <td>64.499825</td>\n",
       "      <td>9.654092e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96718</th>\n",
       "      <td>toner powder refills</td>\n",
       "      <td>1330808</td>\n",
       "      <td>4</td>\n",
       "      <td>63.509755</td>\n",
       "      <td>1.595746e-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>628839</th>\n",
       "      <td>best buy oakland</td>\n",
       "      <td>92551</td>\n",
       "      <td>4</td>\n",
       "      <td>63.509755</td>\n",
       "      <td>1.595746e-15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           token    index  frquency        chi2       p_value\n",
       "983539            best buy store    92563        14  222.284142  2.871874e-50\n",
       "49623         worst printer ever  1449326         6   95.264632  1.665625e-22\n",
       "96702            full list price   465946         7   79.950111  3.839836e-19\n",
       "214366        press start button   955109         8   68.479965  1.281732e-16\n",
       "96707   genuine brother supplies   475327         8   68.479965  1.281732e-16\n",
       "59739         ink system failure   581853         6   64.499825  9.654092e-16\n",
       "801984           read fine print  1045494         6   64.499825  9.654092e-16\n",
       "692319           hp printer best   555961         6   64.499825  9.654092e-16\n",
       "96718       toner powder refills  1330808         4   63.509755  1.595746e-15\n",
       "628839          best buy oakland    92551         4   63.509755  1.595746e-15"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trigram_df.sort_values(by='chi2',ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# filter on chi pvalue and frequency\n",
    "trigram_df=trigram_df[(trigram_df['chi2']>10)&(trigram_df['frquency']>10)&(trigram_df['p_value']<0.05)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#build master cir square df\n",
    "\n",
    "master_chi_sq_df=pd.concat([trigram_df,bigram_df,unigram_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1423, 5)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master_chi_sq_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_chi_sq_df.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_chi_sq_df=master_chi_sq_df[master_chi_sq_df.chi2>10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>index</th>\n",
       "      <th>frquency</th>\n",
       "      <th>chi2</th>\n",
       "      <th>p_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ink cartridges printer</td>\n",
       "      <td>577425</td>\n",
       "      <td>39</td>\n",
       "      <td>14.889288</td>\n",
       "      <td>1.140086e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mo file box</td>\n",
       "      <td>742743</td>\n",
       "      <td>13</td>\n",
       "      <td>53.558605</td>\n",
       "      <td>2.509926e-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>laser printer wireless</td>\n",
       "      <td>641177</td>\n",
       "      <td>11</td>\n",
       "      <td>18.284105</td>\n",
       "      <td>1.902883e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>black white text</td>\n",
       "      <td>115672</td>\n",
       "      <td>22</td>\n",
       "      <td>11.142632</td>\n",
       "      <td>8.436612e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>matter many times</td>\n",
       "      <td>724486</td>\n",
       "      <td>12</td>\n",
       "      <td>41.821264</td>\n",
       "      <td>1.000099e-10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    token   index  frquency       chi2       p_value\n",
       "0  ink cartridges printer  577425        39  14.889288  1.140086e-04\n",
       "1             mo file box  742743        13  53.558605  2.509926e-13\n",
       "2  laser printer wireless  641177        11  18.284105  1.902883e-05\n",
       "3        black white text  115672        22  11.142632  8.436612e-04\n",
       "4       matter many times  724486        12  41.821264  1.000099e-10"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master_chi_sq_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_list=master_chi_sq_df['token'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1423"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(feature_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature in feature_list:\n",
    "    X_train[feature]=X_train.clean_sentence.apply(lambda x: 1 if feature in x else 0)\n",
    "    X_test[feature]=X_test.clean_sentence.apply(lambda x: 1 if feature in x else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewText</th>\n",
       "      <th>overall</th>\n",
       "      <th>label</th>\n",
       "      <th>sentence</th>\n",
       "      <th>tokens</th>\n",
       "      <th>stem_sentence</th>\n",
       "      <th>lemm_sentence</th>\n",
       "      <th>pos_tag</th>\n",
       "      <th>filter_pos_tag</th>\n",
       "      <th>clean_sentence</th>\n",
       "      <th>...</th>\n",
       "      <th>participation</th>\n",
       "      <th>suprised</th>\n",
       "      <th>rig</th>\n",
       "      <th>omit</th>\n",
       "      <th>deceive</th>\n",
       "      <th>lapinator</th>\n",
       "      <th>purport</th>\n",
       "      <th>instal</th>\n",
       "      <th>rethink</th>\n",
       "      <th>prepay</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5527</th>\n",
       "      <td>interestingly, you can open this binder with e...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>[interestingly, you can open this binder with ...</td>\n",
       "      <td>[interestingly, open, binder, either, bottom, ...</td>\n",
       "      <td>[interestingli, open, binder, either, bottom, ...</td>\n",
       "      <td>[interestingly, open, binder, either, bottom, ...</td>\n",
       "      <td>[(interestingly, RB), (open, JJ), (binder, NN)...</td>\n",
       "      <td>[interestingly, open, binder, bottom, top, tab...</td>\n",
       "      <td>interestingly open binder bottom top tabs clos...</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27611</th>\n",
       "      <td>these scotch reusable strips for lightweight m...</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>[these scotch reusable strips for lightweight ...</td>\n",
       "      <td>[scotch, reusable, strips, lightweight, mounti...</td>\n",
       "      <td>[scotch, reusabl, strip, lightweight, mount, t...</td>\n",
       "      <td>[scotch, reusable, strip, lightweight, mount, ...</td>\n",
       "      <td>[(scotch, NN), (reusable, JJ), (strips, NNS), ...</td>\n",
       "      <td>[scotch, reusable, strips, terrific, far, ever...</td>\n",
       "      <td>scotch reusable strips terrific far everything...</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1564</th>\n",
       "      <td>these are good, standard solid labels from ave...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>[these are good, standard solid labels from av...</td>\n",
       "      <td>[good, standard, solid, labels, avery, templat...</td>\n",
       "      <td>[good, standard, solid, label, averi, templat,...</td>\n",
       "      <td>[good, standard, solid, label, avery, template...</td>\n",
       "      <td>[(good, JJ), (standard, NN), (solid, JJ), (lab...</td>\n",
       "      <td>[good, standard, solid, labels, avery, templat...</td>\n",
       "      <td>good standard solid labels avery template sugg...</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10206</th>\n",
       "      <td>this is one of the most powerful staplers, i h...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>[this is one of the most powerful staplers, i ...</td>\n",
       "      <td>[one, powerful, staplers, used, claim, finger,...</td>\n",
       "      <td>[one, power, stapler, use, claim, finger, oper...</td>\n",
       "      <td>[one, powerful, staplers, use, claim, finger, ...</td>\n",
       "      <td>[(one, CD), (powerful, JJ), (staplers, NNS), (...</td>\n",
       "      <td>[powerful, staplers, claim, finger, operation,...</td>\n",
       "      <td>powerful staplers claim finger operation true ...</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2824</th>\n",
       "      <td>we use zebra pens in our office and they last ...</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>[we use zebra pens in our office and they last...</td>\n",
       "      <td>[use, zebra, pens, office, last, well, write, ...</td>\n",
       "      <td>[use, zebra, pen, offic, last, well, write, ni...</td>\n",
       "      <td>[use, zebra, pen, office, last, well, write, n...</td>\n",
       "      <td>[(use, NN), (zebra, NN), (pens, VBZ), (office,...</td>\n",
       "      <td>[use, zebra, office, last, well, write, nice, ...</td>\n",
       "      <td>use zebra office last well write nice fine tip...</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  1442 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              reviewText  overall  label  \\\n",
       "5527   interestingly, you can open this binder with e...        4      0   \n",
       "27611  these scotch reusable strips for lightweight m...        5      0   \n",
       "1564   these are good, standard solid labels from ave...        4      1   \n",
       "10206  this is one of the most powerful staplers, i h...        4      0   \n",
       "2824   we use zebra pens in our office and they last ...        5      0   \n",
       "\n",
       "                                                sentence  \\\n",
       "5527   [interestingly, you can open this binder with ...   \n",
       "27611  [these scotch reusable strips for lightweight ...   \n",
       "1564   [these are good, standard solid labels from av...   \n",
       "10206  [this is one of the most powerful staplers, i ...   \n",
       "2824   [we use zebra pens in our office and they last...   \n",
       "\n",
       "                                                  tokens  \\\n",
       "5527   [interestingly, open, binder, either, bottom, ...   \n",
       "27611  [scotch, reusable, strips, lightweight, mounti...   \n",
       "1564   [good, standard, solid, labels, avery, templat...   \n",
       "10206  [one, powerful, staplers, used, claim, finger,...   \n",
       "2824   [use, zebra, pens, office, last, well, write, ...   \n",
       "\n",
       "                                           stem_sentence  \\\n",
       "5527   [interestingli, open, binder, either, bottom, ...   \n",
       "27611  [scotch, reusabl, strip, lightweight, mount, t...   \n",
       "1564   [good, standard, solid, label, averi, templat,...   \n",
       "10206  [one, power, stapler, use, claim, finger, oper...   \n",
       "2824   [use, zebra, pen, offic, last, well, write, ni...   \n",
       "\n",
       "                                           lemm_sentence  \\\n",
       "5527   [interestingly, open, binder, either, bottom, ...   \n",
       "27611  [scotch, reusable, strip, lightweight, mount, ...   \n",
       "1564   [good, standard, solid, label, avery, template...   \n",
       "10206  [one, powerful, staplers, use, claim, finger, ...   \n",
       "2824   [use, zebra, pen, office, last, well, write, n...   \n",
       "\n",
       "                                                 pos_tag  \\\n",
       "5527   [(interestingly, RB), (open, JJ), (binder, NN)...   \n",
       "27611  [(scotch, NN), (reusable, JJ), (strips, NNS), ...   \n",
       "1564   [(good, JJ), (standard, NN), (solid, JJ), (lab...   \n",
       "10206  [(one, CD), (powerful, JJ), (staplers, NNS), (...   \n",
       "2824   [(use, NN), (zebra, NN), (pens, VBZ), (office,...   \n",
       "\n",
       "                                          filter_pos_tag  \\\n",
       "5527   [interestingly, open, binder, bottom, top, tab...   \n",
       "27611  [scotch, reusable, strips, terrific, far, ever...   \n",
       "1564   [good, standard, solid, labels, avery, templat...   \n",
       "10206  [powerful, staplers, claim, finger, operation,...   \n",
       "2824   [use, zebra, office, last, well, write, nice, ...   \n",
       "\n",
       "                                          clean_sentence  ... participation  \\\n",
       "5527   interestingly open binder bottom top tabs clos...  ...             0   \n",
       "27611  scotch reusable strips terrific far everything...  ...             0   \n",
       "1564   good standard solid labels avery template sugg...  ...             0   \n",
       "10206  powerful staplers claim finger operation true ...  ...             0   \n",
       "2824   use zebra office last well write nice fine tip...  ...             0   \n",
       "\n",
       "       suprised  rig  omit  deceive  lapinator  purport  instal  rethink  \\\n",
       "5527          0    0     0        0          0        0       0        0   \n",
       "27611         0    1     0        0          0        0       0        0   \n",
       "1564          0    1     0        0          0        0       0        0   \n",
       "10206         0    0     0        0          0        0       0        0   \n",
       "2824          0    0     0        0          0        0       0        0   \n",
       "\n",
       "       prepay  \n",
       "5527        0  \n",
       "27611       0  \n",
       "1564        0  \n",
       "10206       0  \n",
       "2824        0  \n",
       "\n",
       "[5 rows x 1442 columns]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try with only feature list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# X = dataset[feature_list]\n",
    "# y = pd.DataFrame(dataset, columns = [\"label\"])\n",
    "\n",
    "# X_train , X_test , y_train , y_test = train_test_split(X, y, random_state=50,stratify=y,train_size=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8572614107883817\n"
     ]
    }
   ],
   "source": [
    "log_reg_model = LogisticRegressionCV(class_weight='balanced')\n",
    "log_reg_model.fit(X_train[feature_list], y_train)\n",
    "scores = log_reg_model.score(X_test[feature_list], y_test) # accuracy\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Making prediction on the train data\n",
    "y_train_pred = log_reg_model.predict_proba(X_train[feature_list])[:,1]\n",
    "\n",
    "#Making prediction on the test data\n",
    "y_pred = log_reg_model.predict_proba(X_test[feature_list])[:,1]\n",
    "\n",
    "y_train_pred=pd.Series(y_train_pred)\n",
    "y_pred=pd.Series(y_pred)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_bool= y_pred.apply(lambda x: 1 if x>=0.134 else 0)\n",
    "y_train_pred_bool= y_train_pred.apply(lambda x: 1 if x>=0.134 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1222,   777],\n",
       "       [  920, 30819]])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.confusion_matrix(y_train,y_train_pred_bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy    : 0.95\n",
      "Sensitivity : 0.97\n",
      "Specificity : 0.61\n",
      "Precision   : 0.98\n",
      "Recall      : 0.97\n",
      "F1_score    : 0.95\n"
     ]
    }
   ],
   "source": [
    "get_model_metrics(y_train,y_train_pred_bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  360,   497],\n",
       "       [  535, 13068]])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.confusion_matrix(y_test,y_pred_bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy    : 0.93\n",
      "Sensitivity : 0.96\n",
      "Specificity : 0.42\n",
      "Precision   : 0.96\n",
      "Recall      : 0.96\n",
      "F1_score    : 0.93\n"
     ]
    }
   ],
   "source": [
    "get_model_metrics(y_test,y_pred_bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "additional_features=feature_list+['#positive_sentences','#negative_sentences']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ink cartridges printer</th>\n",
       "      <th>mo file box</th>\n",
       "      <th>laser printer wireless</th>\n",
       "      <th>black white text</th>\n",
       "      <th>matter many times</th>\n",
       "      <th>amazon vine program</th>\n",
       "      <th>press power button</th>\n",
       "      <th>paper regular paper</th>\n",
       "      <th>pages cents page</th>\n",
       "      <th>cents page cents</th>\n",
       "      <th>...</th>\n",
       "      <th>rig</th>\n",
       "      <th>omit</th>\n",
       "      <th>deceive</th>\n",
       "      <th>lapinator</th>\n",
       "      <th>purport</th>\n",
       "      <th>instal</th>\n",
       "      <th>rethink</th>\n",
       "      <th>prepay</th>\n",
       "      <th>#positive_sentences</th>\n",
       "      <th>#negative_sentences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30346</th>\n",
       "      <td>-0.038525</td>\n",
       "      <td>-0.018863</td>\n",
       "      <td>-0.01806</td>\n",
       "      <td>-0.024957</td>\n",
       "      <td>-0.018863</td>\n",
       "      <td>-0.056932</td>\n",
       "      <td>-0.016335</td>\n",
       "      <td>-0.020375</td>\n",
       "      <td>-0.012175</td>\n",
       "      <td>-0.016335</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.440851</td>\n",
       "      <td>-0.012175</td>\n",
       "      <td>-0.005444</td>\n",
       "      <td>-0.00943</td>\n",
       "      <td>-0.013337</td>\n",
       "      <td>-0.212602</td>\n",
       "      <td>-0.0077</td>\n",
       "      <td>-0.005444</td>\n",
       "      <td>0.793065</td>\n",
       "      <td>-0.077773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466</th>\n",
       "      <td>-0.038525</td>\n",
       "      <td>-0.018863</td>\n",
       "      <td>-0.01806</td>\n",
       "      <td>-0.024957</td>\n",
       "      <td>-0.018863</td>\n",
       "      <td>-0.056932</td>\n",
       "      <td>-0.016335</td>\n",
       "      <td>-0.020375</td>\n",
       "      <td>-0.012175</td>\n",
       "      <td>-0.016335</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.440851</td>\n",
       "      <td>-0.012175</td>\n",
       "      <td>-0.005444</td>\n",
       "      <td>-0.00943</td>\n",
       "      <td>-0.013337</td>\n",
       "      <td>-0.212602</td>\n",
       "      <td>-0.0077</td>\n",
       "      <td>-0.005444</td>\n",
       "      <td>0.793065</td>\n",
       "      <td>-0.682361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4335</th>\n",
       "      <td>-0.038525</td>\n",
       "      <td>-0.018863</td>\n",
       "      <td>-0.01806</td>\n",
       "      <td>-0.024957</td>\n",
       "      <td>-0.018863</td>\n",
       "      <td>-0.056932</td>\n",
       "      <td>-0.016335</td>\n",
       "      <td>-0.020375</td>\n",
       "      <td>-0.012175</td>\n",
       "      <td>-0.016335</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.440851</td>\n",
       "      <td>-0.012175</td>\n",
       "      <td>-0.005444</td>\n",
       "      <td>-0.00943</td>\n",
       "      <td>-0.013337</td>\n",
       "      <td>-0.212602</td>\n",
       "      <td>-0.0077</td>\n",
       "      <td>-0.005444</td>\n",
       "      <td>-0.349900</td>\n",
       "      <td>-0.682361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37664</th>\n",
       "      <td>-0.038525</td>\n",
       "      <td>-0.018863</td>\n",
       "      <td>-0.01806</td>\n",
       "      <td>-0.024957</td>\n",
       "      <td>-0.018863</td>\n",
       "      <td>-0.056932</td>\n",
       "      <td>-0.016335</td>\n",
       "      <td>-0.020375</td>\n",
       "      <td>-0.012175</td>\n",
       "      <td>-0.016335</td>\n",
       "      <td>...</td>\n",
       "      <td>2.268338</td>\n",
       "      <td>-0.012175</td>\n",
       "      <td>-0.005444</td>\n",
       "      <td>-0.00943</td>\n",
       "      <td>-0.013337</td>\n",
       "      <td>-0.212602</td>\n",
       "      <td>-0.0077</td>\n",
       "      <td>-0.005444</td>\n",
       "      <td>1.174053</td>\n",
       "      <td>1.131403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35986</th>\n",
       "      <td>-0.038525</td>\n",
       "      <td>-0.018863</td>\n",
       "      <td>-0.01806</td>\n",
       "      <td>-0.024957</td>\n",
       "      <td>-0.018863</td>\n",
       "      <td>-0.056932</td>\n",
       "      <td>-0.016335</td>\n",
       "      <td>-0.020375</td>\n",
       "      <td>-0.012175</td>\n",
       "      <td>-0.016335</td>\n",
       "      <td>...</td>\n",
       "      <td>2.268338</td>\n",
       "      <td>-0.012175</td>\n",
       "      <td>-0.005444</td>\n",
       "      <td>-0.00943</td>\n",
       "      <td>-0.013337</td>\n",
       "      <td>-0.212602</td>\n",
       "      <td>-0.0077</td>\n",
       "      <td>-0.005444</td>\n",
       "      <td>-0.349900</td>\n",
       "      <td>-0.682361</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  1425 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       ink cartridges printer  mo file box  laser printer wireless  \\\n",
       "30346               -0.038525    -0.018863                -0.01806   \n",
       "466                 -0.038525    -0.018863                -0.01806   \n",
       "4335                -0.038525    -0.018863                -0.01806   \n",
       "37664               -0.038525    -0.018863                -0.01806   \n",
       "35986               -0.038525    -0.018863                -0.01806   \n",
       "\n",
       "       black white text  matter many times  amazon vine program  \\\n",
       "30346         -0.024957          -0.018863            -0.056932   \n",
       "466           -0.024957          -0.018863            -0.056932   \n",
       "4335          -0.024957          -0.018863            -0.056932   \n",
       "37664         -0.024957          -0.018863            -0.056932   \n",
       "35986         -0.024957          -0.018863            -0.056932   \n",
       "\n",
       "       press power button  paper regular paper  pages cents page  \\\n",
       "30346           -0.016335            -0.020375         -0.012175   \n",
       "466             -0.016335            -0.020375         -0.012175   \n",
       "4335            -0.016335            -0.020375         -0.012175   \n",
       "37664           -0.016335            -0.020375         -0.012175   \n",
       "35986           -0.016335            -0.020375         -0.012175   \n",
       "\n",
       "       cents page cents  ...       rig      omit   deceive  lapinator  \\\n",
       "30346         -0.016335  ... -0.440851 -0.012175 -0.005444   -0.00943   \n",
       "466           -0.016335  ... -0.440851 -0.012175 -0.005444   -0.00943   \n",
       "4335          -0.016335  ... -0.440851 -0.012175 -0.005444   -0.00943   \n",
       "37664         -0.016335  ...  2.268338 -0.012175 -0.005444   -0.00943   \n",
       "35986         -0.016335  ...  2.268338 -0.012175 -0.005444   -0.00943   \n",
       "\n",
       "        purport    instal  rethink    prepay  #positive_sentences  \\\n",
       "30346 -0.013337 -0.212602  -0.0077 -0.005444             0.793065   \n",
       "466   -0.013337 -0.212602  -0.0077 -0.005444             0.793065   \n",
       "4335  -0.013337 -0.212602  -0.0077 -0.005444            -0.349900   \n",
       "37664 -0.013337 -0.212602  -0.0077 -0.005444             1.174053   \n",
       "35986 -0.013337 -0.212602  -0.0077 -0.005444            -0.349900   \n",
       "\n",
       "       #negative_sentences  \n",
       "30346            -0.077773  \n",
       "466              -0.682361  \n",
       "4335             -0.682361  \n",
       "37664             1.131403  \n",
       "35986            -0.682361  \n",
       "\n",
       "[5 rows x 1425 columns]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train_1= pd.DataFrame(scaler.fit_transform(X_train[additional_features]), index=X_train.index, columns=additional_features)\n",
    "\n",
    "X_test_1= pd.DataFrame(scaler.transform(X_test[additional_features]), index=X_test.index, columns=additional_features)\n",
    "X_train_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8876901798063623\n"
     ]
    }
   ],
   "source": [
    "log_reg_model = LogisticRegressionCV(class_weight='balanced')\n",
    "log_reg_model.fit(X_train_1[additional_features], y_train)\n",
    "scores = log_reg_model.score(X_test_1[additional_features], y_test) # accuracy\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Making prediction on the train data\n",
    "y_train_pred = log_reg_model.predict_proba(X_train_1[additional_features])[:,1]\n",
    "\n",
    "#Making prediction on the test data\n",
    "y_pred = log_reg_model.predict_proba(X_test_1[additional_features])[:,1]\n",
    "\n",
    "y_train_pred=pd.Series(y_train_pred)\n",
    "y_pred=pd.Series(y_pred)\n",
    "\n",
    "y_pred_bool= y_pred.apply(lambda x: 1 if x>=0.134 else 0)\n",
    "y_train_pred_bool= y_train_pred.apply(lambda x: 1 if x>=0.134 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  512,  1487],\n",
       "       [  145, 31594]])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.confusion_matrix(y_train,y_train_pred_bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  153,   704],\n",
       "       [   73, 13530]])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.confusion_matrix(y_test,y_pred_bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy    : 0.95\n",
      "Sensitivity : 1.0\n",
      "Specificity : 0.26\n",
      "Precision   : 0.96\n",
      "Recall      : 1.0\n",
      "F1_score    : 0.94\n"
     ]
    }
   ],
   "source": [
    "get_model_metrics(y_train,y_train_pred_bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy    : 0.95\n",
      "Sensitivity : 0.99\n",
      "Specificity : 0.18\n",
      "Precision   : 0.95\n",
      "Recall      : 0.99\n",
      "F1_score    : 0.93\n"
     ]
    }
   ],
   "source": [
    "get_model_metrics(y_test,y_pred_bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.iloc[:100,:].to_csv('amazon_text_review_features.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[dataset['label']==0].to_csv('amazon_text_review_negative_features.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification with word vectors v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X=dataset['filter_pos_tag'].to_list()\n",
    "# y=dataset['label'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48198, 20)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_text=dataset['clean_sentence'].to_list()\n",
    "X_train_label=dataset['label'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48198"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(X_train_text,X_train_label, test_size=0.3,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "                dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "                lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "                ngram_range=(1, 1), preprocessor=None, stop_words='english',\n",
       "                strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect = CountVectorizer(stop_words='english',max_features=5000)\n",
    "vect = CountVectorizer(stop_words='english')\n",
    "vect.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_transformed = vect.transform(X_train)\n",
    "X_test_transformed =vect.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('quite', 20968),\n",
       " ('pretty', 20062),\n",
       " ('translucent', 27447),\n",
       " ('cover', 5717),\n",
       " ('bit', 2421),\n",
       " ('write', 30052),\n",
       " ('let', 14583),\n",
       " ('dry', 7777),\n",
       " ('version', 28913),\n",
       " ('little', 14857)]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# printing the vocabulary\n",
    "list(vect.vocabulary_.items())[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Bernoulli NB "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy:  0.9119390598138597\n",
      "Test accuracy:  0.9088520055325034\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "bnb = BernoulliNB()\n",
    "bnb.fit(X_train_transformed,y_train)\n",
    "\n",
    "# predict class\n",
    "pred_train_ys = bnb.predict(X_train_transformed)\n",
    "pred_test_ys = bnb.predict(X_test_transformed)\n",
    "\n",
    "# accuracy\n",
    "print(\"Train accuracy: \", accuracy_score(y_train, pred_train_ys))\n",
    "print(\"Test accuracy: \", accuracy_score(y_test, pred_test_ys))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  591,  1426],\n",
       "       [ 1545, 30176]])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_train, pred_train_ys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Multinomial NB\n",
    " - We expect this to work very well, giving high performance in accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "mnb = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy:  0.9484261070602881\n",
      "Test accuracy:  0.9423236514522821\n"
     ]
    }
   ],
   "source": [
    "#fit on training data\n",
    "mnb.fit(X_train_transformed, y_train)\n",
    "\n",
    "# predict class\n",
    "pred_train_ys = mnb.predict(X_train_transformed)\n",
    "pred_test_ys = mnb.predict(X_test_transformed)\n",
    "\n",
    "# accuracy\n",
    "print(\"Train accuracy: \", accuracy_score(y_train, pred_train_ys))\n",
    "print(\"Test accuracy: \", accuracy_score(y_test, pred_test_ys))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  809,  1208],\n",
       "       [  532, 31189]])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_train, pred_train_ys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - As expected, this performed really well\n",
    " - Remember that we used 5000 features!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using our word embeddings approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " We have two options here:\n",
    " \n",
    "1. Use pre-trained word vectors (Glove)\n",
    "\n",
    "2. Train our own vectors\n",
    "\n",
    "We'll explore both "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400000, 200)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.scripts.glove2word2vec import glove2word2vec\n",
    "glove_input_file = 'glove.6B.200d.txt'\n",
    "word2vec_output_file = 'glove.6B.200d.w2vformat.txt'\n",
    "glove2word2vec(glove_input_file, word2vec_output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "glove_model = KeyedVectors.load_word2vec_format(\"glove.6B.200d.w2vformat.txt\", binary=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentence vector by averaging word vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = stopwords.words(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sent_vec(sent):\n",
    "    wv_res = np.zeros(glove_model.vector_size)\n",
    "    ctr = 1\n",
    "    for w in sent:\n",
    "        if w in glove_model:\n",
    "            ctr += 1\n",
    "            wv_res += glove_model[w]\n",
    "    wv_res = wv_res/ctr\n",
    "    #return (wv_res, ctr)\n",
    "    return wv_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(dataset['filter_pos_tag'],dataset['label'], test_size=0.3,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_doc_vecs = []\n",
    "for doc in X_train:    \n",
    "    doc_words = [term for term in doc if term not in stop_words]\n",
    "    train_doc_vecs.append(sent_vec(doc_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_doc_vecs = []\n",
    "for doc in X_test:    \n",
    "    doc_words = [term for term in doc if term not in stop_words]\n",
    "    test_doc_vecs.append(sent_vec(doc_words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building a predictive model on the averaged word vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using a 'simple' logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l1',\n",
       "                   random_state=42, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg = LogisticRegression(penalty=\"l1\", random_state=42, C = 2)\n",
    "logreg.fit(train_doc_vecs,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy:  0.9418163495168652\n",
      "Test accuracy:  0.9432918395573997\n"
     ]
    }
   ],
   "source": [
    "pred_train_ys = logreg.predict(train_doc_vecs)\n",
    "pred_test_ys = logreg.predict(test_doc_vecs)\n",
    "print(\"Train accuracy: \", accuracy_score(pred_train_ys, y_train))\n",
    "print(\"Test accuracy: \", accuracy_score(pred_test_ys, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_positive_Prob</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.991460</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.945712</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.999866</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.997039</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.979068</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   is_positive_Prob  predicted\n",
       "0          0.991460          1\n",
       "1          0.945712          1\n",
       "2          0.999866          1\n",
       "3          0.997039          1\n",
       "4          0.979068          1"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "y_train_pred = logreg.predict_proba(train_doc_vecs)[:,1]\n",
    "# y_train_pred = y_train_pred.reshape(-1)\n",
    "y_train_pred_final = pd.DataFrame({'is_positive_Prob':y_train_pred})\n",
    "y_train_pred_final['predicted'] = y_train_pred_final.is_positive_Prob.map(lambda x: 1 if x > 0.7 else 0)\n",
    "y_train_pred_final.head()\n",
    "\n",
    "y_test_pred = logreg.predict_proba(test_doc_vecs)[:,1]\n",
    "y_test_pred_final = pd.DataFrame({'is_positive_Prob':y_test_pred})\n",
    "y_test_pred_final['predicted'] = y_test_pred_final.is_positive_Prob.map(lambda x: 1 if x > 0.7 else 0)\n",
    "y_test_pred_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy:  0.9418163495168652\n",
      "Test accuracy:  0.9432918395573997\n"
     ]
    }
   ],
   "source": [
    "print(\"Train accuracy: \", accuracy_score(pred_train_ys, y_train))\n",
    "print(\"Test accuracy: \", accuracy_score(pred_test_ys, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  496,   519],\n",
       "       [ 1521, 31202]])"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_train_pred_final.predicted, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  193,   242],\n",
       "       [  646, 13379]])"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test_pred_final.predicted, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training our own wordvectors on the data\n",
    "We'll create a combined text file to train our word vectors - more data is better. Although in this case we would still have just 7.7K instances to learn from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48198"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_comb = np.concatenate([X_train,X_test])\n",
    "len(X_comb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['great',\n",
       " 'marker',\n",
       " 'boards',\n",
       " 'size',\n",
       " 'perfect',\n",
       " 'shipment',\n",
       " 'super',\n",
       " 'fast',\n",
       " 'always']"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_comb[6000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import word2vec\n",
    "w2v = word2vec.Word2Vec(X_comb, window=2, min_count=2, sg = 1, size=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('tricky', 0.745678186416626),\n",
       " ('harder', 0.7006373405456543),\n",
       " ('awkward', 0.692467987537384),\n",
       " ('confusing', 0.6763489842414856),\n",
       " ('challenge', 0.6719896793365479)]"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v.most_similar(\"difficult\", topn=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sentence vectors by averaging vectors for words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sent_vec_w2v(sent):\n",
    "    wv_res = np.zeros(w2v.vector_size)\n",
    "    ctr = 1\n",
    "    for w in sent:\n",
    "        if w in w2v:\n",
    "            ctr += 1\n",
    "            wv_res += w2v[w]\n",
    "    wv_res = wv_res/ctr\n",
    "    return wv_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Getting the sentence vectors for the test and train sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33738,)"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_doc_vecs = []\n",
    "for doc in X_train:    \n",
    "    doc_words = [term for term in doc if term not in stop_words]\n",
    "    train_doc_vecs.append(sent_vec_w2v(doc_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33738"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_doc_vecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    31721\n",
       "0     2017\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_doc_vecs = []\n",
    "for doc in X_test:    \n",
    "    doc_words = [term for term in doc if term not in stop_words]\n",
    "    test_doc_vecs.append(sent_vec_w2v(doc_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression,LogisticRegressionCV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression( random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=42, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg.fit(train_doc_vecs,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_train_ys = logreg.predict_proba(train_doc_vecs)\n",
    "pred_test_ys = logreg.predict_proba(test_doc_vecs)\n",
    "# print(\"Train accuracy: \", accuracy_score(pred_train_ys, y_train))\n",
    "# print(\"Test accuracy: \", accuracy_score(pred_test_ys, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_positive_Prob</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.999711</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.974641</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.999411</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.988494</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.969478</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   is_positive_Prob  predicted\n",
       "0          0.999711          1\n",
       "1          0.974641          1\n",
       "2          0.999411          1\n",
       "3          0.988494          1\n",
       "4          0.969478          1"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "y_train_pred = logreg.predict_proba(train_doc_vecs)[:,1]\n",
    "# y_train_pred = y_train_pred.reshape(-1)\n",
    "y_train_pred_final = pd.DataFrame({'is_positive_Prob':y_train_pred})\n",
    "y_train_pred_final['predicted'] = y_train_pred_final.is_positive_Prob.map(lambda x: 1 if x > 0.7 else 0)\n",
    "y_train_pred_final.head()\n",
    "\n",
    "y_test_pred = logreg.predict_proba(test_doc_vecs)[:,1]\n",
    "y_test_pred_final = pd.DataFrame({'is_positive_Prob':y_test_pred})\n",
    "y_test_pred_final['predicted'] = y_test_pred_final.is_positive_Prob.map(lambda x: 1 if x > 0.7 else 0)\n",
    "y_test_pred_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  550,   494],\n",
       "       [ 1467, 31227]])"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_train_pred_final.predicted, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  210,   223],\n",
       "       [  629, 13398]])"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test_pred_final.predicted, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
