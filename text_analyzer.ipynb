{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#import plots\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "import string\n",
    "import logging\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.random.seed(0)\n",
    "import re\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import metrics\n",
    "\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import wordpunct_tokenize\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem import LancasterStemmer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.util import ngrams\n",
    "\n",
    "\n",
    "from collections import Counter\n",
    "from nltk.probability import FreqDist\n",
    "\n",
    "from sklearn.linear_model import LogisticRegressionCV,LogisticRegression\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "#TextBlob\n",
    "from textblob import TextBlob\n",
    "from textblob import Word\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'test pretty print which will be helpful for json and list variable'\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "pp.pprint(\"test pretty print which will be helpful for json and list variable\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asin</th>\n",
       "      <th>helpful</th>\n",
       "      <th>overall</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>summary</th>\n",
       "      <th>unixReviewTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B00000JBLH</td>\n",
       "      <td>[3, 4]</td>\n",
       "      <td>5</td>\n",
       "      <td>I bought my first HP12C in about 1984 or so, a...</td>\n",
       "      <td>09 3, 2004</td>\n",
       "      <td>A32T2H8150OJLU</td>\n",
       "      <td>ARH</td>\n",
       "      <td>A solid performer, and long time friend</td>\n",
       "      <td>1094169600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B00000JBLH</td>\n",
       "      <td>[7, 9]</td>\n",
       "      <td>5</td>\n",
       "      <td>WHY THIS BELATED REVIEW? I feel very obliged t...</td>\n",
       "      <td>12 15, 2007</td>\n",
       "      <td>A3MAFS04ZABRGO</td>\n",
       "      <td>Let it Be \"Alan\"</td>\n",
       "      <td>Price of GOLD is up, so don't bury the golden ...</td>\n",
       "      <td>1197676800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B00000JBLH</td>\n",
       "      <td>[3, 3]</td>\n",
       "      <td>2</td>\n",
       "      <td>I have an HP 48GX that has been kicking for mo...</td>\n",
       "      <td>01 1, 2011</td>\n",
       "      <td>A1F1A0QQP2XVH5</td>\n",
       "      <td>Mark B</td>\n",
       "      <td>Good functionality, but not durable like old HPs</td>\n",
       "      <td>1293840000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B00000JBLH</td>\n",
       "      <td>[7, 8]</td>\n",
       "      <td>5</td>\n",
       "      <td>I've started doing more finance stuff recently...</td>\n",
       "      <td>04 19, 2006</td>\n",
       "      <td>A49R5DBXXQDE5</td>\n",
       "      <td>R. D Johnson</td>\n",
       "      <td>One of the last of an almost extinct species</td>\n",
       "      <td>1145404800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B00000JBLH</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>5</td>\n",
       "      <td>For simple calculations and discounted cash fl...</td>\n",
       "      <td>08 4, 2013</td>\n",
       "      <td>A2XRMQA6PJ5ZJ8</td>\n",
       "      <td>Roger J. Buffington</td>\n",
       "      <td>Still the best</td>\n",
       "      <td>1375574400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         asin helpful  overall  \\\n",
       "0  B00000JBLH  [3, 4]        5   \n",
       "1  B00000JBLH  [7, 9]        5   \n",
       "2  B00000JBLH  [3, 3]        2   \n",
       "3  B00000JBLH  [7, 8]        5   \n",
       "4  B00000JBLH  [0, 0]        5   \n",
       "\n",
       "                                          reviewText   reviewTime  \\\n",
       "0  I bought my first HP12C in about 1984 or so, a...   09 3, 2004   \n",
       "1  WHY THIS BELATED REVIEW? I feel very obliged t...  12 15, 2007   \n",
       "2  I have an HP 48GX that has been kicking for mo...   01 1, 2011   \n",
       "3  I've started doing more finance stuff recently...  04 19, 2006   \n",
       "4  For simple calculations and discounted cash fl...   08 4, 2013   \n",
       "\n",
       "       reviewerID         reviewerName  \\\n",
       "0  A32T2H8150OJLU                  ARH   \n",
       "1  A3MAFS04ZABRGO     Let it Be \"Alan\"   \n",
       "2  A1F1A0QQP2XVH5               Mark B   \n",
       "3   A49R5DBXXQDE5         R. D Johnson   \n",
       "4  A2XRMQA6PJ5ZJ8  Roger J. Buffington   \n",
       "\n",
       "                                             summary  unixReviewTime  \n",
       "0            A solid performer, and long time friend      1094169600  \n",
       "1  Price of GOLD is up, so don't bury the golden ...      1197676800  \n",
       "2   Good functionality, but not durable like old HPs      1293840000  \n",
       "3       One of the last of an almost extinct species      1145404800  \n",
       "4                                     Still the best      1375574400  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=pd.read_json('reviews_Office_Products_5.json',lines=True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewText</th>\n",
       "      <th>overall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I bought my first HP12C in about 1984 or so, a...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WHY THIS BELATED REVIEW? I feel very obliged t...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I have an HP 48GX that has been kicking for mo...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I've started doing more finance stuff recently...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>For simple calculations and discounted cash fl...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          reviewText overall\n",
       "0  I bought my first HP12C in about 1984 or so, a...       5\n",
       "1  WHY THIS BELATED REVIEW? I feel very obliged t...       5\n",
       "2  I have an HP 48GX that has been kicking for mo...       2\n",
       "3  I've started doing more finance stuff recently...       5\n",
       "4  For simple calculations and discounted cash fl...       5"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['overall'] = data['overall'].astype(object) # fix datatype error\n",
    "dataset = {\"reviewText\": data[\"reviewText\"], \"overall\": data[\"overall\"]  }\n",
    "dataset = pd.DataFrame(data = dataset)\n",
    "dataset = dataset.dropna()\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "reviewText    object\n",
       "overall       object\n",
       "dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48198, 2)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['overall']=dataset['overall'].astype('int64')\n",
    "dataset = dataset[dataset[\"overall\"] != 3] # need datatype=object\n",
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewText</th>\n",
       "      <th>overall</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [reviewText, overall, label]\n",
       "Index: []"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"label\"] = dataset[\"overall\"].apply(lambda x : 1 if x > 3 else 0)\n",
    "dataset[dataset[\"label\"].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewText</th>\n",
       "      <th>overall</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I bought my first HP12C in about 1984 or so, a...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WHY THIS BELATED REVIEW? I feel very obliged t...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I have an HP 48GX that has been kicking for mo...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I've started doing more finance stuff recently...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>For simple calculations and discounted cash fl...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          reviewText  overall  label\n",
       "0  I bought my first HP12C in about 1984 or so, a...        5      1\n",
       "1  WHY THIS BELATED REVIEW? I feel very obliged t...        5      1\n",
       "2  I have an HP 48GX that has been kicking for mo...        2      0\n",
       "3  I've started doing more finance stuff recently...        5      1\n",
       "4  For simple calculations and discounted cash fl...        5      1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    45342\n",
       "0     2856\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5    30327\n",
       "4    15015\n",
       "2     1726\n",
       "1     1130\n",
       "Name: overall, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.overall.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "entire_dataset=dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# X = pd.DataFrame(entire_dataset, columns = [\"reviewText\",\"label\"])\n",
    "# y = pd.DataFrame(entire_dataset, columns = [\"label\"])\n",
    "\n",
    "# dataset , X_test , y_train , y_test = train_test_split(X, y, random_state=50,stratify=y,train_size=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words=set(stopwords.words(\"english\"))\n",
    "\n",
    "dataset['reviewText']=dataset['reviewText'].str.lower()\n",
    "\n",
    "dataset['sentence']=dataset['reviewText'].apply(lambda x: sent_tokenize(x))\n",
    "\n",
    "dataset['tokens']=dataset['reviewText'].apply(lambda x: word_tokenize(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hewy', 'are', 'qwerty']\n",
      "['hey', '?']\n"
     ]
    }
   ],
   "source": [
    "def get_clean_token_list(words):\n",
    "    clean_words=[]\n",
    "    for word in words:\n",
    "        flag=True\n",
    "        for letter in word:\n",
    "            if letter.isdigit() or letter in string.punctuation:\n",
    "                flag=False\n",
    "        if flag:\n",
    "            clean_words.append(word)\n",
    "    return clean_words\n",
    "\n",
    "print(get_clean_token_list([\"hewy\",\"ho!w\",\"are\",\"yo6u\",\"?dd\",\"111\",\"qwerty\"]))\n",
    "\n",
    "def remove_stopwords(words):\n",
    "    \"\"\"\n",
    "    pass series get series\n",
    "    \"\"\"\n",
    "    filtered_sent=[]\n",
    "    for word in words:\n",
    "        if word not in stop_words:\n",
    "            filtered_sent.append(word)\n",
    "    return filtered_sent\n",
    "\n",
    "\n",
    "print(remove_stopwords([\"hey\",\"how\",\"are\",\"you\",\"?\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [bought, first, hp12c, 1984, ,, served, faithf...\n",
       "1    [belated, review, ?, feel, obliged, share, vie...\n",
       "2    [hp, 48gx, kicking, twenty, years, hp, 11, 25,...\n",
       "3    ['ve, started, finance, stuff, recently, went,...\n",
       "4    [simple, calculations, discounted, cash, flows...\n",
       "Name: tokens, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['tokens']=dataset['tokens'].apply(remove_stopwords)\n",
    "\n",
    "dataset['tokens'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [bought, first, served, faithfully, lost, trav...\n",
       "1    [belated, review, feel, obliged, share, views,...\n",
       "2    [hp, kicking, twenty, years, hp, years, old, s...\n",
       "3    [started, finance, stuff, recently, went, look...\n",
       "4    [simple, calculations, discounted, cash, flows...\n",
       "Name: tokens, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['tokens']=dataset['tokens'].apply(get_clean_token_list)\n",
    "\n",
    "dataset['tokens'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "stem = PorterStemmer()\n",
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def stem_sentence(sentence):\n",
    "    stem_sentence=[]\n",
    "    for word in sentence:\n",
    "        stem_sentence.append(stem.stem(word))\n",
    "    return stem_sentence\n",
    "\n",
    "def lemmatize_sentence(sentence):\n",
    "    lem_sentence=[]\n",
    "    for word in sentence:\n",
    "        lem_sentence.append(wordnet_lemmatizer.lemmatize(word, pos=\"v\"))\n",
    "    return lem_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewText</th>\n",
       "      <th>overall</th>\n",
       "      <th>label</th>\n",
       "      <th>sentence</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i bought my first hp12c in about 1984 or so, a...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>[i bought my first hp12c in about 1984 or so, ...</td>\n",
       "      <td>[bought, first, served, faithfully, lost, trav...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>why this belated review? i feel very obliged t...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>[why this belated review?, i feel very obliged...</td>\n",
       "      <td>[belated, review, feel, obliged, share, views,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i have an hp 48gx that has been kicking for mo...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>[i have an hp 48gx that has been kicking for m...</td>\n",
       "      <td>[hp, kicking, twenty, years, hp, years, old, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i've started doing more finance stuff recently...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>[i've started doing more finance stuff recentl...</td>\n",
       "      <td>[started, finance, stuff, recently, went, look...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>for simple calculations and discounted cash fl...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>[for simple calculations and discounted cash f...</td>\n",
       "      <td>[simple, calculations, discounted, cash, flows...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          reviewText  overall  label  \\\n",
       "0  i bought my first hp12c in about 1984 or so, a...        5      1   \n",
       "1  why this belated review? i feel very obliged t...        5      1   \n",
       "2  i have an hp 48gx that has been kicking for mo...        2      0   \n",
       "3  i've started doing more finance stuff recently...        5      1   \n",
       "4  for simple calculations and discounted cash fl...        5      1   \n",
       "\n",
       "                                            sentence  \\\n",
       "0  [i bought my first hp12c in about 1984 or so, ...   \n",
       "1  [why this belated review?, i feel very obliged...   \n",
       "2  [i have an hp 48gx that has been kicking for m...   \n",
       "3  [i've started doing more finance stuff recentl...   \n",
       "4  [for simple calculations and discounted cash f...   \n",
       "\n",
       "                                              tokens  \n",
       "0  [bought, first, served, faithfully, lost, trav...  \n",
       "1  [belated, review, feel, obliged, share, views,...  \n",
       "2  [hp, kicking, twenty, years, hp, years, old, s...  \n",
       "3  [started, finance, stuff, recently, went, look...  \n",
       "4  [simple, calculations, discounted, cash, flows...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokens</th>\n",
       "      <th>lemm_sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[bought, first, served, faithfully, lost, trav...</td>\n",
       "      <td>[buy, first, serve, faithfully, lose, travel, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[belated, review, feel, obliged, share, views,...</td>\n",
       "      <td>[belated, review, feel, oblige, share, view, o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[hp, kicking, twenty, years, hp, years, old, s...</td>\n",
       "      <td>[hp, kick, twenty, years, hp, years, old, stil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[started, finance, stuff, recently, went, look...</td>\n",
       "      <td>[start, finance, stuff, recently, go, look, go...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[simple, calculations, discounted, cash, flows...</td>\n",
       "      <td>[simple, calculations, discount, cash, flow, o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[mba, hard, believe, calculator, learned, use,...</td>\n",
       "      <td>[mba, hard, believe, calculator, learn, use, u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[hp, ever, since, first, available, roughly, t...</td>\n",
       "      <td>[hp, ever, since, first, available, roughly, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[bought, boss, lost, loves, calculator, would,...</td>\n",
       "      <td>[buy, boss, lose, love, calculator, would, cat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[simple, calculator, handles, typical, math, l...</td>\n",
       "      <td>[simple, calculator, handle, typical, math, la...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[love, calculator, big, numbers, calculate, ex...</td>\n",
       "      <td>[love, calculator, big, number, calculate, exc...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              tokens  \\\n",
       "0  [bought, first, served, faithfully, lost, trav...   \n",
       "1  [belated, review, feel, obliged, share, views,...   \n",
       "2  [hp, kicking, twenty, years, hp, years, old, s...   \n",
       "3  [started, finance, stuff, recently, went, look...   \n",
       "4  [simple, calculations, discounted, cash, flows...   \n",
       "5  [mba, hard, believe, calculator, learned, use,...   \n",
       "6  [hp, ever, since, first, available, roughly, t...   \n",
       "7  [bought, boss, lost, loves, calculator, would,...   \n",
       "8  [simple, calculator, handles, typical, math, l...   \n",
       "9  [love, calculator, big, numbers, calculate, ex...   \n",
       "\n",
       "                                       lemm_sentence  \n",
       "0  [buy, first, serve, faithfully, lose, travel, ...  \n",
       "1  [belated, review, feel, oblige, share, view, o...  \n",
       "2  [hp, kick, twenty, years, hp, years, old, stil...  \n",
       "3  [start, finance, stuff, recently, go, look, go...  \n",
       "4  [simple, calculations, discount, cash, flow, o...  \n",
       "5  [mba, hard, believe, calculator, learn, use, u...  \n",
       "6  [hp, ever, since, first, available, roughly, t...  \n",
       "7  [buy, boss, lose, love, calculator, would, cat...  \n",
       "8  [simple, calculator, handle, typical, math, la...  \n",
       "9  [love, calculator, big, number, calculate, exc...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['stem_sentence']=dataset['tokens'].apply(lambda x: stem_sentence(x))\n",
    "\n",
    "dataset[['tokens','stem_sentence']].head(10)\n",
    "\n",
    "dataset['lemm_sentence']=dataset['tokens'].apply(lambda x: lemmatize_sentence(x))\n",
    "\n",
    "dataset[['tokens','lemm_sentence']].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewText</th>\n",
       "      <th>overall</th>\n",
       "      <th>label</th>\n",
       "      <th>sentence</th>\n",
       "      <th>tokens</th>\n",
       "      <th>stem_sentence</th>\n",
       "      <th>lemm_sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i bought my first hp12c in about 1984 or so, a...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>[i bought my first hp12c in about 1984 or so, ...</td>\n",
       "      <td>[bought, first, served, faithfully, lost, trav...</td>\n",
       "      <td>[bought, first, serv, faith, lost, travel, sea...</td>\n",
       "      <td>[buy, first, serve, faithfully, lose, travel, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>why this belated review? i feel very obliged t...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>[why this belated review?, i feel very obliged...</td>\n",
       "      <td>[belated, review, feel, obliged, share, views,...</td>\n",
       "      <td>[belat, review, feel, oblig, share, view, old,...</td>\n",
       "      <td>[belated, review, feel, oblige, share, view, o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i have an hp 48gx that has been kicking for mo...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>[i have an hp 48gx that has been kicking for m...</td>\n",
       "      <td>[hp, kicking, twenty, years, hp, years, old, s...</td>\n",
       "      <td>[hp, kick, twenti, year, hp, year, old, still,...</td>\n",
       "      <td>[hp, kick, twenty, years, hp, years, old, stil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i've started doing more finance stuff recently...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>[i've started doing more finance stuff recentl...</td>\n",
       "      <td>[started, finance, stuff, recently, went, look...</td>\n",
       "      <td>[start, financ, stuff, recent, went, look, goo...</td>\n",
       "      <td>[start, finance, stuff, recently, go, look, go...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>for simple calculations and discounted cash fl...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>[for simple calculations and discounted cash f...</td>\n",
       "      <td>[simple, calculations, discounted, cash, flows...</td>\n",
       "      <td>[simpl, calcul, discount, cash, flow, one, sti...</td>\n",
       "      <td>[simple, calculations, discount, cash, flow, o...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          reviewText  overall  label  \\\n",
       "0  i bought my first hp12c in about 1984 or so, a...        5      1   \n",
       "1  why this belated review? i feel very obliged t...        5      1   \n",
       "2  i have an hp 48gx that has been kicking for mo...        2      0   \n",
       "3  i've started doing more finance stuff recently...        5      1   \n",
       "4  for simple calculations and discounted cash fl...        5      1   \n",
       "\n",
       "                                            sentence  \\\n",
       "0  [i bought my first hp12c in about 1984 or so, ...   \n",
       "1  [why this belated review?, i feel very obliged...   \n",
       "2  [i have an hp 48gx that has been kicking for m...   \n",
       "3  [i've started doing more finance stuff recentl...   \n",
       "4  [for simple calculations and discounted cash f...   \n",
       "\n",
       "                                              tokens  \\\n",
       "0  [bought, first, served, faithfully, lost, trav...   \n",
       "1  [belated, review, feel, obliged, share, views,...   \n",
       "2  [hp, kicking, twenty, years, hp, years, old, s...   \n",
       "3  [started, finance, stuff, recently, went, look...   \n",
       "4  [simple, calculations, discounted, cash, flows...   \n",
       "\n",
       "                                       stem_sentence  \\\n",
       "0  [bought, first, serv, faith, lost, travel, sea...   \n",
       "1  [belat, review, feel, oblig, share, view, old,...   \n",
       "2  [hp, kick, twenti, year, hp, year, old, still,...   \n",
       "3  [start, financ, stuff, recent, went, look, goo...   \n",
       "4  [simpl, calcul, discount, cash, flow, one, sti...   \n",
       "\n",
       "                                       lemm_sentence  \n",
       "0  [buy, first, serve, faithfully, lose, travel, ...  \n",
       "1  [belated, review, feel, oblige, share, view, o...  \n",
       "2  [hp, kick, twenty, years, hp, years, old, stil...  \n",
       "3  [start, finance, stuff, recently, go, look, go...  \n",
       "4  [simple, calculations, discount, cash, flow, o...  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('use', 61375),\n",
       " ('print', 30238),\n",
       " ('printer', 29298),\n",
       " ('one', 27926),\n",
       " ('paper', 26963),\n",
       " ('like', 26040),\n",
       " ('work', 24809),\n",
       " ('get', 24176),\n",
       " ('make', 22934),\n",
       " ('label', 21503)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews=[word for review in dataset['lemm_sentence'] for word in review]\n",
    "\n",
    "fdist_reviews = FreqDist(reviews)\n",
    "\n",
    "fdist_reviews.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('use', 58058),\n",
       " ('print', 28033),\n",
       " ('printer', 26633),\n",
       " ('one', 25759),\n",
       " ('paper', 25196),\n",
       " ('like', 24400),\n",
       " ('work', 22932),\n",
       " ('get', 21847),\n",
       " ('make', 21464),\n",
       " ('label', 20859)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive_reviews=dataset[dataset['label']==1]['lemm_sentence']\n",
    "\n",
    "positive_tokens=[word for review in positive_reviews for word in review]\n",
    "\n",
    "fdist_positive_tokens = FreqDist(positive_tokens)\n",
    "\n",
    "fdist_positive_tokens.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('use', 3317),\n",
       " ('printer', 2665),\n",
       " ('get', 2329),\n",
       " ('print', 2205),\n",
       " ('one', 2167),\n",
       " ('would', 1954),\n",
       " ('work', 1877),\n",
       " ('paper', 1767),\n",
       " ('ink', 1652),\n",
       " ('like', 1640)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "negative_reviews=dataset[dataset['label']==0]['lemm_sentence']\n",
    "\n",
    "negative_reviews=[word for review in negative_reviews for word in review]\n",
    "\n",
    "fdist_neagtive_tokens = FreqDist(negative_reviews)\n",
    "\n",
    "fdist_neagtive_tokens.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10454"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(fdist_neagtive_tokens.most_common())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32915"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(fdist_positive_tokens.most_common())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequency_tokens={ x[0]:x[1] for x in fdist_positive_tokens.most_common()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [(bought, VBD), (first, RB), (served, VBN), (f...\n",
       "1    [(belated, VBN), (review, NN), (feel, NN), (ob...\n",
       "2    [(hp, NN), (kicking, VBG), (twenty, CD), (year...\n",
       "3    [(started, VBN), (finance, NN), (stuff, NN), (...\n",
       "4    [(simple, JJ), (calculations, NNS), (discounte...\n",
       "Name: pos_tag, dtype: object"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['pos_tag']=dataset['tokens'].apply(lambda x: nltk.pos_tag(x))\n",
    "\n",
    "dataset['pos_tag'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewText</th>\n",
       "      <th>overall</th>\n",
       "      <th>label</th>\n",
       "      <th>sentence</th>\n",
       "      <th>tokens</th>\n",
       "      <th>stem_sentence</th>\n",
       "      <th>lemm_sentence</th>\n",
       "      <th>pos_tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i bought my first hp12c in about 1984 or so, a...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>[i bought my first hp12c in about 1984 or so, ...</td>\n",
       "      <td>[bought, first, served, faithfully, lost, trav...</td>\n",
       "      <td>[bought, first, serv, faith, lost, travel, sea...</td>\n",
       "      <td>[buy, first, serve, faithfully, lose, travel, ...</td>\n",
       "      <td>[(bought, VBD), (first, RB), (served, VBN), (f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>why this belated review? i feel very obliged t...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>[why this belated review?, i feel very obliged...</td>\n",
       "      <td>[belated, review, feel, obliged, share, views,...</td>\n",
       "      <td>[belat, review, feel, oblig, share, view, old,...</td>\n",
       "      <td>[belated, review, feel, oblige, share, view, o...</td>\n",
       "      <td>[(belated, VBN), (review, NN), (feel, NN), (ob...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i have an hp 48gx that has been kicking for mo...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>[i have an hp 48gx that has been kicking for m...</td>\n",
       "      <td>[hp, kicking, twenty, years, hp, years, old, s...</td>\n",
       "      <td>[hp, kick, twenti, year, hp, year, old, still,...</td>\n",
       "      <td>[hp, kick, twenty, years, hp, years, old, stil...</td>\n",
       "      <td>[(hp, NN), (kicking, VBG), (twenty, CD), (year...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i've started doing more finance stuff recently...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>[i've started doing more finance stuff recentl...</td>\n",
       "      <td>[started, finance, stuff, recently, went, look...</td>\n",
       "      <td>[start, financ, stuff, recent, went, look, goo...</td>\n",
       "      <td>[start, finance, stuff, recently, go, look, go...</td>\n",
       "      <td>[(started, VBN), (finance, NN), (stuff, NN), (...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>for simple calculations and discounted cash fl...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>[for simple calculations and discounted cash f...</td>\n",
       "      <td>[simple, calculations, discounted, cash, flows...</td>\n",
       "      <td>[simpl, calcul, discount, cash, flow, one, sti...</td>\n",
       "      <td>[simple, calculations, discount, cash, flow, o...</td>\n",
       "      <td>[(simple, JJ), (calculations, NNS), (discounte...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          reviewText  overall  label  \\\n",
       "0  i bought my first hp12c in about 1984 or so, a...        5      1   \n",
       "1  why this belated review? i feel very obliged t...        5      1   \n",
       "2  i have an hp 48gx that has been kicking for mo...        2      0   \n",
       "3  i've started doing more finance stuff recently...        5      1   \n",
       "4  for simple calculations and discounted cash fl...        5      1   \n",
       "\n",
       "                                            sentence  \\\n",
       "0  [i bought my first hp12c in about 1984 or so, ...   \n",
       "1  [why this belated review?, i feel very obliged...   \n",
       "2  [i have an hp 48gx that has been kicking for m...   \n",
       "3  [i've started doing more finance stuff recentl...   \n",
       "4  [for simple calculations and discounted cash f...   \n",
       "\n",
       "                                              tokens  \\\n",
       "0  [bought, first, served, faithfully, lost, trav...   \n",
       "1  [belated, review, feel, obliged, share, views,...   \n",
       "2  [hp, kicking, twenty, years, hp, years, old, s...   \n",
       "3  [started, finance, stuff, recently, went, look...   \n",
       "4  [simple, calculations, discounted, cash, flows...   \n",
       "\n",
       "                                       stem_sentence  \\\n",
       "0  [bought, first, serv, faith, lost, travel, sea...   \n",
       "1  [belat, review, feel, oblig, share, view, old,...   \n",
       "2  [hp, kick, twenti, year, hp, year, old, still,...   \n",
       "3  [start, financ, stuff, recent, went, look, goo...   \n",
       "4  [simpl, calcul, discount, cash, flow, one, sti...   \n",
       "\n",
       "                                       lemm_sentence  \\\n",
       "0  [buy, first, serve, faithfully, lose, travel, ...   \n",
       "1  [belated, review, feel, oblige, share, view, o...   \n",
       "2  [hp, kick, twenty, years, hp, years, old, stil...   \n",
       "3  [start, finance, stuff, recently, go, look, go...   \n",
       "4  [simple, calculations, discount, cash, flow, o...   \n",
       "\n",
       "                                             pos_tag  \n",
       "0  [(bought, VBD), (first, RB), (served, VBN), (f...  \n",
       "1  [(belated, VBN), (review, NN), (feel, NN), (ob...  \n",
       "2  [(hp, NN), (kicking, VBG), (twenty, CD), (year...  \n",
       "3  [(started, VBN), (finance, NN), (stuff, NN), (...  \n",
       "4  [(simple, JJ), (calculations, NNS), (discounte...  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['asked', 'review', 'scale']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# keep only noun adjective and adverb\n",
    "keep_tags=[\"JJ\",\"JJR\",\"JJS\",\"RB\",\"RBR\",\"RBS\",\"UH\",\"NN\",\"NNS\",\"NNP\",\"NNPS\"]\n",
    "\n",
    "def filter_tag(pos_list):\n",
    "    pos_clean_list=[]\n",
    "    for t in pos_list:\n",
    "        if t[1] in keep_tags:\n",
    "            pos_clean_list.append(t[0])\n",
    "    return pos_clean_list\n",
    "\n",
    "filter_tag([('asked', 'RB'), ('review', 'NN'), ('scale', 'RBS')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokens</th>\n",
       "      <th>filter_pos_tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[bought, first, served, faithfully, lost, trav...</td>\n",
       "      <td>[first, faithfully, travelling, difficult, com...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[belated, review, feel, obliged, share, views,...</td>\n",
       "      <td>[review, feel, share, views, old, workhorse, g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[hp, kicking, twenty, years, hp, years, old, s...</td>\n",
       "      <td>[hp, years, years, old, still, flawless, month...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[started, finance, stuff, recently, went, look...</td>\n",
       "      <td>[finance, stuff, recently, good, calculator, p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[simple, calculations, discounted, cash, flows...</td>\n",
       "      <td>[simple, calculations, cash, flows, still, bes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[mba, hard, believe, calculator, learned, use,...</td>\n",
       "      <td>[mba, hard, calculator, use, undergraduate, bu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[hp, ever, since, first, available, roughly, t...</td>\n",
       "      <td>[hp, ever, first, available, roughly, years, a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[bought, boss, lost, loves, calculator, would,...</td>\n",
       "      <td>[boss, loves, calculator, really, helps, day, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[simple, calculator, handles, typical, math, l...</td>\n",
       "      <td>[simple, calculator, handles, typical, math, l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[love, calculator, big, numbers, calculate, ex...</td>\n",
       "      <td>[love, calculator, big, numbers, excellent, ea...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              tokens  \\\n",
       "0  [bought, first, served, faithfully, lost, trav...   \n",
       "1  [belated, review, feel, obliged, share, views,...   \n",
       "2  [hp, kicking, twenty, years, hp, years, old, s...   \n",
       "3  [started, finance, stuff, recently, went, look...   \n",
       "4  [simple, calculations, discounted, cash, flows...   \n",
       "5  [mba, hard, believe, calculator, learned, use,...   \n",
       "6  [hp, ever, since, first, available, roughly, t...   \n",
       "7  [bought, boss, lost, loves, calculator, would,...   \n",
       "8  [simple, calculator, handles, typical, math, l...   \n",
       "9  [love, calculator, big, numbers, calculate, ex...   \n",
       "\n",
       "                                      filter_pos_tag  \n",
       "0  [first, faithfully, travelling, difficult, com...  \n",
       "1  [review, feel, share, views, old, workhorse, g...  \n",
       "2  [hp, years, years, old, still, flawless, month...  \n",
       "3  [finance, stuff, recently, good, calculator, p...  \n",
       "4  [simple, calculations, cash, flows, still, bes...  \n",
       "5  [mba, hard, calculator, use, undergraduate, bu...  \n",
       "6  [hp, ever, first, available, roughly, years, a...  \n",
       "7  [boss, loves, calculator, really, helps, day, ...  \n",
       "8  [simple, calculator, handles, typical, math, l...  \n",
       "9  [love, calculator, big, numbers, excellent, ea...  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['filter_pos_tag']=dataset['pos_tag'].apply(filter_tag)\n",
    "\n",
    "dataset[['tokens','filter_pos_tag']].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['clean_sentence']=dataset['filter_pos_tag'].apply(lambda x: ' '.join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewText</th>\n",
       "      <th>overall</th>\n",
       "      <th>label</th>\n",
       "      <th>sentence</th>\n",
       "      <th>tokens</th>\n",
       "      <th>stem_sentence</th>\n",
       "      <th>lemm_sentence</th>\n",
       "      <th>pos_tag</th>\n",
       "      <th>filter_pos_tag</th>\n",
       "      <th>clean_sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i bought my first hp12c in about 1984 or so, a...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>[i bought my first hp12c in about 1984 or so, ...</td>\n",
       "      <td>[bought, first, served, faithfully, lost, trav...</td>\n",
       "      <td>[bought, first, serv, faith, lost, travel, sea...</td>\n",
       "      <td>[buy, first, serve, faithfully, lose, travel, ...</td>\n",
       "      <td>[(bought, VBD), (first, RB), (served, VBN), (f...</td>\n",
       "      <td>[first, faithfully, travelling, difficult, com...</td>\n",
       "      <td>first faithfully travelling difficult come are...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>why this belated review? i feel very obliged t...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>[why this belated review?, i feel very obliged...</td>\n",
       "      <td>[belated, review, feel, obliged, share, views,...</td>\n",
       "      <td>[belat, review, feel, oblig, share, view, old,...</td>\n",
       "      <td>[belated, review, feel, oblige, share, view, o...</td>\n",
       "      <td>[(belated, VBN), (review, NN), (feel, NN), (ob...</td>\n",
       "      <td>[review, feel, share, views, old, workhorse, g...</td>\n",
       "      <td>review feel share views old workhorse gold ann...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i have an hp 48gx that has been kicking for mo...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>[i have an hp 48gx that has been kicking for m...</td>\n",
       "      <td>[hp, kicking, twenty, years, hp, years, old, s...</td>\n",
       "      <td>[hp, kick, twenti, year, hp, year, old, still,...</td>\n",
       "      <td>[hp, kick, twenty, years, hp, years, old, stil...</td>\n",
       "      <td>[(hp, NN), (kicking, VBG), (twenty, CD), (year...</td>\n",
       "      <td>[hp, years, years, old, still, flawless, month...</td>\n",
       "      <td>hp years years old still flawless months numbe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i've started doing more finance stuff recently...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>[i've started doing more finance stuff recentl...</td>\n",
       "      <td>[started, finance, stuff, recently, went, look...</td>\n",
       "      <td>[start, financ, stuff, recent, went, look, goo...</td>\n",
       "      <td>[start, finance, stuff, recently, go, look, go...</td>\n",
       "      <td>[(started, VBN), (finance, NN), (stuff, NN), (...</td>\n",
       "      <td>[finance, stuff, recently, good, calculator, p...</td>\n",
       "      <td>finance stuff recently good calculator pleasan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>for simple calculations and discounted cash fl...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>[for simple calculations and discounted cash f...</td>\n",
       "      <td>[simple, calculations, discounted, cash, flows...</td>\n",
       "      <td>[simpl, calcul, discount, cash, flow, one, sti...</td>\n",
       "      <td>[simple, calculations, discount, cash, flow, o...</td>\n",
       "      <td>[(simple, JJ), (calculations, NNS), (discounte...</td>\n",
       "      <td>[simple, calculations, cash, flows, still, bes...</td>\n",
       "      <td>simple calculations cash flows still best used...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          reviewText  overall  label  \\\n",
       "0  i bought my first hp12c in about 1984 or so, a...        5      1   \n",
       "1  why this belated review? i feel very obliged t...        5      1   \n",
       "2  i have an hp 48gx that has been kicking for mo...        2      0   \n",
       "3  i've started doing more finance stuff recently...        5      1   \n",
       "4  for simple calculations and discounted cash fl...        5      1   \n",
       "\n",
       "                                            sentence  \\\n",
       "0  [i bought my first hp12c in about 1984 or so, ...   \n",
       "1  [why this belated review?, i feel very obliged...   \n",
       "2  [i have an hp 48gx that has been kicking for m...   \n",
       "3  [i've started doing more finance stuff recentl...   \n",
       "4  [for simple calculations and discounted cash f...   \n",
       "\n",
       "                                              tokens  \\\n",
       "0  [bought, first, served, faithfully, lost, trav...   \n",
       "1  [belated, review, feel, obliged, share, views,...   \n",
       "2  [hp, kicking, twenty, years, hp, years, old, s...   \n",
       "3  [started, finance, stuff, recently, went, look...   \n",
       "4  [simple, calculations, discounted, cash, flows...   \n",
       "\n",
       "                                       stem_sentence  \\\n",
       "0  [bought, first, serv, faith, lost, travel, sea...   \n",
       "1  [belat, review, feel, oblig, share, view, old,...   \n",
       "2  [hp, kick, twenti, year, hp, year, old, still,...   \n",
       "3  [start, financ, stuff, recent, went, look, goo...   \n",
       "4  [simpl, calcul, discount, cash, flow, one, sti...   \n",
       "\n",
       "                                       lemm_sentence  \\\n",
       "0  [buy, first, serve, faithfully, lose, travel, ...   \n",
       "1  [belated, review, feel, oblige, share, view, o...   \n",
       "2  [hp, kick, twenty, years, hp, years, old, stil...   \n",
       "3  [start, finance, stuff, recently, go, look, go...   \n",
       "4  [simple, calculations, discount, cash, flow, o...   \n",
       "\n",
       "                                             pos_tag  \\\n",
       "0  [(bought, VBD), (first, RB), (served, VBN), (f...   \n",
       "1  [(belated, VBN), (review, NN), (feel, NN), (ob...   \n",
       "2  [(hp, NN), (kicking, VBG), (twenty, CD), (year...   \n",
       "3  [(started, VBN), (finance, NN), (stuff, NN), (...   \n",
       "4  [(simple, JJ), (calculations, NNS), (discounte...   \n",
       "\n",
       "                                      filter_pos_tag  \\\n",
       "0  [first, faithfully, travelling, difficult, com...   \n",
       "1  [review, feel, share, views, old, workhorse, g...   \n",
       "2  [hp, years, years, old, still, flawless, month...   \n",
       "3  [finance, stuff, recently, good, calculator, p...   \n",
       "4  [simple, calculations, cash, flows, still, bes...   \n",
       "\n",
       "                                      clean_sentence  \n",
       "0  first faithfully travelling difficult come are...  \n",
       "1  review feel share views old workhorse gold ann...  \n",
       "2  hp years years old still flawless months numbe...  \n",
       "3  finance stuff recently good calculator pleasan...  \n",
       "4  simple calculations cash flows still best used...  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_polarity(col):\n",
    "    return TextBlob(col).sentiment.polarity\n",
    "\n",
    "def detect_subjectivity(col):\n",
    "    return TextBlob(col).sentiment.subjectivity\n",
    "\n",
    "def get_lemma(col):\n",
    "    lemma_list = []\n",
    "    text = TextBlob(col).words\n",
    "    for item in text:\n",
    "        lemma = Word(item).lemmatize()\n",
    "        lemma_list.append(lemma)\n",
    "    return lemma_list\n",
    "\n",
    "def detect_sentence_polarity(col):\n",
    "    scores = []\n",
    "    for sentences in TextBlob(col).sentences:\n",
    "        score = np.round(sentences.sentiment.polarity,2)\n",
    "        scores.append(score)\n",
    "    return scores\n",
    "\n",
    "def sentence_count(col_name, sign = 'total'):\n",
    "    # TODO : OPTIMIZE this\n",
    "    count_list = []\n",
    "    for reviews in col_name:\n",
    "        total_count = len(reviews)\n",
    "        if sign == 'total':\n",
    "            count_list.append(total_count)\n",
    "        else:\n",
    "            count = 0\n",
    "            for polarity in reviews:\n",
    "                if sign == 'positive' and polarity >= 0.2 :\n",
    "                    count += 1\n",
    "                elif sign == 'neutral' and polarity >=0 and polarity<0.2:\n",
    "                    count += 1\n",
    "                elif sign == 'negative' and polarity <0 :\n",
    "                    count += 1\n",
    "            count_list.append(count)\n",
    "    return count_list \n",
    "\n",
    "\n",
    "\n",
    "def negative_boolean(col):\n",
    "    value = 0\n",
    "    value_list = []\n",
    "    for sentence in col:\n",
    "        polarity = detect_polarity(sentence)\n",
    "        if polarity < 0:\n",
    "            value = 1\n",
    "        else: \n",
    "            value = 0\n",
    "        value_list.append(value)\n",
    "    return value_list\n",
    "\n",
    "filter_method = lambda x:'Highly Positive' if x >= 0.5 else 'Fairly Positive' if (x > 0 and x < 0.5) else 'Highly Negative' if x <= -0.5 else 'Fairly Negative' if (x > -0.5 and x < 0) else 'Neutral'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewText</th>\n",
       "      <th>overall</th>\n",
       "      <th>label</th>\n",
       "      <th>sentence</th>\n",
       "      <th>tokens</th>\n",
       "      <th>stem_sentence</th>\n",
       "      <th>lemm_sentence</th>\n",
       "      <th>pos_tag</th>\n",
       "      <th>filter_pos_tag</th>\n",
       "      <th>clean_sentence</th>\n",
       "      <th>sentence_sentiment</th>\n",
       "      <th>#positive_sentences</th>\n",
       "      <th>#negative_sentences</th>\n",
       "      <th>#neutral_sentences</th>\n",
       "      <th>% positive_sentences</th>\n",
       "      <th>% negative_sentences</th>\n",
       "      <th>% neutral_sentences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i bought my first hp12c in about 1984 or so, a...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>[i bought my first hp12c in about 1984 or so, ...</td>\n",
       "      <td>[bought, first, served, faithfully, lost, trav...</td>\n",
       "      <td>[bought, first, serv, faith, lost, travel, sea...</td>\n",
       "      <td>[buy, first, serve, faithfully, lose, travel, ...</td>\n",
       "      <td>[(bought, VBD), (first, RB), (served, VBN), (f...</td>\n",
       "      <td>[first, faithfully, travelling, difficult, com...</td>\n",
       "      <td>first faithfully travelling difficult come are...</td>\n",
       "      <td>[0.25, -0.5, 0.0, 0.0, 0.42, 0.19, 0.0, 0.25, ...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>30.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>60.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>why this belated review? i feel very obliged t...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>[why this belated review?, i feel very obliged...</td>\n",
       "      <td>[belated, review, feel, obliged, share, views,...</td>\n",
       "      <td>[belat, review, feel, oblig, share, view, old,...</td>\n",
       "      <td>[belated, review, feel, oblige, share, view, o...</td>\n",
       "      <td>[(belated, VBN), (review, NN), (feel, NN), (ob...</td>\n",
       "      <td>[review, feel, share, views, old, workhorse, g...</td>\n",
       "      <td>review feel share views old workhorse gold ann...</td>\n",
       "      <td>[0.0, 0.27, 0.0, 0.18, 0.7, -0.03, 0.08, 0.4, ...</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>44.44</td>\n",
       "      <td>5.56</td>\n",
       "      <td>50.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i have an hp 48gx that has been kicking for mo...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>[i have an hp 48gx that has been kicking for m...</td>\n",
       "      <td>[hp, kicking, twenty, years, hp, years, old, s...</td>\n",
       "      <td>[hp, kick, twenti, year, hp, year, old, still,...</td>\n",
       "      <td>[hp, kick, twenty, years, hp, years, old, stil...</td>\n",
       "      <td>[(hp, NN), (kicking, VBG), (twenty, CD), (year...</td>\n",
       "      <td>[hp, years, years, old, still, flawless, month...</td>\n",
       "      <td>hp years years old still flawless months numbe...</td>\n",
       "      <td>[0.52, -0.16, 0.0, 0.07, 0.15, 0.6, 0.17, -0.35]</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>25.00</td>\n",
       "      <td>25.00</td>\n",
       "      <td>50.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i've started doing more finance stuff recently...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>[i've started doing more finance stuff recentl...</td>\n",
       "      <td>[started, finance, stuff, recently, went, look...</td>\n",
       "      <td>[start, financ, stuff, recent, went, look, goo...</td>\n",
       "      <td>[start, finance, stuff, recently, go, look, go...</td>\n",
       "      <td>[(started, VBN), (finance, NN), (stuff, NN), (...</td>\n",
       "      <td>[finance, stuff, recently, good, calculator, p...</td>\n",
       "      <td>finance stuff recently good calculator pleasan...</td>\n",
       "      <td>[0.4, 0.25, 0.8, 0.38, 0.2, 0.0, 0.25, 0.35, 0...</td>\n",
       "      <td>25</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>59.52</td>\n",
       "      <td>11.90</td>\n",
       "      <td>28.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>for simple calculations and discounted cash fl...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>[for simple calculations and discounted cash f...</td>\n",
       "      <td>[simple, calculations, discounted, cash, flows...</td>\n",
       "      <td>[simpl, calcul, discount, cash, flow, one, sti...</td>\n",
       "      <td>[simple, calculations, discount, cash, flow, o...</td>\n",
       "      <td>[(simple, JJ), (calculations, NNS), (discounte...</td>\n",
       "      <td>[simple, calculations, cash, flows, still, bes...</td>\n",
       "      <td>simple calculations cash flows still best used...</td>\n",
       "      <td>[0.5, 0.0, 0.18, 0.5, 0.72, 0.0, 0.0, 0.0]</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>37.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>62.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>while i don't have an mba, it's hard to believ...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>[while i don't have an mba, it's hard to belie...</td>\n",
       "      <td>[mba, hard, believe, calculator, learned, use,...</td>\n",
       "      <td>[mba, hard, believ, calcul, learn, use, underg...</td>\n",
       "      <td>[mba, hard, believe, calculator, learn, use, u...</td>\n",
       "      <td>[(mba, RB), (hard, JJ), (believe, VBP), (calcu...</td>\n",
       "      <td>[mba, hard, calculator, use, undergraduate, bu...</td>\n",
       "      <td>mba hard calculator use undergraduate business...</td>\n",
       "      <td>[0.01, 0.1, 0.17, 0.03, -0.02, 0.07, 0.0]</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0.00</td>\n",
       "      <td>14.29</td>\n",
       "      <td>85.71</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          reviewText  overall  label  \\\n",
       "0  i bought my first hp12c in about 1984 or so, a...        5      1   \n",
       "1  why this belated review? i feel very obliged t...        5      1   \n",
       "2  i have an hp 48gx that has been kicking for mo...        2      0   \n",
       "3  i've started doing more finance stuff recently...        5      1   \n",
       "4  for simple calculations and discounted cash fl...        5      1   \n",
       "5  while i don't have an mba, it's hard to believ...        5      1   \n",
       "\n",
       "                                            sentence  \\\n",
       "0  [i bought my first hp12c in about 1984 or so, ...   \n",
       "1  [why this belated review?, i feel very obliged...   \n",
       "2  [i have an hp 48gx that has been kicking for m...   \n",
       "3  [i've started doing more finance stuff recentl...   \n",
       "4  [for simple calculations and discounted cash f...   \n",
       "5  [while i don't have an mba, it's hard to belie...   \n",
       "\n",
       "                                              tokens  \\\n",
       "0  [bought, first, served, faithfully, lost, trav...   \n",
       "1  [belated, review, feel, obliged, share, views,...   \n",
       "2  [hp, kicking, twenty, years, hp, years, old, s...   \n",
       "3  [started, finance, stuff, recently, went, look...   \n",
       "4  [simple, calculations, discounted, cash, flows...   \n",
       "5  [mba, hard, believe, calculator, learned, use,...   \n",
       "\n",
       "                                       stem_sentence  \\\n",
       "0  [bought, first, serv, faith, lost, travel, sea...   \n",
       "1  [belat, review, feel, oblig, share, view, old,...   \n",
       "2  [hp, kick, twenti, year, hp, year, old, still,...   \n",
       "3  [start, financ, stuff, recent, went, look, goo...   \n",
       "4  [simpl, calcul, discount, cash, flow, one, sti...   \n",
       "5  [mba, hard, believ, calcul, learn, use, underg...   \n",
       "\n",
       "                                       lemm_sentence  \\\n",
       "0  [buy, first, serve, faithfully, lose, travel, ...   \n",
       "1  [belated, review, feel, oblige, share, view, o...   \n",
       "2  [hp, kick, twenty, years, hp, years, old, stil...   \n",
       "3  [start, finance, stuff, recently, go, look, go...   \n",
       "4  [simple, calculations, discount, cash, flow, o...   \n",
       "5  [mba, hard, believe, calculator, learn, use, u...   \n",
       "\n",
       "                                             pos_tag  \\\n",
       "0  [(bought, VBD), (first, RB), (served, VBN), (f...   \n",
       "1  [(belated, VBN), (review, NN), (feel, NN), (ob...   \n",
       "2  [(hp, NN), (kicking, VBG), (twenty, CD), (year...   \n",
       "3  [(started, VBN), (finance, NN), (stuff, NN), (...   \n",
       "4  [(simple, JJ), (calculations, NNS), (discounte...   \n",
       "5  [(mba, RB), (hard, JJ), (believe, VBP), (calcu...   \n",
       "\n",
       "                                      filter_pos_tag  \\\n",
       "0  [first, faithfully, travelling, difficult, com...   \n",
       "1  [review, feel, share, views, old, workhorse, g...   \n",
       "2  [hp, years, years, old, still, flawless, month...   \n",
       "3  [finance, stuff, recently, good, calculator, p...   \n",
       "4  [simple, calculations, cash, flows, still, bes...   \n",
       "5  [mba, hard, calculator, use, undergraduate, bu...   \n",
       "\n",
       "                                      clean_sentence  \\\n",
       "0  first faithfully travelling difficult come are...   \n",
       "1  review feel share views old workhorse gold ann...   \n",
       "2  hp years years old still flawless months numbe...   \n",
       "3  finance stuff recently good calculator pleasan...   \n",
       "4  simple calculations cash flows still best used...   \n",
       "5  mba hard calculator use undergraduate business...   \n",
       "\n",
       "                                  sentence_sentiment  #positive_sentences  \\\n",
       "0  [0.25, -0.5, 0.0, 0.0, 0.42, 0.19, 0.0, 0.25, ...                    3   \n",
       "1  [0.0, 0.27, 0.0, 0.18, 0.7, -0.03, 0.08, 0.4, ...                    8   \n",
       "2   [0.52, -0.16, 0.0, 0.07, 0.15, 0.6, 0.17, -0.35]                    2   \n",
       "3  [0.4, 0.25, 0.8, 0.38, 0.2, 0.0, 0.25, 0.35, 0...                   25   \n",
       "4         [0.5, 0.0, 0.18, 0.5, 0.72, 0.0, 0.0, 0.0]                    3   \n",
       "5          [0.01, 0.1, 0.17, 0.03, -0.02, 0.07, 0.0]                    0   \n",
       "\n",
       "   #negative_sentences  #neutral_sentences  % positive_sentences  \\\n",
       "0                    1                   6                 30.00   \n",
       "1                    1                   9                 44.44   \n",
       "2                    2                   4                 25.00   \n",
       "3                    5                  12                 59.52   \n",
       "4                    0                   5                 37.50   \n",
       "5                    1                   6                  0.00   \n",
       "\n",
       "   % negative_sentences  % neutral_sentences  \n",
       "0                 10.00                60.00  \n",
       "1                  5.56                50.00  \n",
       "2                 25.00                50.00  \n",
       "3                 11.90                28.57  \n",
       "4                  0.00                62.50  \n",
       "5                 14.29                85.71  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dataset['polarity'] = round(dataset.reviewText.apply(detect_polarity),1)\n",
    "# dataset['subjectivity'] = round(dataset.reviewText.apply(detect_subjectivity),1)\n",
    "# dataset['sentiment'] = dataset['polarity'].apply(filter_method)\n",
    "# dataset['lemma'] = dataset.reviewText.apply(get_lemma)\n",
    "\n",
    "dataset['sentence_sentiment'] = dataset.reviewText.apply(detect_sentence_polarity)\n",
    "\n",
    "dataset['#positive_sentences'] = sentence_count(dataset['sentence_sentiment'], 'positive')\n",
    "dataset['#negative_sentences'] = sentence_count(dataset['sentence_sentiment'], 'negative')\n",
    "dataset['#neutral_sentences']= sentence_count(dataset['sentence_sentiment'], 'neutral')\n",
    "\n",
    "dataset['% positive_sentences'] =np.round(dataset['#positive_sentences']*100/(dataset['#positive_sentences']+dataset['#negative_sentences']+dataset['#neutral_sentences']),2)\n",
    "dataset['% negative_sentences'] =np.round(dataset['#negative_sentences']*100/(dataset['#positive_sentences']+dataset['#negative_sentences']+dataset['#neutral_sentences']),2)\n",
    "dataset['% neutral_sentences'] =np.round(dataset['#neutral_sentences']*100/(dataset['#positive_sentences']+dataset['#negative_sentences']+dataset['#neutral_sentences']),2)\n",
    "\n",
    "dataset.head(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Polarity is float which lies within range of [-1,1]. Values closer to 1 have a highly positive sentiment and values closer to -1 have highly negative sentiment. Values closer to 0 on the either sides shows slighty positive and negative indication.\n",
    "\n",
    "Similarly, subjective sentences refer to personal opinion, emotion or judgement whereas objective refers to facts. Subjectivity is also a float which lies in the range of [0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewText</th>\n",
       "      <th>overall</th>\n",
       "      <th>label</th>\n",
       "      <th>sentence</th>\n",
       "      <th>tokens</th>\n",
       "      <th>stem_sentence</th>\n",
       "      <th>lemm_sentence</th>\n",
       "      <th>pos_tag</th>\n",
       "      <th>filter_pos_tag</th>\n",
       "      <th>clean_sentence</th>\n",
       "      <th>sentence_sentiment</th>\n",
       "      <th>#positive_sentences</th>\n",
       "      <th>#negative_sentences</th>\n",
       "      <th>#neutral_sentences</th>\n",
       "      <th>% positive_sentences</th>\n",
       "      <th>% negative_sentences</th>\n",
       "      <th>% neutral_sentences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i bought my first hp12c in about 1984 or so, a...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>[i bought my first hp12c in about 1984 or so, ...</td>\n",
       "      <td>[bought, first, served, faithfully, lost, trav...</td>\n",
       "      <td>[bought, first, serv, faith, lost, travel, sea...</td>\n",
       "      <td>[buy, first, serve, faithfully, lose, travel, ...</td>\n",
       "      <td>[(bought, VBD), (first, RB), (served, VBN), (f...</td>\n",
       "      <td>[first, faithfully, travelling, difficult, com...</td>\n",
       "      <td>first faithfully travelling difficult come are...</td>\n",
       "      <td>[0.25, -0.5, 0.0, 0.0, 0.42, 0.19, 0.0, 0.25, ...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>30.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>60.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>why this belated review? i feel very obliged t...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>[why this belated review?, i feel very obliged...</td>\n",
       "      <td>[belated, review, feel, obliged, share, views,...</td>\n",
       "      <td>[belat, review, feel, oblig, share, view, old,...</td>\n",
       "      <td>[belated, review, feel, oblige, share, view, o...</td>\n",
       "      <td>[(belated, VBN), (review, NN), (feel, NN), (ob...</td>\n",
       "      <td>[review, feel, share, views, old, workhorse, g...</td>\n",
       "      <td>review feel share views old workhorse gold ann...</td>\n",
       "      <td>[0.0, 0.27, 0.0, 0.18, 0.7, -0.03, 0.08, 0.4, ...</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>44.44</td>\n",
       "      <td>5.56</td>\n",
       "      <td>50.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i have an hp 48gx that has been kicking for mo...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>[i have an hp 48gx that has been kicking for m...</td>\n",
       "      <td>[hp, kicking, twenty, years, hp, years, old, s...</td>\n",
       "      <td>[hp, kick, twenti, year, hp, year, old, still,...</td>\n",
       "      <td>[hp, kick, twenty, years, hp, years, old, stil...</td>\n",
       "      <td>[(hp, NN), (kicking, VBG), (twenty, CD), (year...</td>\n",
       "      <td>[hp, years, years, old, still, flawless, month...</td>\n",
       "      <td>hp years years old still flawless months numbe...</td>\n",
       "      <td>[0.52, -0.16, 0.0, 0.07, 0.15, 0.6, 0.17, -0.35]</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>25.00</td>\n",
       "      <td>25.00</td>\n",
       "      <td>50.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i've started doing more finance stuff recently...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>[i've started doing more finance stuff recentl...</td>\n",
       "      <td>[started, finance, stuff, recently, went, look...</td>\n",
       "      <td>[start, financ, stuff, recent, went, look, goo...</td>\n",
       "      <td>[start, finance, stuff, recently, go, look, go...</td>\n",
       "      <td>[(started, VBN), (finance, NN), (stuff, NN), (...</td>\n",
       "      <td>[finance, stuff, recently, good, calculator, p...</td>\n",
       "      <td>finance stuff recently good calculator pleasan...</td>\n",
       "      <td>[0.4, 0.25, 0.8, 0.38, 0.2, 0.0, 0.25, 0.35, 0...</td>\n",
       "      <td>25</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>59.52</td>\n",
       "      <td>11.90</td>\n",
       "      <td>28.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>for simple calculations and discounted cash fl...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>[for simple calculations and discounted cash f...</td>\n",
       "      <td>[simple, calculations, discounted, cash, flows...</td>\n",
       "      <td>[simpl, calcul, discount, cash, flow, one, sti...</td>\n",
       "      <td>[simple, calculations, discount, cash, flow, o...</td>\n",
       "      <td>[(simple, JJ), (calculations, NNS), (discounte...</td>\n",
       "      <td>[simple, calculations, cash, flows, still, bes...</td>\n",
       "      <td>simple calculations cash flows still best used...</td>\n",
       "      <td>[0.5, 0.0, 0.18, 0.5, 0.72, 0.0, 0.0, 0.0]</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>37.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>62.50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          reviewText  overall  label  \\\n",
       "0  i bought my first hp12c in about 1984 or so, a...        5      1   \n",
       "1  why this belated review? i feel very obliged t...        5      1   \n",
       "2  i have an hp 48gx that has been kicking for mo...        2      0   \n",
       "3  i've started doing more finance stuff recently...        5      1   \n",
       "4  for simple calculations and discounted cash fl...        5      1   \n",
       "\n",
       "                                            sentence  \\\n",
       "0  [i bought my first hp12c in about 1984 or so, ...   \n",
       "1  [why this belated review?, i feel very obliged...   \n",
       "2  [i have an hp 48gx that has been kicking for m...   \n",
       "3  [i've started doing more finance stuff recentl...   \n",
       "4  [for simple calculations and discounted cash f...   \n",
       "\n",
       "                                              tokens  \\\n",
       "0  [bought, first, served, faithfully, lost, trav...   \n",
       "1  [belated, review, feel, obliged, share, views,...   \n",
       "2  [hp, kicking, twenty, years, hp, years, old, s...   \n",
       "3  [started, finance, stuff, recently, went, look...   \n",
       "4  [simple, calculations, discounted, cash, flows...   \n",
       "\n",
       "                                       stem_sentence  \\\n",
       "0  [bought, first, serv, faith, lost, travel, sea...   \n",
       "1  [belat, review, feel, oblig, share, view, old,...   \n",
       "2  [hp, kick, twenti, year, hp, year, old, still,...   \n",
       "3  [start, financ, stuff, recent, went, look, goo...   \n",
       "4  [simpl, calcul, discount, cash, flow, one, sti...   \n",
       "\n",
       "                                       lemm_sentence  \\\n",
       "0  [buy, first, serve, faithfully, lose, travel, ...   \n",
       "1  [belated, review, feel, oblige, share, view, o...   \n",
       "2  [hp, kick, twenty, years, hp, years, old, stil...   \n",
       "3  [start, finance, stuff, recently, go, look, go...   \n",
       "4  [simple, calculations, discount, cash, flow, o...   \n",
       "\n",
       "                                             pos_tag  \\\n",
       "0  [(bought, VBD), (first, RB), (served, VBN), (f...   \n",
       "1  [(belated, VBN), (review, NN), (feel, NN), (ob...   \n",
       "2  [(hp, NN), (kicking, VBG), (twenty, CD), (year...   \n",
       "3  [(started, VBN), (finance, NN), (stuff, NN), (...   \n",
       "4  [(simple, JJ), (calculations, NNS), (discounte...   \n",
       "\n",
       "                                      filter_pos_tag  \\\n",
       "0  [first, faithfully, travelling, difficult, com...   \n",
       "1  [review, feel, share, views, old, workhorse, g...   \n",
       "2  [hp, years, years, old, still, flawless, month...   \n",
       "3  [finance, stuff, recently, good, calculator, p...   \n",
       "4  [simple, calculations, cash, flows, still, bes...   \n",
       "\n",
       "                                      clean_sentence  \\\n",
       "0  first faithfully travelling difficult come are...   \n",
       "1  review feel share views old workhorse gold ann...   \n",
       "2  hp years years old still flawless months numbe...   \n",
       "3  finance stuff recently good calculator pleasan...   \n",
       "4  simple calculations cash flows still best used...   \n",
       "\n",
       "                                  sentence_sentiment  #positive_sentences  \\\n",
       "0  [0.25, -0.5, 0.0, 0.0, 0.42, 0.19, 0.0, 0.25, ...                    3   \n",
       "1  [0.0, 0.27, 0.0, 0.18, 0.7, -0.03, 0.08, 0.4, ...                    8   \n",
       "2   [0.52, -0.16, 0.0, 0.07, 0.15, 0.6, 0.17, -0.35]                    2   \n",
       "3  [0.4, 0.25, 0.8, 0.38, 0.2, 0.0, 0.25, 0.35, 0...                   25   \n",
       "4         [0.5, 0.0, 0.18, 0.5, 0.72, 0.0, 0.0, 0.0]                    3   \n",
       "\n",
       "   #negative_sentences  #neutral_sentences  % positive_sentences  \\\n",
       "0                    1                   6                 30.00   \n",
       "1                    1                   9                 44.44   \n",
       "2                    2                   4                 25.00   \n",
       "3                    5                  12                 59.52   \n",
       "4                    0                   5                 37.50   \n",
       "\n",
       "   % negative_sentences  % neutral_sentences  \n",
       "0                 10.00                60.00  \n",
       "1                  5.56                50.00  \n",
       "2                 25.00                50.00  \n",
       "3                 11.90                28.57  \n",
       "4                  0.00                62.50  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['% negative > % positive']=dataset['% negative_sentences']>dataset['% positive_sentences']\n",
    "dataset['% negative > 10']=dataset['% negative_sentences']>10\n",
    "dataset['% positive > 50']=dataset['% positive_sentences']>50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZEAAAEGCAYAAACkQqisAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAAPtElEQVR4nO3df6zddX3H8eeLFkTjkGpvGLZoyWzcqttUGkRNFpUMituEGTQwHZ1r7BJx02TZxP0xNpRFNx0Tf5CQUfkxIxLdRmdwTYOicROhTBQLI9yhjjZoKyDoDLjie3+cT/Ws3FsOn3LO6e19PpKT+/2+P5/v97xPcpNXvj/O96SqkCSpx2HTbkCStHAZIpKkboaIJKmbISJJ6maISJK6LZ12A5O2fPnyWrVq1bTbkKQF45ZbbvleVc3MNbboQmTVqlVs27Zt2m1I0oKR5NvzjXk6S5LUzRCRJHUzRCRJ3QwRSVI3Q0SS1M0QkSR1M0QkSd0MEUlSN0NEktRt0X1jXTqU/fcFvzztFnQQes6f3za2fXskIknqZohIkroZIpKkboaIJKmbISJJ6maISJK6GSKSpG6GiCSpmyEiSepmiEiSuhkikqRuhogkqZshIknqZohIkroZIpKkboaIJKmbISJJ6maISJK6GSKSpG6GiCSp29hDJMmSJF9N8pm2fnySrySZTfLJJEe0+lPa+mwbXzW0j3e1+p1JTh2qr2u12STnjfuzSJL+v0kcibwduGNo/X3ARVX1POABYEOrbwAeaPWL2jySrAHOAl4ArAM+2oJpCfAR4DRgDXB2mytJmpCxhkiSlcBvAH/f1gO8GvhUm3IFcEZbPr2t08ZPbvNPB66uqkeq6pvALHBie81W1d1V9WPg6jZXkjQh4z4S+TvgT4GftPVnAd+vqj1tfQewoi2vAO4BaOMPtvk/re+zzXz1x0iyMcm2JNt27959oJ9JktSMLUSS/Cawq6puGdd7jKqqLq2qtVW1dmZmZtrtSNIhY+kY9/0K4LVJXgMcCRwFfBA4OsnSdrSxEtjZ5u8EjgN2JFkKPAO4b6i+1/A289UlSRMwtiORqnpXVa2sqlUMLox/rqreCHweOLNNWw9c25Y3t3Xa+Oeqqlr9rHb31vHAauAm4GZgdbvb64j2HpvH9XkkSY81ziOR+bwTuDrJe4CvApe1+mXAVUlmgfsZhAJVtT3JNcDtwB7g3Kp6FCDJ24AtwBJgU1Vtn+gnkaRFbiIhUlU3ADe05bsZ3Fm175yHgdfPs/2FwIVz1K8DrnsSW5UkPQF+Y12S1M0QkSR1M0QkSd0MEUlSN0NEktTNEJEkdTNEJEndDBFJUjdDRJLUzRCRJHUzRCRJ3QwRSVI3Q0SS1M0QkSR1M0QkSd0MEUlSN0NEktTNEJEkdTNEJEndDBFJUjdDRJLUzRCRJHUzRCRJ3QwRSVI3Q0SS1M0QkSR1M0QkSd0MEUlSN0NEktTNEJEkdTNEJEndDBFJUjdDRJLUzRCRJHUzRCRJ3QwRSVI3Q0SS1G1sIZLkyCQ3Jflaku1J/rLVj0/ylSSzST6Z5IhWf0pbn23jq4b29a5WvzPJqUP1da02m+S8cX0WSdLcxnkk8gjw6qr6VeBFwLokJwHvAy6qqucBDwAb2vwNwAOtflGbR5I1wFnAC4B1wEeTLEmyBPgIcBqwBji7zZUkTcjYQqQGfthWD2+vAl4NfKrVrwDOaMunt3Xa+MlJ0upXV9UjVfVNYBY4sb1mq+ruqvoxcHWbK0makLFeE2lHDLcCu4CtwH8B36+qPW3KDmBFW14B3APQxh8EnjVc32eb+epz9bExybYk23bv3v1kfDRJEmMOkap6tKpeBKxkcOTwi+N8v/30cWlVra2qtTMzM9NoQZIOSRO5O6uqvg98HngZcHSSpW1oJbCzLe8EjgNo488A7huu77PNfHVJ0oSM8+6smSRHt+WnAr8O3MEgTM5s09YD17blzW2dNv65qqpWP6vdvXU8sBq4CbgZWN3u9jqCwcX3zeP6PJKkx1r6+FO6HQtc0e6iOgy4pqo+k+R24Ook7wG+ClzW5l8GXJVkFrifQShQVduTXAPcDuwBzq2qRwGSvA3YAiwBNlXV9jF+HknSPsYWIlX1deDFc9TvZnB9ZN/6w8Dr59nXhcCFc9SvA6474GYlSV38xrokqZshIknqZohIkroZIpKkboaIJKmbISJJ6maISJK6GSKSpG6GiCSpmyEiSepmiEiSuo0UIkmuH6UmSVpc9vsAxiRHAk8DlidZBqQNHcU8vyIoSVo8Hu8pvn8AvAN4NnALPwuRh4APj7EvSdICsN8QqaoPAh9M8odV9aEJ9SRJWiBG+j2RqvpQkpcDq4a3qaorx9SXJGkBGClEklwF/AJwK/BoKxdgiEjSIjbqLxuuBda03zyXJAkY/Xsi3wB+fpyNSJIWnlGPRJYDtye5CXhkb7GqXjuWriRJC8KoIfIX42xCkrQwjXp31hfG3YgkaeEZ9e6sHzC4GwvgCOBw4H+q6qhxNSZJOviNeiTyc3uXkwQ4HThpXE1JkhaGJ/wU3xr4Z+DUMfQjSVpARj2d9bqh1cMYfG/k4bF0JElaMEa9O+u3hpb3AN9icEpLkrSIjXpN5M3jbkSStPCM+qNUK5P8U5Jd7fXpJCvH3Zwk6eA26oX1jwGbGfyuyLOBf2k1SdIiNmqIzFTVx6pqT3tdDsyMsS9J0gIwaojcl+RNSZa015uA+8bZmCTp4DdqiPw+8AbgO8C9wJnA742pJ0nSAjHqLb4XAOur6gGAJM8E3s8gXCRJi9SoRyK/sjdAAKrqfuDF42lJkrRQjBoihyVZtnelHYmMehQjSTpEjRoiHwC+nOTdSd4N/Dvw1/vbIMlxST6f5PYk25O8vdWfmWRrkrva32WtniQXJ5lN8vUkLxna1/o2/64k64fqJyS5rW1zcXs4pCRpQkYKkaq6Engd8N32el1VXfU4m+0B/riq1jB44u+5SdYA5wHXV9Vq4Pq2DnAasLq9NgKXwE+Pes4HXgqcCJw/dFR0CfCWoe3WjfJ5JElPjpFPSVXV7cDtT2D+vQzu5KKqfpDkDmAFg2duvbJNuwK4AXhnq19ZVQXcmOToJMe2uVvbdRiSbAXWJbkBOKqqbmz1K4EzgM+O2qMk6cA84UfB90iyisGF+K8Ax7SAgcEtw8e05RXAPUOb7Wi1/dV3zFGf6/03JtmWZNvu3bsP6LNIkn5m7CGS5OnAp4F3VNVDw2PtqKPm3PBJVFWXVtXaqlo7M+MX7SXpyTLWEElyOIMA+XhV/WMrf7edpqL93dXqO4HjhjZf2Wr7q6+coy5JmpCxhUi7U+oy4I6q+tuhoc3A3jus1gPXDtXPaXdpnQQ82E57bQFOSbKsXVA/BdjSxh5KclJ7r3OG9iVJmoBxftfjFcDvArclubXV/gx4L3BNkg3Atxk8TgXgOuA1wCzwI+DNMPhiY7ut+OY274K9F9mBtwKXA09lcEHdi+qSNEFjC5Gq+hIw3/c2Tp5jfgHnzrOvTcCmOerbgBceQJuSpAMwkbuzJEmHJkNEktTNEJEkdTNEJEndDBFJUjdDRJLUzRCRJHUzRCRJ3QwRSVI3Q0SS1M0QkSR1M0QkSd0MEUlSN0NEktTNEJEkdTNEJEndDBFJUjdDRJLUzRCRJHUzRCRJ3QwRSVI3Q0SS1M0QkSR1M0QkSd0MEUlSN0NEktTNEJEkdTNEJEndDBFJUjdDRJLUzRCRJHUzRCRJ3QwRSVI3Q0SS1M0QkSR1M0QkSd0MEUlSt7GFSJJNSXYl+cZQ7ZlJtia5q/1d1upJcnGS2SRfT/KSoW3Wt/l3JVk/VD8hyW1tm4uTZFyfRZI0t3EeiVwOrNundh5wfVWtBq5v6wCnAavbayNwCQxCBzgfeClwInD+3uBpc94ytN2+7yVJGrOxhUhVfRG4f5/y6cAVbfkK4Iyh+pU1cCNwdJJjgVOBrVV1f1U9AGwF1rWxo6rqxqoq4MqhfUmSJmTS10SOqap72/J3gGPa8grgnqF5O1ptf/Udc9TnlGRjkm1Jtu3evfvAPoEk6aemdmG9HUHUhN7r0qpaW1VrZ2ZmJvGWkrQoTDpEvttORdH+7mr1ncBxQ/NWttr+6ivnqEuSJmjSIbIZ2HuH1Xrg2qH6Oe0urZOAB9tpry3AKUmWtQvqpwBb2thDSU5qd2WdM7QvSdKELB3XjpN8AnglsDzJDgZ3Wb0XuCbJBuDbwBva9OuA1wCzwI+ANwNU1f1J3g3c3OZdUFV7L9a/lcEdYE8FPttekqQJGluIVNXZ8wydPMfcAs6dZz+bgE1z1LcBLzyQHiVJB8ZvrEuSuhkikqRuhogkqZshIknqZohIkroZIpKkboaIJKmbISJJ6maISJK6GSKSpG6GiCSpmyEiSepmiEiSuhkikqRuhogkqZshIknqZohIkroZIpKkboaIJKmbISJJ6maISJK6GSKSpG6GiCSpmyEiSepmiEiSuhkikqRuhogkqdvSaTew0JzwJ1dOuwUdhG75m3Om3YI0FR6JSJK6GSKSpG6GiCSpmyEiSepmiEiSuhkikqRuhogkqZshIknqZohIkrot+BBJsi7JnUlmk5w37X4kaTFZ0CGSZAnwEeA0YA1wdpI10+1KkhaPBR0iwInAbFXdXVU/Bq4GTp9yT5K0aCz0BzCuAO4ZWt8BvHTfSUk2Ahvb6g+T3DmB3haD5cD3pt3EwSDvXz/tFvRY/n/udX4OdA/PnW9goYfISKrqUuDSafdxqEmyrarWTrsPaS7+f07GQj+dtRM4bmh9ZatJkiZgoYfIzcDqJMcnOQI4C9g85Z4kadFY0KezqmpPkrcBW4AlwKaq2j7lthYTTxHqYOb/5wSkqqbdgyRpgVrop7MkSVNkiEiSuhki6uLjZnSwSrIpya4k35h2L4uBIaInzMfN6CB3ObBu2k0sFoaIevi4GR20quqLwP3T7mOxMETUY67HzayYUi+SpsgQkSR1M0TUw8fNSAIMEfXxcTOSAENEHapqD7D3cTN3ANf4uBkdLJJ8Avgy8PwkO5JsmHZPhzIfeyJJ6uaRiCSpmyEiSepmiEiSuhkikqRuhogkqZshIo1Rkh8+zviqJ/q02SSXJznzwDqTnhyGiCSpmyEiTUCSpye5Psl/JLktyfBTj5cm+XiSO5J8KsnT2jYnJPlCkluSbEly7JTal+ZliEiT8TDw21X1EuBVwAeSpI09H/hoVf0S8BDw1iSHAx8CzqyqE4BNwIVT6Fvar6XTbkBaJAL8VZJfA37C4NH5x7Sxe6rq39ryPwB/BPwr8EJga8uaJcC9E+1YGoEhIk3GG4EZ4ISq+t8k3wKObGP7PnuoGITO9qp62eRalJ44T2dJk/EMYFcLkFcBzx0ae06SvWHxO8CXgDuBmb31JIcnecFEO5ZGYIhIk/FxYG2S24BzgP8cGrsTODfJHcAy4JL2s8NnAu9L8jXgVuDlE+5Zelw+xVeS1M0jEUlSN0NEktTNEJEkdTNEJEndDBFJUjdDRJLUzRCRJHX7Py8V3YRe6RjbAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(x='label', data=dataset);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(x='label', data=dataset,hue='% negative > 10');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(x='label', data=dataset,hue='% positive > 50');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewText</th>\n",
       "      <th>overall</th>\n",
       "      <th>label</th>\n",
       "      <th>sentence</th>\n",
       "      <th>tokens</th>\n",
       "      <th>stem_sentence</th>\n",
       "      <th>lemm_sentence</th>\n",
       "      <th>pos_tag</th>\n",
       "      <th>filter_pos_tag</th>\n",
       "      <th>clean_sentence</th>\n",
       "      <th>sentence_sentiment</th>\n",
       "      <th>#positive_sentences</th>\n",
       "      <th>#negative_sentences</th>\n",
       "      <th>#neutral_sentences</th>\n",
       "      <th>% positive_sentences</th>\n",
       "      <th>% negative_sentences</th>\n",
       "      <th>% neutral_sentences</th>\n",
       "      <th>% negative &gt; % positive</th>\n",
       "      <th>% negative &gt; 10</th>\n",
       "      <th>% positive &gt; 50</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i have an hp 48gx that has been kicking for mo...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>[i have an hp 48gx that has been kicking for m...</td>\n",
       "      <td>[hp, kicking, twenty, years, hp, years, old, s...</td>\n",
       "      <td>[hp, kick, twenti, year, hp, year, old, still,...</td>\n",
       "      <td>[hp, kick, twenty, years, hp, years, old, stil...</td>\n",
       "      <td>[(hp, NN), (kicking, VBG), (twenty, CD), (year...</td>\n",
       "      <td>[hp, years, years, old, still, flawless, month...</td>\n",
       "      <td>hp years years old still flawless months numbe...</td>\n",
       "      <td>[0.52, -0.16, 0.0, 0.07, 0.15, 0.6, 0.17, -0.35]</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>25.00</td>\n",
       "      <td>25.00</td>\n",
       "      <td>50.00</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>these ubiquitous texas instrument calculator t...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[these ubiquitous texas instrument calculator ...</td>\n",
       "      <td>[ubiquitous, texas, instrument, calculator, ev...</td>\n",
       "      <td>[ubiquit, texa, instrument, calcul, everyon, t...</td>\n",
       "      <td>[ubiquitous, texas, instrument, calculator, ev...</td>\n",
       "      <td>[(ubiquitous, JJ), (texas, NN), (instrument, N...</td>\n",
       "      <td>[ubiquitous, texas, instrument, calculator, ev...</td>\n",
       "      <td>ubiquitous texas instrument calculator everyon...</td>\n",
       "      <td>[0.45, 0.0]</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>50.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>50.00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>overall i do not recommend this product. i rem...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>[overall i do not recommend this product., i r...</td>\n",
       "      <td>[overall, recommend, product, remember, calcul...</td>\n",
       "      <td>[overal, recommend, product, rememb, calcul, s...</td>\n",
       "      <td>[overall, recommend, product, remember, calcul...</td>\n",
       "      <td>[(overall, JJ), (recommend, VB), (product, NN)...</td>\n",
       "      <td>[overall, product, calculator, several, years,...</td>\n",
       "      <td>overall product calculator several years ago v...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.14, -0.4, 0.0]</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>16.67</td>\n",
       "      <td>83.33</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>bought this product recently based on recommen...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[bought this product recently based on recomme...</td>\n",
       "      <td>[bought, product, recently, based, recommendat...</td>\n",
       "      <td>[bought, product, recent, base, recommend, adv...</td>\n",
       "      <td>[buy, product, recently, base, recommendations...</td>\n",
       "      <td>[(bought, JJ), (product, NN), (recently, RB), ...</td>\n",
       "      <td>[bought, product, recently, recommendations, s...</td>\n",
       "      <td>bought product recently recommendations scient...</td>\n",
       "      <td>[0.2, 0.35, -0.5, -0.25, 0.25]</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>60.00</td>\n",
       "      <td>40.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>parents: if you're going to buy your child a g...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>[parents: if you're going to buy your child a ...</td>\n",
       "      <td>[parents, going, buy, child, graphing, calcula...</td>\n",
       "      <td>[parent, go, buy, child, graph, calcul, school...</td>\n",
       "      <td>[parent, go, buy, child, graph, calculator, sc...</td>\n",
       "      <td>[(parents, NNS), (going, VBG), (buy, NN), (chi...</td>\n",
       "      <td>[parents, buy, child, calculator, school, insu...</td>\n",
       "      <td>parents buy child calculator school insult int...</td>\n",
       "      <td>[-0.07, 0.0, 0.4, 0.0, 0.27, 0.29, 0.0, 0.07, ...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>23.08</td>\n",
       "      <td>15.38</td>\n",
       "      <td>61.54</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           reviewText  overall  label  \\\n",
       "2   i have an hp 48gx that has been kicking for mo...        2      0   \n",
       "32  these ubiquitous texas instrument calculator t...        1      0   \n",
       "37  overall i do not recommend this product. i rem...        2      0   \n",
       "40  bought this product recently based on recommen...        1      0   \n",
       "43  parents: if you're going to buy your child a g...        2      0   \n",
       "\n",
       "                                             sentence  \\\n",
       "2   [i have an hp 48gx that has been kicking for m...   \n",
       "32  [these ubiquitous texas instrument calculator ...   \n",
       "37  [overall i do not recommend this product., i r...   \n",
       "40  [bought this product recently based on recomme...   \n",
       "43  [parents: if you're going to buy your child a ...   \n",
       "\n",
       "                                               tokens  \\\n",
       "2   [hp, kicking, twenty, years, hp, years, old, s...   \n",
       "32  [ubiquitous, texas, instrument, calculator, ev...   \n",
       "37  [overall, recommend, product, remember, calcul...   \n",
       "40  [bought, product, recently, based, recommendat...   \n",
       "43  [parents, going, buy, child, graphing, calcula...   \n",
       "\n",
       "                                        stem_sentence  \\\n",
       "2   [hp, kick, twenti, year, hp, year, old, still,...   \n",
       "32  [ubiquit, texa, instrument, calcul, everyon, t...   \n",
       "37  [overal, recommend, product, rememb, calcul, s...   \n",
       "40  [bought, product, recent, base, recommend, adv...   \n",
       "43  [parent, go, buy, child, graph, calcul, school...   \n",
       "\n",
       "                                        lemm_sentence  \\\n",
       "2   [hp, kick, twenty, years, hp, years, old, stil...   \n",
       "32  [ubiquitous, texas, instrument, calculator, ev...   \n",
       "37  [overall, recommend, product, remember, calcul...   \n",
       "40  [buy, product, recently, base, recommendations...   \n",
       "43  [parent, go, buy, child, graph, calculator, sc...   \n",
       "\n",
       "                                              pos_tag  \\\n",
       "2   [(hp, NN), (kicking, VBG), (twenty, CD), (year...   \n",
       "32  [(ubiquitous, JJ), (texas, NN), (instrument, N...   \n",
       "37  [(overall, JJ), (recommend, VB), (product, NN)...   \n",
       "40  [(bought, JJ), (product, NN), (recently, RB), ...   \n",
       "43  [(parents, NNS), (going, VBG), (buy, NN), (chi...   \n",
       "\n",
       "                                       filter_pos_tag  \\\n",
       "2   [hp, years, years, old, still, flawless, month...   \n",
       "32  [ubiquitous, texas, instrument, calculator, ev...   \n",
       "37  [overall, product, calculator, several, years,...   \n",
       "40  [bought, product, recently, recommendations, s...   \n",
       "43  [parents, buy, child, calculator, school, insu...   \n",
       "\n",
       "                                       clean_sentence  \\\n",
       "2   hp years years old still flawless months numbe...   \n",
       "32  ubiquitous texas instrument calculator everyon...   \n",
       "37  overall product calculator several years ago v...   \n",
       "40  bought product recently recommendations scient...   \n",
       "43  parents buy child calculator school insult int...   \n",
       "\n",
       "                                   sentence_sentiment  #positive_sentences  \\\n",
       "2    [0.52, -0.16, 0.0, 0.07, 0.15, 0.6, 0.17, -0.35]                    2   \n",
       "32                                        [0.45, 0.0]                    1   \n",
       "37                   [0.0, 0.0, 0.0, 0.14, -0.4, 0.0]                    0   \n",
       "40                     [0.2, 0.35, -0.5, -0.25, 0.25]                    3   \n",
       "43  [-0.07, 0.0, 0.4, 0.0, 0.27, 0.29, 0.0, 0.07, ...                    3   \n",
       "\n",
       "    #negative_sentences  #neutral_sentences  % positive_sentences  \\\n",
       "2                     2                   4                 25.00   \n",
       "32                    0                   1                 50.00   \n",
       "37                    1                   5                  0.00   \n",
       "40                    2                   0                 60.00   \n",
       "43                    2                   8                 23.08   \n",
       "\n",
       "    % negative_sentences  % neutral_sentences  % negative > % positive  \\\n",
       "2                  25.00                50.00                    False   \n",
       "32                  0.00                50.00                    False   \n",
       "37                 16.67                83.33                     True   \n",
       "40                 40.00                 0.00                    False   \n",
       "43                 15.38                61.54                    False   \n",
       "\n",
       "    % negative > 10  % positive > 50  \n",
       "2              True            False  \n",
       "32            False            False  \n",
       "37             True            False  \n",
       "40             True             True  \n",
       "43             True            False  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[dataset['label']==0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to calculate Model Metrics\n",
    "\n",
    "def get_model_metrics(actual,predicted):\n",
    "    \"\"\"\n",
    "    Print Summary Metrics of the Model\n",
    "\n",
    "    Parameters:\n",
    "    actual (pandas.core.series.Series): Series of Boolean values for target column\n",
    "    predicted (pandas.core.series.Series): Series of Boolean values for Model predicted the target column\n",
    "    \n",
    "    Returns:\n",
    "    None\n",
    "\n",
    "   \"\"\"\n",
    "\n",
    "    \n",
    "    confusion = metrics.confusion_matrix(actual,predicted )\n",
    "    TP = confusion[1,1] # true positive \n",
    "    TN = confusion[0,0] # true negatives\n",
    "    FP = confusion[0,1] # false positives\n",
    "    FN = confusion[1,0] # false negatives\n",
    "    accuracy=metrics.accuracy_score(actual,predicted)\n",
    "    sensitivity = TP / float(TP+FN)\n",
    "    specificity = TN / float(TN+FP)\n",
    "    precision=TP/float(FP+TP)\n",
    "    recall=TP/float(FN+TP)\n",
    "    \n",
    "    precision=metrics.precision_score(actual,predicted)\n",
    "    recall=metrics.recall_score(actual,predicted)\n",
    "    f1=metrics.f1_score(actual,predicted, average='weighted') \n",
    "    print(\"Accuracy    : \"+str(round(accuracy,2)))\n",
    "    print(\"Sensitivity : \"+str(round(sensitivity,2)))\n",
    "    print(\"Specificity : \"+str(round(specificity,2)))\n",
    "    print(\"Precision   : \"+str(round(precision,2)))\n",
    "    print(\"Recall      : \"+str(round(recall,2)))\n",
    "    print(\"F1_score    : \"+str(round(f1,2)))\n",
    "    \n",
    "# fokal ml utils\n",
    "\n",
    "def get_cross_validated_model_metrics(X,y,cv=5):\n",
    "    \"\"\"\n",
    "    Get cross validated model metric for k folds\n",
    "\n",
    "    Parameters:\n",
    "    X (pandas.core.frame.DataFrame): DF of all the features excluding target column\n",
    "    y (pandas.core.series.Series): Series of Boolean values of the target column\n",
    "    \n",
    "    Returns:\n",
    "    df (pandas.core.frame.DataFrame): DF will all the metric for k fold\n",
    "\n",
    "   \"\"\"\n",
    "    accuracy=cross_val_score(logregcv, X, y, cv=cv,n_jobs=-1,scoring='accuracy')\n",
    "    precision=cross_val_score(logregcv, X, y, cv=cv,n_jobs=-1,scoring='precision')\n",
    "    recall=cross_val_score(logregcv, X, y, cv=cv,n_jobs=-1,scoring='recall')\n",
    "    f1_weighted=cross_val_score(logregcv, X, y, cv=cv,n_jobs=-1,scoring='f1_weighted')\n",
    "    roc_auc=cross_val_score(logregcv, X, y, cv=cv,n_jobs=-1,scoring='roc_auc')\n",
    "    df=pd.DataFrame(\n",
    "    {'accuracy': accuracy,\n",
    "     'precision': precision,\n",
    "     'recall': recall,\n",
    "     'f1_weighted': f1_weighted,\n",
    "     'roc_auc': roc_auc,\n",
    "    })\n",
    "    return df\n",
    "\n",
    "logregcv = LogisticRegressionCV(class_weight='balanced',cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "class TfIdfExtractor(object):\n",
    "\n",
    "    def gen_tf_score(self, doc):\n",
    "        return Counter(doc)\n",
    "\n",
    "    def gen_df_score(self, doc_list):\n",
    "\n",
    "        idf_corpus = {}\n",
    "        doc_cntr = 0\n",
    "        for doc in doc_list:\n",
    "            ## TODO: Handle Bad docs\n",
    "            if len(doc) == 0: continue\n",
    "\n",
    "            doc_cntr += 1\n",
    "            tf_doc = self.gen_tf_score(doc)\n",
    "            idf_corpus.update(\n",
    "                {_k: idf_corpus.get(_k, 0) + 1 for _k, _v in tf_doc.items()})  # Add for the presence of term\n",
    "            #tf_doc = {_k: _v / len(doc) for _k, _v in tf_doc.items()}\n",
    "\n",
    "        return idf_corpus, doc_cntr\n",
    "\n",
    "    def gen_tf_idf_scores(self, doc_list):\n",
    "\n",
    "        global_tfidf= {}\n",
    "\n",
    "        # Obtain the document frequency scores\n",
    "        df_scores, num_doc = self.gen_df_score(doc_list)\n",
    "\n",
    "        for doc in doc_list:\n",
    "            tf_doc = Counter(doc)\n",
    "\n",
    "            for _term, _freq in tf_doc.items():\n",
    "                _term_idf = df_scores.get(_term, 0)\n",
    "                if _term_idf > 0:\n",
    "                    tfidf_score = _freq * math.log10(num_doc / _term_idf)\n",
    "                else:\n",
    "                    raise Exception(\"TFIDF calculation failed!\")\n",
    "\n",
    "                if _term in global_tfidf:\n",
    "                    global_tfidf[_term].append(tfidf_score)\n",
    "                else:\n",
    "                    global_tfidf[_term] = [tfidf_score]\n",
    "\n",
    "                #global_tfidf[_term] = [tfidf_score]\n",
    "\n",
    "        return global_tfidf\n",
    "\n",
    "    def gen_tf_idf_stats_df(self, doc_list):\n",
    "\n",
    "        global_tfidf = self.gen_tf_idf_scores(doc_list)\n",
    "\n",
    "        tfidf_list = []\n",
    "        for _term in global_tfidf:\n",
    "            tfidf_dict = {}\n",
    "            tfidf_scores = global_tfidf[_term]\n",
    "            tfidf_dict['term'] = _term\n",
    "            # tfidf_dict['mode'] = mode(tfidf_scores)\n",
    "            tfidf_dict['mean'] = np.mean(tfidf_scores)\n",
    "            tfidf_dict['median'] = np.median(tfidf_scores)\n",
    "            tfidf_dict['min'] = min(tfidf_scores)\n",
    "            tfidf_dict['max'] = max(tfidf_scores)\n",
    "            tfidf_dict['freq'] = len(tfidf_scores)\n",
    "            tfidf_list.append(tfidf_dict)\n",
    "\n",
    "        tfidf_df = pd.DataFrame(tfidf_list)\n",
    "        return tfidf_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# corp_proc_tokens = list(dataset[''])\n",
    "# tfidf_df = TfIdfExtractor().gen_tf_idf_stats_df(corp_proc_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = dataset\n",
    "y = pd.DataFrame(dataset, columns = [\"label\"])\n",
    "\n",
    "X_train , X_test , y_train , y_test = train_test_split(X, y, random_state=50,stratify=y,train_size=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    31739\n",
       "0     1999\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1340885407912871"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "3989/29749"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(token_pattern=r'\\b\\w+\\b')\n",
    "dataset_vector = vectorizer.fit_transform(X_train[\"clean_sentence\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 30443)\n"
     ]
    }
   ],
   "source": [
    "print(dataset_vector[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(33738, 30443)\n"
     ]
    }
   ],
   "source": [
    "print(dataset_vector.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48198, 20)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30443"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vectorizer.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sharpie': 23604,\n",
       " 'bold': 2734,\n",
       " 'clean': 4454,\n",
       " 'solid': 24553,\n",
       " 'lines': 14834,\n",
       " 'product': 20499,\n",
       " 'really': 21322,\n",
       " 'back': 1902,\n",
       " 'even': 8783,\n",
       " 'immediately': 12582,\n",
       " 'functionality': 10445,\n",
       " 'pencil': 18894,\n",
       " 'permanent': 19042,\n",
       " 'days': 6323,\n",
       " 'interest': 13320,\n",
       " 'need': 16940,\n",
       " 'advance': 471,\n",
       " 'lead': 14494,\n",
       " 'great': 11185,\n",
       " 'lowdown': 15128,\n",
       " 'write': 30159,\n",
       " 'cleanly': 4467,\n",
       " 'consistently': 5288,\n",
       " 'erasable': 8633,\n",
       " 'pens': 18938,\n",
       " 'sort': 24642,\n",
       " 'writes': 30164,\n",
       " 'cheaper': 4112,\n",
       " 'cheapest': 4114,\n",
       " 'bic': 2381,\n",
       " 'pen': 18885,\n",
       " 'ever': 8799,\n",
       " 'happy': 11605,\n",
       " 'never': 17051,\n",
       " 'say': 22881,\n",
       " 'changes': 4050,\n",
       " 'basically': 2107,\n",
       " 'bottom': 2887,\n",
       " 'heap': 11777,\n",
       " 'performance': 19008,\n",
       " 'avery': 1827,\n",
       " 'best': 2331,\n",
       " 'products': 20509,\n",
       " 'labels': 14216,\n",
       " 'easy': 8036,\n",
       " 'printing': 20344,\n",
       " 'old': 17757,\n",
       " 'order': 17967,\n",
       " 'company': 4944,\n",
       " 'stuff': 25580,\n",
       " 'home': 12090,\n",
       " 'simple': 23968,\n",
       " 'anyone': 1146,\n",
       " 'instructions': 13235,\n",
       " 'clear': 4477,\n",
       " 'return': 22225,\n",
       " 'also': 818,\n",
       " 'many': 15500,\n",
       " 'different': 6978,\n",
       " 'applications': 1238,\n",
       " 'folder': 9993,\n",
       " 'items': 13639,\n",
       " 'yard': 30249,\n",
       " 'sale': 22753,\n",
       " 'price': 20211,\n",
       " 'stickers': 25290,\n",
       " 'use': 28734,\n",
       " 'first': 9721,\n",
       " 'drafts': 7676,\n",
       " 'continually': 5386,\n",
       " 'new': 17056,\n",
       " 'comfortable': 4848,\n",
       " 'hand': 11498,\n",
       " 'favorites': 9366,\n",
       " 'high': 11954,\n",
       " 'school': 23018,\n",
       " 'continue': 5387,\n",
       " 'printers': 20316,\n",
       " 'market': 15554,\n",
       " 'decent': 6395,\n",
       " 'job': 13814,\n",
       " 'decide': 6402,\n",
       " 'priorities': 20406,\n",
       " 'offers': 17678,\n",
       " 'number': 17450,\n",
       " 'attractive': 1691,\n",
       " 'features': 9419,\n",
       " 'directly': 7095,\n",
       " 'camera': 3520,\n",
       " 'memory': 15854,\n",
       " 'card': 3664,\n",
       " 'print': 20281,\n",
       " 'smartphone': 24298,\n",
       " 'quite': 21091,\n",
       " 'conveniently': 5441,\n",
       " 'hp': 12254,\n",
       " 'copies': 5538,\n",
       " 'room': 22538,\n",
       " 'cable': 3404,\n",
       " 'clutter': 4630,\n",
       " 'additional': 347,\n",
       " 'cost': 5643,\n",
       " 'computer': 5081,\n",
       " 'wirelessly': 29870,\n",
       " 'scan': 22902,\n",
       " 'photos': 19222,\n",
       " 'documents': 7456,\n",
       " 'large': 14369,\n",
       " 'convenient': 5438,\n",
       " 'last': 14398,\n",
       " 'size': 24054,\n",
       " 'less': 14631,\n",
       " 'others': 18082,\n",
       " 'space': 24685,\n",
       " 'premium': 20097,\n",
       " 'workspace': 30063,\n",
       " 'unit': 28332,\n",
       " 'small': 24277,\n",
       " 'specifically': 24758,\n",
       " 'footprint': 10063,\n",
       " 'almost': 789,\n",
       " 'printer': 20290,\n",
       " 'half': 11459,\n",
       " 'trouble': 27718,\n",
       " 'know': 14142,\n",
       " 'information': 12969,\n",
       " 'wireless': 29866,\n",
       " 'router': 22591,\n",
       " 'originally': 18038,\n",
       " 'drivers': 7758,\n",
       " 'cd': 3932,\n",
       " 'functions': 10448,\n",
       " 'touch': 27388,\n",
       " 'screen': 23114,\n",
       " 'smoothly': 24362,\n",
       " 'epson': 8600,\n",
       " 'service': 23443,\n",
       " 'emailing': 8294,\n",
       " 'email': 8292,\n",
       " 'address': 354,\n",
       " 'method': 15936,\n",
       " 'slightly': 24204,\n",
       " 'hour': 12220,\n",
       " 'ink': 13038,\n",
       " 'cartridges': 3800,\n",
       " 'photo': 19193,\n",
       " 'copy': 5545,\n",
       " 'well': 29590,\n",
       " 'used': 28744,\n",
       " 'glossy': 10897,\n",
       " 'paper': 18528,\n",
       " 'problem': 20454,\n",
       " 'good': 10970,\n",
       " 'better': 2347,\n",
       " 'quality': 20972,\n",
       " 'prints': 20389,\n",
       " 'text': 26573,\n",
       " 'excellent': 8863,\n",
       " 'dark': 6261,\n",
       " 'black': 2494,\n",
       " 'sharp': 23575,\n",
       " 'pops': 19785,\n",
       " 'right': 22374,\n",
       " 'individual': 12893,\n",
       " 'colors': 4792,\n",
       " 'advantage': 477,\n",
       " 'cartridge': 3790,\n",
       " 'color': 4761,\n",
       " 'whole': 29734,\n",
       " 'costs': 5655,\n",
       " 'much': 16619,\n",
       " 'downside': 7636,\n",
       " 'word': 29997,\n",
       " 'processing': 20472,\n",
       " 'white': 29707,\n",
       " 'fair': 9215,\n",
       " 'amount': 918,\n",
       " 'copying': 5550,\n",
       " 'idea': 12437,\n",
       " 'spend': 24811,\n",
       " 'money': 16395,\n",
       " 'choice': 4256,\n",
       " 'factors': 9185,\n",
       " 'present': 20131,\n",
       " 'shopping': 23757,\n",
       " 'around': 1383,\n",
       " 'read': 21270,\n",
       " 'reference': 21570,\n",
       " 'books': 2806,\n",
       " 'note': 17321,\n",
       " 'sections': 23256,\n",
       " 'important': 12650,\n",
       " 'pages': 18423,\n",
       " 'future': 10515,\n",
       " 'scotch': 23068,\n",
       " 'tape': 26291,\n",
       " 'markers': 15546,\n",
       " 'bright': 3069,\n",
       " 'removable': 21828,\n",
       " 'big': 2396,\n",
       " 'enough': 8481,\n",
       " 'annotations': 1061,\n",
       " 'cube': 6042,\n",
       " 'years': 30272,\n",
       " 'people': 18959,\n",
       " 'work': 30008,\n",
       " 'item': 13634,\n",
       " 'significants': 23919,\n",
       " 'functional': 10443,\n",
       " 'little': 14911,\n",
       " 'office': 17681,\n",
       " 'however': 12250,\n",
       " 'often': 17720,\n",
       " 'enjoy': 8461,\n",
       " 'artisan': 1433,\n",
       " 'special': 24744,\n",
       " 'qualities': 20970,\n",
       " 'feed': 9443,\n",
       " 'extremely': 9118,\n",
       " 'cards': 3688,\n",
       " 'leader': 14495,\n",
       " 'thicker': 26858,\n",
       " 'art': 1409,\n",
       " 'papers': 18571,\n",
       " 'doubt': 7598,\n",
       " 'system': 26131,\n",
       " 'durabrite': 7906,\n",
       " 'perfect': 18989,\n",
       " 'anything': 1149,\n",
       " 'collage': 4719,\n",
       " 'transfer': 27510,\n",
       " 'matte': 15658,\n",
       " 'heavyweight': 11818,\n",
       " 'already': 815,\n",
       " 'similar': 23958,\n",
       " 'canon': 3578,\n",
       " 'main': 15355,\n",
       " 'difference': 6975,\n",
       " 'definitely': 6509,\n",
       " 'delivers': 6582,\n",
       " 'detail': 6810,\n",
       " 'time': 27119,\n",
       " 'end': 8398,\n",
       " 'spending': 24812,\n",
       " 'road': 22457,\n",
       " 'nice': 17111,\n",
       " 'mess': 15907,\n",
       " 'function': 10441,\n",
       " 'place': 19442,\n",
       " 'document': 7448,\n",
       " 'press': 20160,\n",
       " 'fax': 9373,\n",
       " 'opinion': 17895,\n",
       " 'incredible': 12827,\n",
       " 'value': 28877,\n",
       " 'fun': 10436,\n",
       " 'drawbacks': 7701,\n",
       " 'blue': 2650,\n",
       " 'nubs': 17433,\n",
       " 'lightness': 14754,\n",
       " 'orange': 17952,\n",
       " 'hard': 11609,\n",
       " 'notes': 17341,\n",
       " 'friends': 10334,\n",
       " 'lot': 15091,\n",
       " 'dispenser': 7271,\n",
       " 'recommend': 21452,\n",
       " 'pleased': 19555,\n",
       " 'find': 9631,\n",
       " 'folders': 9996,\n",
       " 'appear': 1211,\n",
       " 'plenty': 19569,\n",
       " 'abuse': 87,\n",
       " 'frequently': 10311,\n",
       " 'relabel': 21711,\n",
       " 'reuse': 22240,\n",
       " 'appreciate': 1258,\n",
       " 'pair': 18468,\n",
       " 'super': 25821,\n",
       " 'sticky': 25307,\n",
       " 'x': 30197,\n",
       " 'inches': 12749,\n",
       " 'neon': 16991,\n",
       " 'pack': 18350,\n",
       " 'happen': 11595,\n",
       " 'fit': 9736,\n",
       " 'tabs': 26165,\n",
       " 'fast': 9307,\n",
       " 'everything': 8813,\n",
       " 'huge': 12290,\n",
       " 'improvement': 12692,\n",
       " 'track': 27452,\n",
       " 'detachable': 6805,\n",
       " 'always': 854,\n",
       " 'inserts': 13141,\n",
       " 'soon': 24614,\n",
       " 'come': 4841,\n",
       " 'inconvenient': 12812,\n",
       " 'times': 27138,\n",
       " 'liked': 14772,\n",
       " 'measurement': 15752,\n",
       " 'colours': 4813,\n",
       " 'handy': 11569,\n",
       " 'grab': 11049,\n",
       " 'business': 3322,\n",
       " 'personal': 19083,\n",
       " 'conversation': 5452,\n",
       " 'sheet': 23646,\n",
       " 'actually': 292,\n",
       " 'wanted': 29339,\n",
       " 'priority': 20408,\n",
       " 'things': 26883,\n",
       " 'sense': 23363,\n",
       " 'satisfaction': 22838,\n",
       " 'control': 5422,\n",
       " 'seemingly': 23291,\n",
       " 'details': 6814,\n",
       " 'pretty': 20188,\n",
       " 'patterned': 18761,\n",
       " 'decorations': 6439,\n",
       " 'top': 27332,\n",
       " 'middle': 16020,\n",
       " 'feminine': 9480,\n",
       " 'regular': 21661,\n",
       " 'grip': 11253,\n",
       " 'part': 18654,\n",
       " 'third': 26904,\n",
       " 'spongy': 24899,\n",
       " 'feel': 9456,\n",
       " 'hold': 12064,\n",
       " 'love': 15111,\n",
       " 'purple': 20869,\n",
       " 'afraid': 567,\n",
       " 'playful': 19533,\n",
       " 'crytal': 6029,\n",
       " 'clickers': 4514,\n",
       " 'hexagon': 11927,\n",
       " 'crystal': 6027,\n",
       " 'decoration': 6438,\n",
       " 'body': 2721,\n",
       " 'sure': 25918,\n",
       " 'clip': 4535,\n",
       " 'necessary': 16929,\n",
       " 'women': 29964,\n",
       " 'usually': 28818,\n",
       " 'pockets': 19643,\n",
       " 'useful': 28760,\n",
       " 'tourquoise': 27418,\n",
       " 'pleasure': 19562,\n",
       " 'day': 6313,\n",
       " 'absolutely': 68,\n",
       " 'laptop': 14364,\n",
       " 'table': 26146,\n",
       " 'countertop': 5698,\n",
       " 'etc': 8739,\n",
       " 'surface': 25926,\n",
       " 'pad': 18394,\n",
       " 'rules': 22662,\n",
       " 'zoom': 30435,\n",
       " 'away': 1853,\n",
       " 'sticks': 25302,\n",
       " 'next': 17097,\n",
       " 'burning': 3299,\n",
       " 'batteries': 2139,\n",
       " 'mouse': 16552,\n",
       " 'unfriendly': 28253,\n",
       " 'see': 23275,\n",
       " 'longer': 15020,\n",
       " 'probably': 20450,\n",
       " 'prismy': 20419,\n",
       " 'cooling': 5502,\n",
       " 'total': 27376,\n",
       " 'stapler': 25125,\n",
       " 'powerful': 19938,\n",
       " 'tool': 27303,\n",
       " 'description': 6710,\n",
       " 'meant': 15742,\n",
       " 'yet': 30309,\n",
       " 'staple': 25123,\n",
       " 'something': 24595,\n",
       " 'effort': 8168,\n",
       " 'engineer': 8445,\n",
       " 'squeeze': 24991,\n",
       " 'point': 19668,\n",
       " 'suddenly': 25742,\n",
       " 'boom': 2820,\n",
       " 'thing': 26879,\n",
       " 'stick': 25283,\n",
       " 'staples': 25136,\n",
       " 'break': 3014,\n",
       " 'guess': 11348,\n",
       " 'limitation': 14805,\n",
       " 'thick': 26853,\n",
       " 'stands': 25109,\n",
       " 'easily': 8021,\n",
       " 'line': 14817,\n",
       " 'smack': 24273,\n",
       " 'past': 18715,\n",
       " 'experience': 9004,\n",
       " 'ship': 23709,\n",
       " 'helpful': 11867,\n",
       " 'cute': 6153,\n",
       " 'magnets': 15318,\n",
       " 'board': 2689,\n",
       " 'sturdy': 25606,\n",
       " 'refrigerator': 21619,\n",
       " 'magnetic': 15311,\n",
       " 'put': 20908,\n",
       " 'sign': 23906,\n",
       " 'dishes': 7221,\n",
       " 'list': 14877,\n",
       " 'markings': 15565,\n",
       " 'pixma': 19426,\n",
       " 'inkjet': 13060,\n",
       " 'users': 28784,\n",
       " 'area': 1337,\n",
       " 'low': 15126,\n",
       " 'basics': 2109,\n",
       " 'duplex': 7884,\n",
       " 'capability': 3602,\n",
       " 'ability': 36,\n",
       " 'sides': 23886,\n",
       " 'wifi': 29778,\n",
       " 'anywhere': 1157,\n",
       " 'speed': 24782,\n",
       " 'upgrade': 28636,\n",
       " 'older': 17761,\n",
       " 'brother': 3125,\n",
       " 'mfc': 15951,\n",
       " 'cases': 3838,\n",
       " 'notice': 17361,\n",
       " 'terms': 26540,\n",
       " 'quickly': 21057,\n",
       " 'overall': 18197,\n",
       " 'readable': 21273,\n",
       " 'pictures': 19302,\n",
       " 'interested': 13321,\n",
       " 'laser': 14384,\n",
       " 'instead': 13215,\n",
       " 'similarly': 23963,\n",
       " 'primary': 20257,\n",
       " 'goal': 10933,\n",
       " 'model': 16309,\n",
       " 'versatility': 29015,\n",
       " 'fine': 9640,\n",
       " 'mind': 16090,\n",
       " 'get': 10751,\n",
       " 'capable': 3609,\n",
       " 'long': 15018,\n",
       " 'term': 26531,\n",
       " 'uses': 28785,\n",
       " 'separate': 23389,\n",
       " 'run': 22672,\n",
       " 'magenta': 15292,\n",
       " 'whereas': 29669,\n",
       " 'folks': 10014,\n",
       " 'simplicity': 23977,\n",
       " 'purchase': 20847,\n",
       " 'durable': 7899,\n",
       " 'postal': 19865,\n",
       " 'person': 19082,\n",
       " 'cram': 5808,\n",
       " 'box': 2921,\n",
       " 'crease': 5856,\n",
       " 'center': 3972,\n",
       " 'laid': 14278,\n",
       " 'flat': 9803,\n",
       " 'purposes': 20882,\n",
       " 'completely': 5019,\n",
       " 'flip': 9882,\n",
       " 'side': 23873,\n",
       " 'particularly': 18672,\n",
       " 'removed': 21838,\n",
       " 'composition': 5048,\n",
       " 'book': 2773,\n",
       " 'flexible': 9851,\n",
       " 'desktop': 6775,\n",
       " 'holder': 12065,\n",
       " 'strong': 25534,\n",
       " 'secure': 23259,\n",
       " 'fan': 9252,\n",
       " 'reality': 21313,\n",
       " 'rarely': 21203,\n",
       " 'several': 23494,\n",
       " 'complaints': 5012,\n",
       " 'usage': 28719,\n",
       " 'still': 25326,\n",
       " 'shape': 23556,\n",
       " 'wire': 29861,\n",
       " 'mesh': 15904,\n",
       " 'style': 25617,\n",
       " 'mount': 16541,\n",
       " 'finish': 9676,\n",
       " 'adjustments': 417,\n",
       " 'smooth': 24355,\n",
       " 'professional': 20521,\n",
       " 'classy': 4447,\n",
       " 'real': 21305,\n",
       " 'metal': 15924,\n",
       " 'accents': 116,\n",
       " 'stainless': 25063,\n",
       " 'steel': 25235,\n",
       " 'materials': 15639,\n",
       " 'notch': 17318,\n",
       " 'structural': 25546,\n",
       " 'components': 5040,\n",
       " 'plastic': 19494,\n",
       " 'cut': 6150,\n",
       " 'parts': 18687,\n",
       " 'cap': 3598,\n",
       " 'vertical': 29030,\n",
       " 'base': 2093,\n",
       " 'tube': 27780,\n",
       " 'management': 15416,\n",
       " 'manufacturer': 15489,\n",
       " 'clearly': 4487,\n",
       " 'corners': 5592,\n",
       " 'mine': 16099,\n",
       " 'light': 14738,\n",
       " 'scratches': 23098,\n",
       " 'noticeable': 17362,\n",
       " 'closely': 4570,\n",
       " 'wide': 29756,\n",
       " 'range': 21182,\n",
       " 'adjustment': 416,\n",
       " 'rear': 21338,\n",
       " 'edge': 8102,\n",
       " 'desk': 6757,\n",
       " 'bring': 3085,\n",
       " 'monitor': 16401,\n",
       " 'forward': 10193,\n",
       " 'chair': 4019,\n",
       " 'feet': 9461,\n",
       " 'distance': 7333,\n",
       " 'adjustable': 409,\n",
       " 'widescreen': 29765,\n",
       " 'portrait': 19824,\n",
       " 'mode': 16306,\n",
       " 'plan': 19466,\n",
       " 'basis': 2111,\n",
       " 'larger': 14373,\n",
       " 'due': 7843,\n",
       " 'insufficient': 13254,\n",
       " 'clearance': 4478,\n",
       " 'maximum': 15687,\n",
       " 'height': 11836,\n",
       " 'hardware': 11633,\n",
       " 'permits': 19054,\n",
       " 'desks': 6769,\n",
       " 'thicknesses': 26864,\n",
       " 'hole': 12075,\n",
       " 'benefits': 2311,\n",
       " 'accurate': 204,\n",
       " 'neck': 16933,\n",
       " 'shoulder': 23784,\n",
       " 'pain': 18447,\n",
       " 'eye': 9125,\n",
       " 'strain': 25432,\n",
       " 'adjust': 407,\n",
       " 'posture': 19890,\n",
       " 'suit': 25771,\n",
       " 'position': 19840,\n",
       " 'struggle': 25551,\n",
       " 'far': 9276,\n",
       " 'extension': 9087,\n",
       " 'stand': 25085,\n",
       " 'clampfor': 4401,\n",
       " 'together': 27237,\n",
       " 'ergotron': 8668,\n",
       " 'mounts': 16550,\n",
       " 'bit': 2460,\n",
       " 'easier': 8018,\n",
       " 'stay': 25214,\n",
       " 'worth': 30090,\n",
       " 'improve': 12690,\n",
       " 'comfort': 4847,\n",
       " 'highly': 11977,\n",
       " 'ago': 614,\n",
       " 'pouches': 19908,\n",
       " 'prefers': 20071,\n",
       " 'letter': 14647,\n",
       " 'sheets': 23655,\n",
       " 'simply': 23984,\n",
       " 'pouch': 19906,\n",
       " 'stores': 25397,\n",
       " 'neatly': 16918,\n",
       " 'addition': 346,\n",
       " 'spilled': 24836,\n",
       " 'coffee': 4693,\n",
       " 'tea': 26362,\n",
       " 'paperwork': 18591,\n",
       " 'reprint': 21964,\n",
       " 'helper': 11865,\n",
       " 'owner': 18317,\n",
       " 'shelf': 23668,\n",
       " 'way': 29473,\n",
       " 'businesses': 3323,\n",
       " 'dress': 7723,\n",
       " 'store': 25393,\n",
       " 'look': 15038,\n",
       " 'razor': 21252,\n",
       " 'change': 4043,\n",
       " 'inventory': 13444,\n",
       " 'prices': 20233,\n",
       " 'label': 14198,\n",
       " 'technology': 26399,\n",
       " 'game': 10562,\n",
       " 'set': 23454,\n",
       " 'payments': 18785,\n",
       " 'check': 4128,\n",
       " 'columbian': 4815,\n",
       " 'security': 23269,\n",
       " 'envelopes': 8541,\n",
       " 'purpose': 20877,\n",
       " 'drugstore': 7802,\n",
       " 'brand': 2986,\n",
       " 'thin': 26876,\n",
       " 'flimsy': 9875,\n",
       " 'binder': 2427,\n",
       " 'option': 17931,\n",
       " 'certainly': 3996,\n",
       " 'rings': 22401,\n",
       " 'kids': 14048,\n",
       " 'binders': 2432,\n",
       " 'ring': 22395,\n",
       " 'claim': 4392,\n",
       " 'especially': 8702,\n",
       " 'hinge': 12001,\n",
       " 'surprised': 25950,\n",
       " 'particular': 18669,\n",
       " 'sometimes': 24599,\n",
       " 'basic': 2106,\n",
       " 'options': 17939,\n",
       " 'jones': 13843,\n",
       " 'heavy': 11814,\n",
       " 'duty': 7928,\n",
       " 'think': 26887,\n",
       " 'nicer': 17119,\n",
       " 'children': 4215,\n",
       " 'overly': 18248,\n",
       " 'average': 1817,\n",
       " 'relationship': 21722,\n",
       " 'boards': 2700,\n",
       " 'variety': 28907,\n",
       " 'messages': 15910,\n",
       " 'reminder': 21810,\n",
       " 'months': 16444,\n",
       " 'dingy': 7063,\n",
       " 'liquid': 14872,\n",
       " 'cleaners': 4461,\n",
       " 'pick': 19267,\n",
       " 'sharpy': 23618,\n",
       " 'matter': 15663,\n",
       " 'magic': 15296,\n",
       " 'recommended': 21456,\n",
       " 'wish': 29886,\n",
       " 'earlier': 7986,\n",
       " 'stickiness': 25296,\n",
       " 'suggest': 25763,\n",
       " 'stack': 25039,\n",
       " 'prevents': 20200,\n",
       " 'jams': 13724,\n",
       " 'stars': 25159,\n",
       " 'stickier': 25293,\n",
       " 'fairly': 9218,\n",
       " 'stock': 25349,\n",
       " 'lables': 14248,\n",
       " 'package': 18354,\n",
       " 'inexpensive': 12932,\n",
       " 'solve': 24566,\n",
       " 'expensive': 8989,\n",
       " 'storage': 25387,\n",
       " 'clipboard': 4537,\n",
       " 'fall': 9229,\n",
       " 'compartments': 4964,\n",
       " 'works': 30055,\n",
       " 'wanting': 29341,\n",
       " 'cruise': 5996,\n",
       " 'take': 26221,\n",
       " 'dividers': 7403,\n",
       " 'certain': 3995,\n",
       " 'categories': 3883,\n",
       " 'flights': 9867,\n",
       " 'docs': 7442,\n",
       " 'hotels': 12210,\n",
       " 'rental': 21864,\n",
       " 'cars': 3760,\n",
       " 'divider': 7402,\n",
       " 'identification': 12449,\n",
       " 'section': 23253,\n",
       " 'names': 16825,\n",
       " 'city': 4378,\n",
       " 'country': 5703,\n",
       " 'date': 6296,\n",
       " 'trip': 27687,\n",
       " 'bag': 1962,\n",
       " 'excursion': 8895,\n",
       " 'receipts': 21387,\n",
       " 'dog': 7478,\n",
       " 'ear': 7980,\n",
       " 'previous': 20204,\n",
       " 'eagerly': 7975,\n",
       " 'eraser': 8640,\n",
       " 'erasers': 8644,\n",
       " 'disappear': 7118,\n",
       " 'yellow': 30282,\n",
       " 'invisible': 13466,\n",
       " 'teacher': 26364,\n",
       " 'answers': 1099,\n",
       " 'student': 25569,\n",
       " 'able': 39,\n",
       " 'whist': 29703,\n",
       " 'exam': 8845,\n",
       " 'try': 27764,\n",
       " 'loose': 15060,\n",
       " 'pay': 18777,\n",
       " 'attention': 1676,\n",
       " 'mistakenly': 16232,\n",
       " 'maybe': 15695,\n",
       " 'pros': 20657,\n",
       " 'spine': 24843,\n",
       " 'pocket': 19635,\n",
       " 'cover': 5737,\n",
       " 'front': 10368,\n",
       " 'gray': 11172,\n",
       " 'elastic': 8212,\n",
       " 'loop': 15057,\n",
       " 'button': 3355,\n",
       " 'keep': 13981,\n",
       " 'pencils': 18896,\n",
       " 'transparent': 27552,\n",
       " 'insert': 13135,\n",
       " 'title': 27200,\n",
       " 'page': 18411,\n",
       " 'apart': 1171,\n",
       " 'least': 14538,\n",
       " 'inch': 12747,\n",
       " 'along': 796,\n",
       " 'classes': 4427,\n",
       " 'fabric': 9152,\n",
       " 'swatches': 26010,\n",
       " 'difficult': 6995,\n",
       " 'open': 17866,\n",
       " 'close': 4566,\n",
       " 'loud': 15101,\n",
       " 'sound': 24658,\n",
       " 'discreet': 7195,\n",
       " 'library': 14692,\n",
       " 'classroom': 4443,\n",
       " 'accessories': 142,\n",
       " 'amazon': 872,\n",
       " 'vine': 29113,\n",
       " 'reviewer': 22271,\n",
       " 'receive': 21389,\n",
       " 'fully': 10430,\n",
       " 'unfortunately': 28249,\n",
       " 'give': 10821,\n",
       " 'score': 23061,\n",
       " 'general': 10689,\n",
       " 'aware': 1849,\n",
       " 'stacks': 25048,\n",
       " 'therapeutic': 26769,\n",
       " 'writer': 30161,\n",
       " 'shredder': 23820,\n",
       " 'motor': 16526,\n",
       " 'shredders': 23825,\n",
       " 'cardboard': 3667,\n",
       " 'normal': 17283,\n",
       " 'type': 27897,\n",
       " 'handle': 11532,\n",
       " 'talk': 26236,\n",
       " 'strange': 25439,\n",
       " 'generally': 10692,\n",
       " 'cds': 3938,\n",
       " 'mechanism': 15768,\n",
       " 'shreds': 23837,\n",
       " 'slot': 24248,\n",
       " 'cuts': 6166,\n",
       " 'pieces': 19313,\n",
       " 'destroy': 6798,\n",
       " 'disability': 7108,\n",
       " 'fact': 9178,\n",
       " 'digital': 7017,\n",
       " 'downloadable': 7625,\n",
       " 'power': 19934,\n",
       " 'bin': 2423,\n",
       " 'informative': 12974,\n",
       " 'recently': 21398,\n",
       " 'cross': 5966,\n",
       " 'town': 27430,\n",
       " 'move': 16570,\n",
       " 'seattle': 23229,\n",
       " 'mexico': 15949,\n",
       " 'boxes': 2927,\n",
       " 'mirrors': 16159,\n",
       " 'collectible': 4738,\n",
       " 'comic': 4859,\n",
       " 'final': 9621,\n",
       " 'year': 30265,\n",
       " 'star': 25144,\n",
       " 'stackable': 25041,\n",
       " 'locker': 14975,\n",
       " 'piece': 19311,\n",
       " 'transport': 27559,\n",
       " 'assemble': 1507,\n",
       " 'inside': 13147,\n",
       " 'keys': 14019,\n",
       " 'support': 25883,\n",
       " 'wobbly': 29951,\n",
       " 'free': 10276,\n",
       " 'lock': 14970,\n",
       " 'disassemble': 7134,\n",
       " 'interior': 13341,\n",
       " 'ample': 927,\n",
       " 'capacity': 3616,\n",
       " 'tall': 26245,\n",
       " 'indentations': 12849,\n",
       " 'personalize': 19086,\n",
       " 'frustrated': 10391,\n",
       " 'deploy': 6667,\n",
       " 'tried': 27652,\n",
       " 'penclip': 18908,\n",
       " 'deploys': 6669,\n",
       " 'click': 4510,\n",
       " 'harder': 11625,\n",
       " 'luckily': 15173,\n",
       " 'user': 28780,\n",
       " 'darn': 6274,\n",
       " 'otherwise': 18087,\n",
       " 'cool': 5496,\n",
       " 'multipen': 16667,\n",
       " 'beautifully': 2206,\n",
       " 'anyway': 1152,\n",
       " 'tricky': 27649,\n",
       " 'tip': 27173,\n",
       " 'expose': 9057,\n",
       " 'refills': 21589,\n",
       " 'reasonable': 21344,\n",
       " 'proposition': 20652,\n",
       " 'current': 6099,\n",
       " 'kind': 14059,\n",
       " 'bulbous': 3223,\n",
       " 'pilot': 19348,\n",
       " 'chunky': 4322,\n",
       " 'rubber': 22624,\n",
       " 'pleasant': 19550,\n",
       " 'strips': 25524,\n",
       " 'adhesive': 392,\n",
       " 'inevitably': 12930,\n",
       " 'nuisance': 17442,\n",
       " 'exactly': 8835,\n",
       " 'single': 24006,\n",
       " 'neater': 16916,\n",
       " 'saver': 22868,\n",
       " 'tough': 27407,\n",
       " 'daily': 6222,\n",
       " 'gentle': 10719,\n",
       " 'material': 15635,\n",
       " 'mark': 15536,\n",
       " 'marker': 15540,\n",
       " 'worries': 30081,\n",
       " 'ones': 17807,\n",
       " 'workbooks': 30016,\n",
       " 'early': 7989,\n",
       " 'boring': 2853,\n",
       " 'child': 4211,\n",
       " 'activities': 285,\n",
       " 'logical': 14992,\n",
       " 'grader': 11070,\n",
       " 'want': 29338,\n",
       " 'stop': 25373,\n",
       " 'ways': 29478,\n",
       " 'math': 15644,\n",
       " 'maps': 15509,\n",
       " 'clues': 4611,\n",
       " 'charts': 4098,\n",
       " 'fantastic': 9268,\n",
       " 'workbook': 30015,\n",
       " 'relaxation': 21730,\n",
       " 'relief': 21758,\n",
       " 'adult': 467,\n",
       " 'level': 14658,\n",
       " 'picked': 19268,\n",
       " 'problems': 20458,\n",
       " 'spiral': 24850,\n",
       " 'con': 5100,\n",
       " 'start': 25168,\n",
       " 'presentations': 20135,\n",
       " 'bible': 2377,\n",
       " 'studies': 25573,\n",
       " 'binding': 2435,\n",
       " 'runs': 22684,\n",
       " 'smaller': 24278,\n",
       " 'projects': 20577,\n",
       " 'camper': 3536,\n",
       " 'dispense': 7269,\n",
       " 'sorry': 24641,\n",
       " 'moron': 16481,\n",
       " 'increadibly': 12822,\n",
       " 'fha': 9517,\n",
       " 'loan': 14947,\n",
       " 'morgage': 16474,\n",
       " 'litter': 14907,\n",
       " 'assume': 1555,\n",
       " 'cats': 3896,\n",
       " 'heavily': 11812,\n",
       " 'weighted': 29564,\n",
       " 'asscotch': 1504,\n",
       " 'deluxe': 6590,\n",
       " 'core': 5577,\n",
       " 'tapes': 26307,\n",
       " 'pull': 20799,\n",
       " 'proper': 20635,\n",
       " 'length': 14614,\n",
       " 'mousetrap': 16559,\n",
       " 'gazillions': 10639,\n",
       " 'blade': 2531,\n",
       " 'sharpeners': 23589,\n",
       " 'wood': 29981,\n",
       " 'sharpens': 23597,\n",
       " 'feature': 9413,\n",
       " 'multiple': 16670,\n",
       " 'sizes': 24064,\n",
       " 'concept': 5112,\n",
       " 'remove': 21836,\n",
       " 'sticker': 25289,\n",
       " 'notebooks': 17327,\n",
       " 'rip': 22418,\n",
       " 'pads': 18405,\n",
       " 'stronger': 25536,\n",
       " 'consultant': 5330,\n",
       " 'pet': 19116,\n",
       " 'companies': 4939,\n",
       " 'megacheap': 15809,\n",
       " 'ml': 16273,\n",
       " 'buy': 3367,\n",
       " 'house': 12227,\n",
       " 'tab': 26142,\n",
       " 'rigid': 22384,\n",
       " 'else': 8280,\n",
       " 'lots': 15097,\n",
       " 'mall': 15403,\n",
       " 'manage': 15412,\n",
       " 'snag': 24395,\n",
       " 'hangers': 11579,\n",
       " 'corridor': 5629,\n",
       " 'care': 3701,\n",
       " 'smell': 24324,\n",
       " 'dumpster': 7869,\n",
       " 'savory': 22875,\n",
       " 'elements': 8248,\n",
       " 'digging': 7011,\n",
       " 'treasure': 27609,\n",
       " 'empty': 8350,\n",
       " 'roll': 22506,\n",
       " 'tear': 26374,\n",
       " 'gun': 11387,\n",
       " 'worried': 30080,\n",
       " 'weight': 29561,\n",
       " 'bet': 2338,\n",
       " 'diagram': 6916,\n",
       " 'dig': 7007,\n",
       " 'pile': 19333,\n",
       " 'trash': 27572,\n",
       " 'truck': 27734,\n",
       " 'bookmark': 2796,\n",
       " 'husband': 12358,\n",
       " 'sales': 22755,\n",
       " 'show': 23797,\n",
       " 'customers': 6137,\n",
       " 'customer': 6135,\n",
       " 'allows': 774,\n",
       " 'frequent': 10309,\n",
       " 'customize': 6144,\n",
       " 'entire': 8521,\n",
       " 'ballpoint': 2004,\n",
       " 'erase': 8637,\n",
       " 'translucent': 27540,\n",
       " 'stylish': 25624,\n",
       " 'adequate': 368,\n",
       " 'organizers': 18003,\n",
       " 'ball': 1995,\n",
       " 'rating': 21222,\n",
       " 'barrels': 2081,\n",
       " 'cheap': 4108,\n",
       " 'match': 15628,\n",
       " 'brittle': 3097,\n",
       " 'scratched': 23096,\n",
       " 'angles': 1028,\n",
       " 'narrow': 16844,\n",
       " 'barrel': 2079,\n",
       " 'hands': 11548,\n",
       " 'finger': 9661,\n",
       " 'personally': 19088,\n",
       " 'firmer': 9711,\n",
       " 'compensate': 4981,\n",
       " 'tell': 26457,\n",
       " 'writers': 30163,\n",
       " 'callous': 3490,\n",
       " 'suppose': 25896,\n",
       " ...}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "vectorizer = CountVectorizer(token_pattern=r'\\b\\w+\\b')\n",
    "dataset_vector = vectorizer.fit_transform(X_train[\"clean_sentence\"])\n",
    "\n",
    "\n",
    "chi2_selector = chi2(dataset_vector, X_train['label'])\n",
    "\n",
    "list_tokens=[]\n",
    "for key, val in vectorizer.vocabulary_.items():    # for name, age in dictionary.iteritems():  (for Python 2.x)\n",
    "        if key in frequency_tokens:\n",
    "            list_tokens.append([key,val,frequency_tokens[key],chi2_selector[0][val],chi2_selector[1][val]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "unigram_df=pd.DataFrame(list_tokens,columns=['token','index','frquency','chi2','p_value'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>index</th>\n",
       "      <th>frquency</th>\n",
       "      <th>chi2</th>\n",
       "      <th>p_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sharpie</td>\n",
       "      <td>23604</td>\n",
       "      <td>951</td>\n",
       "      <td>0.041787</td>\n",
       "      <td>8.380266e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bold</td>\n",
       "      <td>2734</td>\n",
       "      <td>568</td>\n",
       "      <td>0.707124</td>\n",
       "      <td>4.004003e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>clean</td>\n",
       "      <td>4454</td>\n",
       "      <td>2677</td>\n",
       "      <td>0.998970</td>\n",
       "      <td>3.175598e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>solid</td>\n",
       "      <td>24553</td>\n",
       "      <td>1866</td>\n",
       "      <td>6.256164</td>\n",
       "      <td>1.237619e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>product</td>\n",
       "      <td>20499</td>\n",
       "      <td>10598</td>\n",
       "      <td>174.238228</td>\n",
       "      <td>8.781325e-40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     token  index  frquency        chi2       p_value\n",
       "0  sharpie  23604       951    0.041787  8.380266e-01\n",
       "1     bold   2734       568    0.707124  4.004003e-01\n",
       "2    clean   4454      2677    0.998970  3.175598e-01\n",
       "3    solid  24553      1866    6.256164  1.237619e-02\n",
       "4  product  20499     10598  174.238228  8.781325e-40"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unigram_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>index</th>\n",
       "      <th>frquency</th>\n",
       "      <th>chi2</th>\n",
       "      <th>p_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1573</th>\n",
       "      <td>poor</td>\n",
       "      <td>19771</td>\n",
       "      <td>290</td>\n",
       "      <td>448.821425</td>\n",
       "      <td>1.301987e-99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>printer</td>\n",
       "      <td>20290</td>\n",
       "      <td>26633</td>\n",
       "      <td>426.733519</td>\n",
       "      <td>8.353022e-95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1560</th>\n",
       "      <td>useless</td>\n",
       "      <td>28771</td>\n",
       "      <td>229</td>\n",
       "      <td>371.991124</td>\n",
       "      <td>6.897120e-83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>710</th>\n",
       "      <td>support</td>\n",
       "      <td>25883</td>\n",
       "      <td>1915</td>\n",
       "      <td>365.103304</td>\n",
       "      <td>2.179594e-81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>845</th>\n",
       "      <td>customer</td>\n",
       "      <td>6135</td>\n",
       "      <td>488</td>\n",
       "      <td>357.687075</td>\n",
       "      <td>8.978858e-80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>hp</td>\n",
       "      <td>12254</td>\n",
       "      <td>4094</td>\n",
       "      <td>350.685178</td>\n",
       "      <td>3.005612e-78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4977</th>\n",
       "      <td>refund</td>\n",
       "      <td>21622</td>\n",
       "      <td>35</td>\n",
       "      <td>325.801453</td>\n",
       "      <td>7.893216e-73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>service</td>\n",
       "      <td>23443</td>\n",
       "      <td>1145</td>\n",
       "      <td>305.610285</td>\n",
       "      <td>1.974769e-68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1552</th>\n",
       "      <td>worst</td>\n",
       "      <td>30089</td>\n",
       "      <td>97</td>\n",
       "      <td>301.471966</td>\n",
       "      <td>1.574281e-67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1241</th>\n",
       "      <td>bad</td>\n",
       "      <td>1950</td>\n",
       "      <td>1363</td>\n",
       "      <td>300.815176</td>\n",
       "      <td>2.188632e-67</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         token  index  frquency        chi2       p_value\n",
       "1573      poor  19771       290  448.821425  1.301987e-99\n",
       "110    printer  20290     26633  426.733519  8.353022e-95\n",
       "1560   useless  28771       229  371.991124  6.897120e-83\n",
       "710    support  25883      1915  365.103304  2.179594e-81\n",
       "845   customer   6135       488  357.687075  8.978858e-80\n",
       "86          hp  12254      4094  350.685178  3.005612e-78\n",
       "4977    refund  21622        35  325.801453  7.893216e-73\n",
       "124    service  23443      1145  305.610285  1.974769e-68\n",
       "1552     worst  30089        97  301.471966  1.574281e-67\n",
       "1241       bad   1950      1363  300.815176  2.188632e-67"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unigram_df.sort_values(by='chi2',ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter on chi pvalue and frequency\n",
    "unigram_df=unigram_df[(unigram_df['chi2']>10)&(unigram_df['frquency']>10)&(unigram_df['p_value']<0.05)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>index</th>\n",
       "      <th>frquency</th>\n",
       "      <th>chi2</th>\n",
       "      <th>p_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4143</th>\n",
       "      <td>garbage</td>\n",
       "      <td>10593</td>\n",
       "      <td>109</td>\n",
       "      <td>82.266333</td>\n",
       "      <td>1.189308e-19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        token  index  frquency       chi2       p_value\n",
       "4143  garbage  10593       109  82.266333  1.189308e-19"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unigram_df[unigram_df.token.str.contains('garbage')]\n",
    "# significant\n",
    "#frequency cutoff -5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>index</th>\n",
       "      <th>frquency</th>\n",
       "      <th>chi2</th>\n",
       "      <th>p_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6246</th>\n",
       "      <td>profit</td>\n",
       "      <td>20537</td>\n",
       "      <td>55</td>\n",
       "      <td>10.030704</td>\n",
       "      <td>0.001540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4680</th>\n",
       "      <td>recognize</td>\n",
       "      <td>21445</td>\n",
       "      <td>422</td>\n",
       "      <td>10.030704</td>\n",
       "      <td>0.001540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3141</th>\n",
       "      <td>bug</td>\n",
       "      <td>3202</td>\n",
       "      <td>103</td>\n",
       "      <td>10.030704</td>\n",
       "      <td>0.001540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>959</th>\n",
       "      <td>restart</td>\n",
       "      <td>22122</td>\n",
       "      <td>77</td>\n",
       "      <td>10.030704</td>\n",
       "      <td>0.001540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1750</th>\n",
       "      <td>workforce</td>\n",
       "      <td>30027</td>\n",
       "      <td>1151</td>\n",
       "      <td>10.041827</td>\n",
       "      <td>0.001530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1855</th>\n",
       "      <td>oem</td>\n",
       "      <td>17651</td>\n",
       "      <td>328</td>\n",
       "      <td>10.109230</td>\n",
       "      <td>0.001475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>511</th>\n",
       "      <td>ago</td>\n",
       "      <td>614</td>\n",
       "      <td>1124</td>\n",
       "      <td>10.112687</td>\n",
       "      <td>0.001473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2974</th>\n",
       "      <td>c</td>\n",
       "      <td>3396</td>\n",
       "      <td>74</td>\n",
       "      <td>10.115090</td>\n",
       "      <td>0.001471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1655</th>\n",
       "      <td>english</td>\n",
       "      <td>8451</td>\n",
       "      <td>145</td>\n",
       "      <td>10.214721</td>\n",
       "      <td>0.001393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3404</th>\n",
       "      <td>twenty</td>\n",
       "      <td>27859</td>\n",
       "      <td>156</td>\n",
       "      <td>10.235114</td>\n",
       "      <td>0.001378</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          token  index  frquency       chi2   p_value\n",
       "6246     profit  20537        55  10.030704  0.001540\n",
       "4680  recognize  21445       422  10.030704  0.001540\n",
       "3141        bug   3202       103  10.030704  0.001540\n",
       "959     restart  22122        77  10.030704  0.001540\n",
       "1750  workforce  30027      1151  10.041827  0.001530\n",
       "1855        oem  17651       328  10.109230  0.001475\n",
       "511         ago    614      1124  10.112687  0.001473\n",
       "2974          c   3396        74  10.115090  0.001471\n",
       "1655    english   8451       145  10.214721  0.001393\n",
       "3404     twenty  27859       156  10.235114  0.001378"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unigram_df.sort_values(by='p_value',ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "s=' '.join(list(X_train['clean_sentence']))\n",
    "\n",
    "s = s.lower()\n",
    "s = re.sub(r'[^a-zA-Z0-9\\s]', ' ', s)\n",
    "tokens = [token for token in s.split(\" \") if token != \"\"]\n",
    "\n",
    "# 2grams\n",
    "bgs = nltk.bigrams(tokens)\n",
    "\n",
    "#compute frequency distribution for all the bigrams in the text\n",
    "bigram_fdist = nltk.FreqDist(bgs)\n",
    "tmp_bigram_frequency_tokens={ x[0]:x[1] for x in bigram_fdist.most_common()}\n",
    "# pp.pprint(bigram_frequency_tokens)\n",
    "\n",
    "#3grams\n",
    "bgs = nltk.trigrams(tokens)\n",
    "\n",
    "#compute frequency distribution for all the trigrams in the text\n",
    "trigram_fdist = nltk.FreqDist(bgs)\n",
    "tmp_trigram_frequency_tokens={ x[0]:x[1] for x in trigram_fdist.most_common()}\n",
    "# pp.pprint(trigram_frequency_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram_frequency_tokens={}\n",
    "for key , value in tmp_bigram_frequency_tokens.items():\n",
    "    bigram_frequency_tokens[key[0]+\" \"+key[1]]=value\n",
    "\n",
    "trigram_frequency_tokens={}\n",
    "for key , value in tmp_trigram_frequency_tokens.items():\n",
    "    trigram_frequency_tokens[key[0]+\" \"+key[1]+\" \"+key[2]]=value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(token_pattern=r'\\b\\w+\\b', ngram_range=(2, 2))\n",
    "dataset_vector = vectorizer.fit_transform(X_train[\"clean_sentence\"])\n",
    "\n",
    "\n",
    "chi2_selector = chi2(dataset_vector, X_train['label'])\n",
    "\n",
    "list_tokens=[]\n",
    "for key, val in vectorizer.vocabulary_.items():\n",
    "        if key in bigram_frequency_tokens:\n",
    "            list_tokens.append([key,val,bigram_frequency_tokens[key],chi2_selector[0][val],chi2_selector[1][val]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram_df=pd.DataFrame(list_tokens,columns=['token','index','frquency','chi2','p_value'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>index</th>\n",
       "      <th>frquency</th>\n",
       "      <th>chi2</th>\n",
       "      <th>p_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2848</th>\n",
       "      <td>file box</td>\n",
       "      <td>239685</td>\n",
       "      <td>92</td>\n",
       "      <td>404.577083</td>\n",
       "      <td>5.553609e-90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7027</th>\n",
       "      <td>waste money</td>\n",
       "      <td>758191</td>\n",
       "      <td>56</td>\n",
       "      <td>385.346925</td>\n",
       "      <td>8.528500e-86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2505</th>\n",
       "      <td>tech support</td>\n",
       "      <td>695770</td>\n",
       "      <td>133</td>\n",
       "      <td>366.424157</td>\n",
       "      <td>1.124025e-81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>433706</th>\n",
       "      <td>buy store</td>\n",
       "      <td>83397</td>\n",
       "      <td>17</td>\n",
       "      <td>206.627979</td>\n",
       "      <td>7.474343e-47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13001</th>\n",
       "      <td>customer service</td>\n",
       "      <td>151174</td>\n",
       "      <td>209</td>\n",
       "      <td>202.887641</td>\n",
       "      <td>4.894472e-46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113644</th>\n",
       "      <td>refillable cartridges</td>\n",
       "      <td>568609</td>\n",
       "      <td>16</td>\n",
       "      <td>191.014370</td>\n",
       "      <td>1.909497e-43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23058</th>\n",
       "      <td>poor quality</td>\n",
       "      <td>512171</td>\n",
       "      <td>48</td>\n",
       "      <td>167.285054</td>\n",
       "      <td>2.898445e-38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57030</th>\n",
       "      <td>piece junk</td>\n",
       "      <td>500999</td>\n",
       "      <td>22</td>\n",
       "      <td>152.977721</td>\n",
       "      <td>3.873843e-35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33739</th>\n",
       "      <td>best buy</td>\n",
       "      <td>54129</td>\n",
       "      <td>60</td>\n",
       "      <td>150.632605</td>\n",
       "      <td>1.260925e-34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110974</th>\n",
       "      <td>free postage</td>\n",
       "      <td>260177</td>\n",
       "      <td>13</td>\n",
       "      <td>144.417078</td>\n",
       "      <td>2.880076e-33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        token   index  frquency        chi2       p_value\n",
       "2848                 file box  239685        92  404.577083  5.553609e-90\n",
       "7027              waste money  758191        56  385.346925  8.528500e-86\n",
       "2505             tech support  695770       133  366.424157  1.124025e-81\n",
       "433706              buy store   83397        17  206.627979  7.474343e-47\n",
       "13001        customer service  151174       209  202.887641  4.894472e-46\n",
       "113644  refillable cartridges  568609        16  191.014370  1.909497e-43\n",
       "23058            poor quality  512171        48  167.285054  2.898445e-38\n",
       "57030              piece junk  500999        22  152.977721  3.873843e-35\n",
       "33739                best buy   54129        60  150.632605  1.260925e-34\n",
       "110974           free postage  260177        13  144.417078  2.880076e-33"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigram_df.sort_values(by='chi2',ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Just to update: \n",
    "This clearly tells us the Negative reviews bigrams tokens which have decent frequency and large chi-square results.\n",
    "*waste money*\n",
    "*tech support*\n",
    "*customer service*\n",
    "*piece junk*\n",
    "*poor quality*\n",
    "*really disappointed*\n",
    "*full refund*\n",
    "*error message*\n",
    "\n",
    "Following are the bigram product which negative review revolve around. \n",
    "*worst printer*\n",
    "*refillable cartridges*\n",
    "*head cleanings*\n",
    "*pixel granularity*\n",
    "*cents laser*\n",
    "\n",
    "Yesterday night finished 30 plus positive negative review comments. Bigrams trigram and single tokens features are ready. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>index</th>\n",
       "      <th>frquency</th>\n",
       "      <th>chi2</th>\n",
       "      <th>p_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>54109</th>\n",
       "      <td>fit right</td>\n",
       "      <td>247762</td>\n",
       "      <td>17</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>0.994048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69626</th>\n",
       "      <td>messenger bag</td>\n",
       "      <td>406615</td>\n",
       "      <td>17</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>0.994048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37048</th>\n",
       "      <td>pencil work</td>\n",
       "      <td>486317</td>\n",
       "      <td>17</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>0.994048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51362</th>\n",
       "      <td>front computer</td>\n",
       "      <td>262251</td>\n",
       "      <td>17</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>0.994048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29377</th>\n",
       "      <td>ever problem</td>\n",
       "      <td>215554</td>\n",
       "      <td>17</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>0.994048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114163</th>\n",
       "      <td>printers scanners</td>\n",
       "      <td>531074</td>\n",
       "      <td>17</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>0.994048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118715</th>\n",
       "      <td>kids also</td>\n",
       "      <td>344239</td>\n",
       "      <td>17</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>0.994048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26243</th>\n",
       "      <td>minutes install</td>\n",
       "      <td>411251</td>\n",
       "      <td>17</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>0.994048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72003</th>\n",
       "      <td>well smooth</td>\n",
       "      <td>766333</td>\n",
       "      <td>17</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>0.994048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19947</th>\n",
       "      <td>printer larger</td>\n",
       "      <td>528791</td>\n",
       "      <td>17</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>0.994048</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    token   index  frquency      chi2   p_value\n",
       "54109           fit right  247762        17  0.000056  0.994048\n",
       "69626       messenger bag  406615        17  0.000056  0.994048\n",
       "37048         pencil work  486317        17  0.000056  0.994048\n",
       "51362      front computer  262251        17  0.000056  0.994048\n",
       "29377        ever problem  215554        17  0.000056  0.994048\n",
       "114163  printers scanners  531074        17  0.000056  0.994048\n",
       "118715          kids also  344239        17  0.000056  0.994048\n",
       "26243     minutes install  411251        17  0.000056  0.994048\n",
       "72003         well smooth  766333        17  0.000056  0.994048\n",
       "19947      printer larger  528791        17  0.000056  0.994048"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigram_df.sort_values(by='p_value',ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter on chi pvalue and frequency\n",
    "bigram_df=bigram_df[(bigram_df['chi2']>10)&(bigram_df['frquency']>10)&(bigram_df['p_value']<0.05)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(token_pattern=r'\\b\\w+\\b', ngram_range=(3, 3))\n",
    "dataset_vector = vectorizer.fit_transform(X_train[\"clean_sentence\"])\n",
    "\n",
    "\n",
    "chi2_selector = chi2(dataset_vector, X_train['label'])\n",
    "\n",
    "list_tokens=[]\n",
    "for key, val in vectorizer.vocabulary_.items():\n",
    "        if key in trigram_frequency_tokens:\n",
    "            list_tokens.append([key,val,trigram_frequency_tokens[key],chi2_selector[0][val],chi2_selector[1][val]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigram_df=pd.DataFrame(list_tokens,columns=['token','index','frquency','chi2','p_value'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>index</th>\n",
       "      <th>frquency</th>\n",
       "      <th>chi2</th>\n",
       "      <th>p_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>983539</th>\n",
       "      <td>best buy store</td>\n",
       "      <td>92563</td>\n",
       "      <td>14</td>\n",
       "      <td>222.284142</td>\n",
       "      <td>2.871874e-50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49623</th>\n",
       "      <td>worst printer ever</td>\n",
       "      <td>1449326</td>\n",
       "      <td>6</td>\n",
       "      <td>95.264632</td>\n",
       "      <td>1.665625e-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96702</th>\n",
       "      <td>full list price</td>\n",
       "      <td>465946</td>\n",
       "      <td>7</td>\n",
       "      <td>79.950111</td>\n",
       "      <td>3.839836e-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214366</th>\n",
       "      <td>press start button</td>\n",
       "      <td>955109</td>\n",
       "      <td>8</td>\n",
       "      <td>68.479965</td>\n",
       "      <td>1.281732e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96707</th>\n",
       "      <td>genuine brother supplies</td>\n",
       "      <td>475327</td>\n",
       "      <td>8</td>\n",
       "      <td>68.479965</td>\n",
       "      <td>1.281732e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59739</th>\n",
       "      <td>ink system failure</td>\n",
       "      <td>581853</td>\n",
       "      <td>6</td>\n",
       "      <td>64.499825</td>\n",
       "      <td>9.654092e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>801984</th>\n",
       "      <td>read fine print</td>\n",
       "      <td>1045494</td>\n",
       "      <td>6</td>\n",
       "      <td>64.499825</td>\n",
       "      <td>9.654092e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>692319</th>\n",
       "      <td>hp printer best</td>\n",
       "      <td>555961</td>\n",
       "      <td>6</td>\n",
       "      <td>64.499825</td>\n",
       "      <td>9.654092e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96718</th>\n",
       "      <td>toner powder refills</td>\n",
       "      <td>1330808</td>\n",
       "      <td>4</td>\n",
       "      <td>63.509755</td>\n",
       "      <td>1.595746e-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>628839</th>\n",
       "      <td>best buy oakland</td>\n",
       "      <td>92551</td>\n",
       "      <td>4</td>\n",
       "      <td>63.509755</td>\n",
       "      <td>1.595746e-15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           token    index  frquency        chi2       p_value\n",
       "983539            best buy store    92563        14  222.284142  2.871874e-50\n",
       "49623         worst printer ever  1449326         6   95.264632  1.665625e-22\n",
       "96702            full list price   465946         7   79.950111  3.839836e-19\n",
       "214366        press start button   955109         8   68.479965  1.281732e-16\n",
       "96707   genuine brother supplies   475327         8   68.479965  1.281732e-16\n",
       "59739         ink system failure   581853         6   64.499825  9.654092e-16\n",
       "801984           read fine print  1045494         6   64.499825  9.654092e-16\n",
       "692319           hp printer best   555961         6   64.499825  9.654092e-16\n",
       "96718       toner powder refills  1330808         4   63.509755  1.595746e-15\n",
       "628839          best buy oakland    92551         4   63.509755  1.595746e-15"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trigram_df.sort_values(by='chi2',ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# filter on chi pvalue and frequency\n",
    "trigram_df=trigram_df[(trigram_df['chi2']>10)&(trigram_df['frquency']>10)&(trigram_df['p_value']<0.05)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#build master cir square df\n",
    "\n",
    "master_chi_sq_df=pd.concat([trigram_df,bigram_df,unigram_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1423, 5)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master_chi_sq_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_chi_sq_df.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_chi_sq_df=master_chi_sq_df[master_chi_sq_df.chi2>10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>index</th>\n",
       "      <th>frquency</th>\n",
       "      <th>chi2</th>\n",
       "      <th>p_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ink cartridges printer</td>\n",
       "      <td>577425</td>\n",
       "      <td>39</td>\n",
       "      <td>14.889288</td>\n",
       "      <td>1.140086e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mo file box</td>\n",
       "      <td>742743</td>\n",
       "      <td>13</td>\n",
       "      <td>53.558605</td>\n",
       "      <td>2.509926e-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>laser printer wireless</td>\n",
       "      <td>641177</td>\n",
       "      <td>11</td>\n",
       "      <td>18.284105</td>\n",
       "      <td>1.902883e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>black white text</td>\n",
       "      <td>115672</td>\n",
       "      <td>22</td>\n",
       "      <td>11.142632</td>\n",
       "      <td>8.436612e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>matter many times</td>\n",
       "      <td>724486</td>\n",
       "      <td>12</td>\n",
       "      <td>41.821264</td>\n",
       "      <td>1.000099e-10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    token   index  frquency       chi2       p_value\n",
       "0  ink cartridges printer  577425        39  14.889288  1.140086e-04\n",
       "1             mo file box  742743        13  53.558605  2.509926e-13\n",
       "2  laser printer wireless  641177        11  18.284105  1.902883e-05\n",
       "3        black white text  115672        22  11.142632  8.436612e-04\n",
       "4       matter many times  724486        12  41.821264  1.000099e-10"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master_chi_sq_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_list=master_chi_sq_df['token'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1423"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(feature_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature in feature_list:\n",
    "    X_train[feature]=X_train.clean_sentence.apply(lambda x: 1 if feature in x else 0)\n",
    "    X_test[feature]=X_test.clean_sentence.apply(lambda x: 1 if feature in x else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewText</th>\n",
       "      <th>overall</th>\n",
       "      <th>label</th>\n",
       "      <th>sentence</th>\n",
       "      <th>tokens</th>\n",
       "      <th>stem_sentence</th>\n",
       "      <th>lemm_sentence</th>\n",
       "      <th>pos_tag</th>\n",
       "      <th>filter_pos_tag</th>\n",
       "      <th>clean_sentence</th>\n",
       "      <th>...</th>\n",
       "      <th>participation</th>\n",
       "      <th>suprised</th>\n",
       "      <th>rig</th>\n",
       "      <th>omit</th>\n",
       "      <th>deceive</th>\n",
       "      <th>lapinator</th>\n",
       "      <th>purport</th>\n",
       "      <th>instal</th>\n",
       "      <th>rethink</th>\n",
       "      <th>prepay</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5527</th>\n",
       "      <td>interestingly, you can open this binder with e...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>[interestingly, you can open this binder with ...</td>\n",
       "      <td>[interestingly, open, binder, either, bottom, ...</td>\n",
       "      <td>[interestingli, open, binder, either, bottom, ...</td>\n",
       "      <td>[interestingly, open, binder, either, bottom, ...</td>\n",
       "      <td>[(interestingly, RB), (open, JJ), (binder, NN)...</td>\n",
       "      <td>[interestingly, open, binder, bottom, top, tab...</td>\n",
       "      <td>interestingly open binder bottom top tabs clos...</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27611</th>\n",
       "      <td>these scotch reusable strips for lightweight m...</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>[these scotch reusable strips for lightweight ...</td>\n",
       "      <td>[scotch, reusable, strips, lightweight, mounti...</td>\n",
       "      <td>[scotch, reusabl, strip, lightweight, mount, t...</td>\n",
       "      <td>[scotch, reusable, strip, lightweight, mount, ...</td>\n",
       "      <td>[(scotch, NN), (reusable, JJ), (strips, NNS), ...</td>\n",
       "      <td>[scotch, reusable, strips, terrific, far, ever...</td>\n",
       "      <td>scotch reusable strips terrific far everything...</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1564</th>\n",
       "      <td>these are good, standard solid labels from ave...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>[these are good, standard solid labels from av...</td>\n",
       "      <td>[good, standard, solid, labels, avery, templat...</td>\n",
       "      <td>[good, standard, solid, label, averi, templat,...</td>\n",
       "      <td>[good, standard, solid, label, avery, template...</td>\n",
       "      <td>[(good, JJ), (standard, NN), (solid, JJ), (lab...</td>\n",
       "      <td>[good, standard, solid, labels, avery, templat...</td>\n",
       "      <td>good standard solid labels avery template sugg...</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10206</th>\n",
       "      <td>this is one of the most powerful staplers, i h...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>[this is one of the most powerful staplers, i ...</td>\n",
       "      <td>[one, powerful, staplers, used, claim, finger,...</td>\n",
       "      <td>[one, power, stapler, use, claim, finger, oper...</td>\n",
       "      <td>[one, powerful, staplers, use, claim, finger, ...</td>\n",
       "      <td>[(one, CD), (powerful, JJ), (staplers, NNS), (...</td>\n",
       "      <td>[powerful, staplers, claim, finger, operation,...</td>\n",
       "      <td>powerful staplers claim finger operation true ...</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2824</th>\n",
       "      <td>we use zebra pens in our office and they last ...</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>[we use zebra pens in our office and they last...</td>\n",
       "      <td>[use, zebra, pens, office, last, well, write, ...</td>\n",
       "      <td>[use, zebra, pen, offic, last, well, write, ni...</td>\n",
       "      <td>[use, zebra, pen, office, last, well, write, n...</td>\n",
       "      <td>[(use, NN), (zebra, NN), (pens, VBZ), (office,...</td>\n",
       "      <td>[use, zebra, office, last, well, write, nice, ...</td>\n",
       "      <td>use zebra office last well write nice fine tip...</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1442 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              reviewText  overall  label  \\\n",
       "5527   interestingly, you can open this binder with e...        4      0   \n",
       "27611  these scotch reusable strips for lightweight m...        5      0   \n",
       "1564   these are good, standard solid labels from ave...        4      1   \n",
       "10206  this is one of the most powerful staplers, i h...        4      0   \n",
       "2824   we use zebra pens in our office and they last ...        5      0   \n",
       "\n",
       "                                                sentence  \\\n",
       "5527   [interestingly, you can open this binder with ...   \n",
       "27611  [these scotch reusable strips for lightweight ...   \n",
       "1564   [these are good, standard solid labels from av...   \n",
       "10206  [this is one of the most powerful staplers, i ...   \n",
       "2824   [we use zebra pens in our office and they last...   \n",
       "\n",
       "                                                  tokens  \\\n",
       "5527   [interestingly, open, binder, either, bottom, ...   \n",
       "27611  [scotch, reusable, strips, lightweight, mounti...   \n",
       "1564   [good, standard, solid, labels, avery, templat...   \n",
       "10206  [one, powerful, staplers, used, claim, finger,...   \n",
       "2824   [use, zebra, pens, office, last, well, write, ...   \n",
       "\n",
       "                                           stem_sentence  \\\n",
       "5527   [interestingli, open, binder, either, bottom, ...   \n",
       "27611  [scotch, reusabl, strip, lightweight, mount, t...   \n",
       "1564   [good, standard, solid, label, averi, templat,...   \n",
       "10206  [one, power, stapler, use, claim, finger, oper...   \n",
       "2824   [use, zebra, pen, offic, last, well, write, ni...   \n",
       "\n",
       "                                           lemm_sentence  \\\n",
       "5527   [interestingly, open, binder, either, bottom, ...   \n",
       "27611  [scotch, reusable, strip, lightweight, mount, ...   \n",
       "1564   [good, standard, solid, label, avery, template...   \n",
       "10206  [one, powerful, staplers, use, claim, finger, ...   \n",
       "2824   [use, zebra, pen, office, last, well, write, n...   \n",
       "\n",
       "                                                 pos_tag  \\\n",
       "5527   [(interestingly, RB), (open, JJ), (binder, NN)...   \n",
       "27611  [(scotch, NN), (reusable, JJ), (strips, NNS), ...   \n",
       "1564   [(good, JJ), (standard, NN), (solid, JJ), (lab...   \n",
       "10206  [(one, CD), (powerful, JJ), (staplers, NNS), (...   \n",
       "2824   [(use, NN), (zebra, NN), (pens, VBZ), (office,...   \n",
       "\n",
       "                                          filter_pos_tag  \\\n",
       "5527   [interestingly, open, binder, bottom, top, tab...   \n",
       "27611  [scotch, reusable, strips, terrific, far, ever...   \n",
       "1564   [good, standard, solid, labels, avery, templat...   \n",
       "10206  [powerful, staplers, claim, finger, operation,...   \n",
       "2824   [use, zebra, office, last, well, write, nice, ...   \n",
       "\n",
       "                                          clean_sentence  ... participation  \\\n",
       "5527   interestingly open binder bottom top tabs clos...  ...             0   \n",
       "27611  scotch reusable strips terrific far everything...  ...             0   \n",
       "1564   good standard solid labels avery template sugg...  ...             0   \n",
       "10206  powerful staplers claim finger operation true ...  ...             0   \n",
       "2824   use zebra office last well write nice fine tip...  ...             0   \n",
       "\n",
       "       suprised  rig  omit  deceive  lapinator  purport  instal  rethink  \\\n",
       "5527          0    0     0        0          0        0       0        0   \n",
       "27611         0    1     0        0          0        0       0        0   \n",
       "1564          0    1     0        0          0        0       0        0   \n",
       "10206         0    0     0        0          0        0       0        0   \n",
       "2824          0    0     0        0          0        0       0        0   \n",
       "\n",
       "       prepay  \n",
       "5527        0  \n",
       "27611       0  \n",
       "1564        0  \n",
       "10206       0  \n",
       "2824        0  \n",
       "\n",
       "[5 rows x 1442 columns]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try with only feature list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# X = dataset[feature_list]\n",
    "# y = pd.DataFrame(dataset, columns = [\"label\"])\n",
    "\n",
    "# X_train , X_test , y_train , y_test = train_test_split(X, y, random_state=50,stratify=y,train_size=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8572614107883817\n"
     ]
    }
   ],
   "source": [
    "log_reg_model = LogisticRegressionCV(class_weight='balanced')\n",
    "log_reg_model.fit(X_train[feature_list], y_train)\n",
    "scores = log_reg_model.score(X_test[feature_list], y_test) # accuracy\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Making prediction on the train data\n",
    "y_train_pred = log_reg_model.predict_proba(X_train[feature_list])[:,1]\n",
    "\n",
    "#Making prediction on the test data\n",
    "y_pred = log_reg_model.predict_proba(X_test[feature_list])[:,1]\n",
    "\n",
    "y_train_pred=pd.Series(y_train_pred)\n",
    "y_pred=pd.Series(y_pred)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_bool= y_pred.apply(lambda x: 1 if x>=0.134 else 0)\n",
    "y_train_pred_bool= y_train_pred.apply(lambda x: 1 if x>=0.134 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1222,   777],\n",
       "       [  920, 30819]])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.confusion_matrix(y_train,y_train_pred_bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy    : 0.95\n",
      "Sensitivity : 0.97\n",
      "Specificity : 0.61\n",
      "Precision   : 0.98\n",
      "Recall      : 0.97\n",
      "F1_score    : 0.95\n"
     ]
    }
   ],
   "source": [
    "get_model_metrics(y_train,y_train_pred_bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  360,   497],\n",
       "       [  535, 13068]])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.confusion_matrix(y_test,y_pred_bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy    : 0.93\n",
      "Sensitivity : 0.96\n",
      "Specificity : 0.42\n",
      "Precision   : 0.96\n",
      "Recall      : 0.96\n",
      "F1_score    : 0.93\n"
     ]
    }
   ],
   "source": [
    "get_model_metrics(y_test,y_pred_bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "additional_features=feature_list+['#positive_sentences','#negative_sentences']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ink cartridges printer</th>\n",
       "      <th>mo file box</th>\n",
       "      <th>laser printer wireless</th>\n",
       "      <th>black white text</th>\n",
       "      <th>matter many times</th>\n",
       "      <th>amazon vine program</th>\n",
       "      <th>press power button</th>\n",
       "      <th>paper regular paper</th>\n",
       "      <th>pages cents page</th>\n",
       "      <th>cents page cents</th>\n",
       "      <th>...</th>\n",
       "      <th>rig</th>\n",
       "      <th>omit</th>\n",
       "      <th>deceive</th>\n",
       "      <th>lapinator</th>\n",
       "      <th>purport</th>\n",
       "      <th>instal</th>\n",
       "      <th>rethink</th>\n",
       "      <th>prepay</th>\n",
       "      <th>#positive_sentences</th>\n",
       "      <th>#negative_sentences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30346</th>\n",
       "      <td>-0.038525</td>\n",
       "      <td>-0.018863</td>\n",
       "      <td>-0.01806</td>\n",
       "      <td>-0.024957</td>\n",
       "      <td>-0.018863</td>\n",
       "      <td>-0.056932</td>\n",
       "      <td>-0.016335</td>\n",
       "      <td>-0.020375</td>\n",
       "      <td>-0.012175</td>\n",
       "      <td>-0.016335</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.440851</td>\n",
       "      <td>-0.012175</td>\n",
       "      <td>-0.005444</td>\n",
       "      <td>-0.00943</td>\n",
       "      <td>-0.013337</td>\n",
       "      <td>-0.212602</td>\n",
       "      <td>-0.0077</td>\n",
       "      <td>-0.005444</td>\n",
       "      <td>0.793065</td>\n",
       "      <td>-0.077773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466</th>\n",
       "      <td>-0.038525</td>\n",
       "      <td>-0.018863</td>\n",
       "      <td>-0.01806</td>\n",
       "      <td>-0.024957</td>\n",
       "      <td>-0.018863</td>\n",
       "      <td>-0.056932</td>\n",
       "      <td>-0.016335</td>\n",
       "      <td>-0.020375</td>\n",
       "      <td>-0.012175</td>\n",
       "      <td>-0.016335</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.440851</td>\n",
       "      <td>-0.012175</td>\n",
       "      <td>-0.005444</td>\n",
       "      <td>-0.00943</td>\n",
       "      <td>-0.013337</td>\n",
       "      <td>-0.212602</td>\n",
       "      <td>-0.0077</td>\n",
       "      <td>-0.005444</td>\n",
       "      <td>0.793065</td>\n",
       "      <td>-0.682361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4335</th>\n",
       "      <td>-0.038525</td>\n",
       "      <td>-0.018863</td>\n",
       "      <td>-0.01806</td>\n",
       "      <td>-0.024957</td>\n",
       "      <td>-0.018863</td>\n",
       "      <td>-0.056932</td>\n",
       "      <td>-0.016335</td>\n",
       "      <td>-0.020375</td>\n",
       "      <td>-0.012175</td>\n",
       "      <td>-0.016335</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.440851</td>\n",
       "      <td>-0.012175</td>\n",
       "      <td>-0.005444</td>\n",
       "      <td>-0.00943</td>\n",
       "      <td>-0.013337</td>\n",
       "      <td>-0.212602</td>\n",
       "      <td>-0.0077</td>\n",
       "      <td>-0.005444</td>\n",
       "      <td>-0.349900</td>\n",
       "      <td>-0.682361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37664</th>\n",
       "      <td>-0.038525</td>\n",
       "      <td>-0.018863</td>\n",
       "      <td>-0.01806</td>\n",
       "      <td>-0.024957</td>\n",
       "      <td>-0.018863</td>\n",
       "      <td>-0.056932</td>\n",
       "      <td>-0.016335</td>\n",
       "      <td>-0.020375</td>\n",
       "      <td>-0.012175</td>\n",
       "      <td>-0.016335</td>\n",
       "      <td>...</td>\n",
       "      <td>2.268338</td>\n",
       "      <td>-0.012175</td>\n",
       "      <td>-0.005444</td>\n",
       "      <td>-0.00943</td>\n",
       "      <td>-0.013337</td>\n",
       "      <td>-0.212602</td>\n",
       "      <td>-0.0077</td>\n",
       "      <td>-0.005444</td>\n",
       "      <td>1.174053</td>\n",
       "      <td>1.131403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35986</th>\n",
       "      <td>-0.038525</td>\n",
       "      <td>-0.018863</td>\n",
       "      <td>-0.01806</td>\n",
       "      <td>-0.024957</td>\n",
       "      <td>-0.018863</td>\n",
       "      <td>-0.056932</td>\n",
       "      <td>-0.016335</td>\n",
       "      <td>-0.020375</td>\n",
       "      <td>-0.012175</td>\n",
       "      <td>-0.016335</td>\n",
       "      <td>...</td>\n",
       "      <td>2.268338</td>\n",
       "      <td>-0.012175</td>\n",
       "      <td>-0.005444</td>\n",
       "      <td>-0.00943</td>\n",
       "      <td>-0.013337</td>\n",
       "      <td>-0.212602</td>\n",
       "      <td>-0.0077</td>\n",
       "      <td>-0.005444</td>\n",
       "      <td>-0.349900</td>\n",
       "      <td>-0.682361</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1425 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       ink cartridges printer  mo file box  laser printer wireless  \\\n",
       "30346               -0.038525    -0.018863                -0.01806   \n",
       "466                 -0.038525    -0.018863                -0.01806   \n",
       "4335                -0.038525    -0.018863                -0.01806   \n",
       "37664               -0.038525    -0.018863                -0.01806   \n",
       "35986               -0.038525    -0.018863                -0.01806   \n",
       "\n",
       "       black white text  matter many times  amazon vine program  \\\n",
       "30346         -0.024957          -0.018863            -0.056932   \n",
       "466           -0.024957          -0.018863            -0.056932   \n",
       "4335          -0.024957          -0.018863            -0.056932   \n",
       "37664         -0.024957          -0.018863            -0.056932   \n",
       "35986         -0.024957          -0.018863            -0.056932   \n",
       "\n",
       "       press power button  paper regular paper  pages cents page  \\\n",
       "30346           -0.016335            -0.020375         -0.012175   \n",
       "466             -0.016335            -0.020375         -0.012175   \n",
       "4335            -0.016335            -0.020375         -0.012175   \n",
       "37664           -0.016335            -0.020375         -0.012175   \n",
       "35986           -0.016335            -0.020375         -0.012175   \n",
       "\n",
       "       cents page cents  ...       rig      omit   deceive  lapinator  \\\n",
       "30346         -0.016335  ... -0.440851 -0.012175 -0.005444   -0.00943   \n",
       "466           -0.016335  ... -0.440851 -0.012175 -0.005444   -0.00943   \n",
       "4335          -0.016335  ... -0.440851 -0.012175 -0.005444   -0.00943   \n",
       "37664         -0.016335  ...  2.268338 -0.012175 -0.005444   -0.00943   \n",
       "35986         -0.016335  ...  2.268338 -0.012175 -0.005444   -0.00943   \n",
       "\n",
       "        purport    instal  rethink    prepay  #positive_sentences  \\\n",
       "30346 -0.013337 -0.212602  -0.0077 -0.005444             0.793065   \n",
       "466   -0.013337 -0.212602  -0.0077 -0.005444             0.793065   \n",
       "4335  -0.013337 -0.212602  -0.0077 -0.005444            -0.349900   \n",
       "37664 -0.013337 -0.212602  -0.0077 -0.005444             1.174053   \n",
       "35986 -0.013337 -0.212602  -0.0077 -0.005444            -0.349900   \n",
       "\n",
       "       #negative_sentences  \n",
       "30346            -0.077773  \n",
       "466              -0.682361  \n",
       "4335             -0.682361  \n",
       "37664             1.131403  \n",
       "35986            -0.682361  \n",
       "\n",
       "[5 rows x 1425 columns]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train_1= pd.DataFrame(scaler.fit_transform(X_train[additional_features]), index=X_train.index, columns=additional_features)\n",
    "\n",
    "X_test_1= pd.DataFrame(scaler.transform(X_test[additional_features]), index=X_test.index, columns=additional_features)\n",
    "X_train_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8876901798063623\n"
     ]
    }
   ],
   "source": [
    "log_reg_model = LogisticRegressionCV(class_weight='balanced')\n",
    "log_reg_model.fit(X_train_1[additional_features], y_train)\n",
    "scores = log_reg_model.score(X_test_1[additional_features], y_test) # accuracy\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Making prediction on the train data\n",
    "y_train_pred = log_reg_model.predict_proba(X_train_1[additional_features])[:,1]\n",
    "\n",
    "#Making prediction on the test data\n",
    "y_pred = log_reg_model.predict_proba(X_test_1[additional_features])[:,1]\n",
    "\n",
    "y_train_pred=pd.Series(y_train_pred)\n",
    "y_pred=pd.Series(y_pred)\n",
    "\n",
    "y_pred_bool= y_pred.apply(lambda x: 1 if x>=0.134 else 0)\n",
    "y_train_pred_bool= y_train_pred.apply(lambda x: 1 if x>=0.134 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  512,  1487],\n",
       "       [  145, 31594]])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.confusion_matrix(y_train,y_train_pred_bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  153,   704],\n",
       "       [   73, 13530]])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.confusion_matrix(y_test,y_pred_bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy    : 0.95\n",
      "Sensitivity : 1.0\n",
      "Specificity : 0.26\n",
      "Precision   : 0.96\n",
      "Recall      : 1.0\n",
      "F1_score    : 0.94\n"
     ]
    }
   ],
   "source": [
    "get_model_metrics(y_train,y_train_pred_bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy    : 0.95\n",
      "Sensitivity : 0.99\n",
      "Specificity : 0.18\n",
      "Precision   : 0.95\n",
      "Recall      : 0.99\n",
      "F1_score    : 0.93\n"
     ]
    }
   ],
   "source": [
    "get_model_metrics(y_test,y_pred_bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.iloc[:100,:].to_csv('amazon_text_review_features.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[dataset['label']==0].to_csv('amazon_text_review_negative_features.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification with word vectors v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X=dataset['filter_pos_tag'].to_list()\n",
    "# y=dataset['label'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48198, 20)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_text=dataset['clean_sentence'].to_list()\n",
    "X_train_label=dataset['label'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48198"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(X_train_text,X_train_label, test_size=0.3,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "                dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "                lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "                ngram_range=(1, 1), preprocessor=None, stop_words='english',\n",
       "                strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect = CountVectorizer(stop_words='english',max_features=5000)\n",
    "vect = CountVectorizer(stop_words='english')\n",
    "vect.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_transformed = vect.transform(X_train)\n",
    "X_test_transformed =vect.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('quite', 20968),\n",
       " ('pretty', 20062),\n",
       " ('translucent', 27447),\n",
       " ('cover', 5717),\n",
       " ('bit', 2421),\n",
       " ('write', 30052),\n",
       " ('let', 14583),\n",
       " ('dry', 7777),\n",
       " ('version', 28913),\n",
       " ('little', 14857)]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# printing the vocabulary\n",
    "list(vect.vocabulary_.items())[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Bernoulli NB "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy:  0.9119390598138597\n",
      "Test accuracy:  0.9088520055325034\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "bnb = BernoulliNB()\n",
    "bnb.fit(X_train_transformed,y_train)\n",
    "\n",
    "# predict class\n",
    "pred_train_ys = bnb.predict(X_train_transformed)\n",
    "pred_test_ys = bnb.predict(X_test_transformed)\n",
    "\n",
    "# accuracy\n",
    "print(\"Train accuracy: \", accuracy_score(y_train, pred_train_ys))\n",
    "print(\"Test accuracy: \", accuracy_score(y_test, pred_test_ys))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  591,  1426],\n",
       "       [ 1545, 30176]])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_train, pred_train_ys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Multinomial NB\n",
    " - We expect this to work very well, giving high performance in accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "mnb = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy:  0.9484261070602881\n",
      "Test accuracy:  0.9423236514522821\n"
     ]
    }
   ],
   "source": [
    "#fit on training data\n",
    "mnb.fit(X_train_transformed, y_train)\n",
    "\n",
    "# predict class\n",
    "pred_train_ys = mnb.predict(X_train_transformed)\n",
    "pred_test_ys = mnb.predict(X_test_transformed)\n",
    "\n",
    "# accuracy\n",
    "print(\"Train accuracy: \", accuracy_score(y_train, pred_train_ys))\n",
    "print(\"Test accuracy: \", accuracy_score(y_test, pred_test_ys))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  809,  1208],\n",
       "       [  532, 31189]])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_train, pred_train_ys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - As expected, this performed really well\n",
    " - Remember that we used 5000 features!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using our word embeddings approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " We have two options here:\n",
    " \n",
    "1. Use pre-trained word vectors (Glove)\n",
    "\n",
    "2. Train our own vectors\n",
    "\n",
    "We'll explore both "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400000, 200)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.scripts.glove2word2vec import glove2word2vec\n",
    "glove_input_file = 'glove.6B.200d.txt'\n",
    "word2vec_output_file = 'glove.6B.200d.w2vformat.txt'\n",
    "glove2word2vec(glove_input_file, word2vec_output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "glove_model = KeyedVectors.load_word2vec_format(\"glove.6B.200d.w2vformat.txt\", binary=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentence vector by averaging word vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = stopwords.words(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sent_vec(sent):\n",
    "    wv_res = np.zeros(glove_model.vector_size)\n",
    "    ctr = 1\n",
    "    for w in sent:\n",
    "        if w in glove_model:\n",
    "            ctr += 1\n",
    "            wv_res += glove_model[w]\n",
    "    wv_res = wv_res/ctr\n",
    "    #return (wv_res, ctr)\n",
    "    return wv_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(dataset['filter_pos_tag'],dataset['label'], test_size=0.3,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_doc_vecs = []\n",
    "for doc in X_train:    \n",
    "    doc_words = [term for term in doc if term not in stop_words]\n",
    "    train_doc_vecs.append(sent_vec(doc_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_doc_vecs = []\n",
    "for doc in X_test:    \n",
    "    doc_words = [term for term in doc if term not in stop_words]\n",
    "    test_doc_vecs.append(sent_vec(doc_words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building a predictive model on the averaged word vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using a 'simple' logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l1',\n",
       "                   random_state=42, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg = LogisticRegression(penalty=\"l1\", random_state=42, C = 2)\n",
    "logreg.fit(train_doc_vecs,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy:  0.9418163495168652\n",
      "Test accuracy:  0.9432918395573997\n"
     ]
    }
   ],
   "source": [
    "pred_train_ys = logreg.predict(train_doc_vecs)\n",
    "pred_test_ys = logreg.predict(test_doc_vecs)\n",
    "print(\"Train accuracy: \", accuracy_score(pred_train_ys, y_train))\n",
    "print(\"Test accuracy: \", accuracy_score(pred_test_ys, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_positive_Prob</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.991460</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.945712</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.999866</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.997039</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.979068</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   is_positive_Prob  predicted\n",
       "0          0.991460          1\n",
       "1          0.945712          1\n",
       "2          0.999866          1\n",
       "3          0.997039          1\n",
       "4          0.979068          1"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "y_train_pred = logreg.predict_proba(train_doc_vecs)[:,1]\n",
    "# y_train_pred = y_train_pred.reshape(-1)\n",
    "y_train_pred_final = pd.DataFrame({'is_positive_Prob':y_train_pred})\n",
    "y_train_pred_final['predicted'] = y_train_pred_final.is_positive_Prob.map(lambda x: 1 if x > 0.7 else 0)\n",
    "y_train_pred_final.head()\n",
    "\n",
    "y_test_pred = logreg.predict_proba(test_doc_vecs)[:,1]\n",
    "y_test_pred_final = pd.DataFrame({'is_positive_Prob':y_test_pred})\n",
    "y_test_pred_final['predicted'] = y_test_pred_final.is_positive_Prob.map(lambda x: 1 if x > 0.7 else 0)\n",
    "y_test_pred_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy:  0.9418163495168652\n",
      "Test accuracy:  0.9432918395573997\n"
     ]
    }
   ],
   "source": [
    "print(\"Train accuracy: \", accuracy_score(pred_train_ys, y_train))\n",
    "print(\"Test accuracy: \", accuracy_score(pred_test_ys, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  496,   519],\n",
       "       [ 1521, 31202]])"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_train_pred_final.predicted, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  193,   242],\n",
       "       [  646, 13379]])"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test_pred_final.predicted, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training our own wordvectors on the data\n",
    "We'll create a combined text file to train our word vectors - more data is better. Although in this case we would still have just 7.7K instances to learn from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48198"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_comb = np.concatenate([X_train,X_test])\n",
    "len(X_comb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['great',\n",
       " 'marker',\n",
       " 'boards',\n",
       " 'size',\n",
       " 'perfect',\n",
       " 'shipment',\n",
       " 'super',\n",
       " 'fast',\n",
       " 'always']"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_comb[6000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import word2vec\n",
    "w2v = word2vec.Word2Vec(X_comb, window=2, min_count=2, sg = 1, size=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('tricky', 0.7400240898132324),\n",
       " ('confusing', 0.6999003887176514),\n",
       " ('awkward', 0.6924850344657898),\n",
       " ('struggle', 0.6896036267280579),\n",
       " ('harder', 0.6783034801483154)]"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v.most_similar(\"difficult\", topn=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sentence vectors by averaging vectors for words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sent_vec_w2v(sent):\n",
    "    wv_res = np.zeros(w2v.vector_size)\n",
    "    ctr = 1\n",
    "    for w in sent:\n",
    "        if w in w2v:\n",
    "            ctr += 1\n",
    "            wv_res += w2v[w]\n",
    "    wv_res = wv_res/ctr\n",
    "    return wv_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Getting the sentence vectors for the test and train sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33738,)"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_doc_vecs = []\n",
    "for doc in X_train:    \n",
    "    doc_words = [term for term in doc if term not in stop_words]\n",
    "    train_doc_vecs.append(sent_vec_w2v(doc_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33738"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_doc_vecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    31721\n",
       "0     2017\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_doc_vecs = []\n",
    "for doc in X_test:    \n",
    "    doc_words = [term for term in doc if term not in stop_words]\n",
    "    test_doc_vecs.append(sent_vec_w2v(doc_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression,LogisticRegressionCV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression( random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=42, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg.fit(train_doc_vecs,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_train_ys = logreg.predict_proba(train_doc_vecs)\n",
    "pred_test_ys = logreg.predict_proba(test_doc_vecs)\n",
    "# print(\"Train accuracy: \", accuracy_score(pred_train_ys, y_train))\n",
    "# print(\"Test accuracy: \", accuracy_score(pred_test_ys, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_positive_Prob</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.999558</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.973552</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.999309</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.986397</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.972431</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   is_positive_Prob  predicted\n",
       "0          0.999558          1\n",
       "1          0.973552          1\n",
       "2          0.999309          1\n",
       "3          0.986397          1\n",
       "4          0.972431          1"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "y_train_pred = logreg.predict_proba(train_doc_vecs)[:,1]\n",
    "# y_train_pred = y_train_pred.reshape(-1)\n",
    "y_train_pred_final = pd.DataFrame({'is_positive_Prob':y_train_pred})\n",
    "y_train_pred_final['predicted'] = y_train_pred_final.is_positive_Prob.map(lambda x: 1 if x > 0.7 else 0)\n",
    "y_train_pred_final.head()\n",
    "\n",
    "y_test_pred = logreg.predict_proba(test_doc_vecs)[:,1]\n",
    "y_test_pred_final = pd.DataFrame({'is_positive_Prob':y_test_pred})\n",
    "y_test_pred_final['predicted'] = y_test_pred_final.is_positive_Prob.map(lambda x: 1 if x > 0.7 else 0)\n",
    "y_test_pred_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  555,   476],\n",
       "       [ 1462, 31245]])"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_train_pred_final.predicted, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  218,   225],\n",
       "       [  621, 13396]])"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test_pred_final.predicted, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
